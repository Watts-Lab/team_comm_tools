# Importing modules from features
from team_comm_tools.utils.summarize_features import get_user_sum_dataframe, get_user_mean_dataframe, get_user_max_dataframe, get_user_min_dataframe, get_user_stdev_dataframe, get_user_median_dataframe
from team_comm_tools.features.get_user_network import *
from team_comm_tools.features.user_centroids import *
from fuzzywuzzy import process

class UserLevelFeaturesCalculator:
    """
    Initialize variables and objects used by the UserLevelFeaturesCalculator class.

    This class uses various feature modules to define user- (speaker) level features. It reads input data and
    initializes variables required to compute the features.

    :param chat_data: Pandas dataframe of chat-level features read from the input dataset
    :type chat_data: pd.DataFrame
    :param user_data: Pandas dataframe of user-level features derived from the chat-level dataframe
    :type user_data: pd.DataFrame
    :param vect_data: Pandas dataframe of message embeddings corresponding to each instance of the chat data
    :type vect_data: pd.DataFrame
    :param conversation_id_col: A string representing the column name that should be selected as the conversation ID. Defaults to "conversation_num".
    :type conversation_id_col: str
    :param speaker_id_col: A string representing the column name that should be selected as the speaker ID. Defaults to "speaker_nickname".
    :type speaker_id_col: str
    :param user_aggregation: If true, will aggregate features at the user level
    :type user_aggregation: bool
    :param user_methods: Specifies which functions users want to aggregate with (e.g., mean, stdev...) at the user level
    :type user_methods: list
    :param user_columns: Specifies which columns (at the chat level) users want aggregated for the user level
    :type user_columns: list
    :param chat_features: Tracks all the chat-level features generated by the toolkit
    :type chat_features: list
    """
    def __init__(self, chat_data: pd.DataFrame, 
                        user_data: pd.DataFrame, 
                        vect_data: pd.DataFrame, 
                        conversation_id_col: str, 
                        speaker_id_col: str, 
                        user_aggregation: bool,
                        user_methods: list,
                        user_columns: list,
                        chat_features: list) -> None:

        # Initializing variables
        self.chat_data = chat_data
        self.user_data = user_data
        self.vect_data = vect_data
        self.conversation_id_col = conversation_id_col
        self.speaker_id_col = speaker_id_col
        self.user_aggregation = user_aggregation
        self.user_methods = user_methods
        self.chat_features = chat_features

        def clean_up_aggregation_method_names(aggregation_method_names:list) -> list:
            """
            Clean up different ways of specifying the aggregation names; e.g., point "average" and "max"
            to the same function

            :param aggregation_method_names: The list of method names requested by the user for aggregation
            :type aggregation_method_names: list

            :return: the list of valid methods that can be used for aggregation
            :rtype: list
            """

            aggregation_method_names = aggregation_method_names.copy()

            for i in range(len(aggregation_method_names)):
                # directly modify the list to replace synonyms
                if aggregation_method_names[i] == "average":
                    aggregation_method_names[i] = "mean"
                if aggregation_method_names[i] == "maximum":
                    aggregation_method_names[i] = "max"
                if aggregation_method_names[i] == "minimum":
                    aggregation_method_names[i] = "min"
                if aggregation_method_names[i] == "standard deviation":
                    aggregation_method_names[i] = "stdev"
                if aggregation_method_names[i] == "sd":
                    aggregation_method_names[i] = "stdev"
                if aggregation_method_names[i] == "std":
                    aggregation_method_names[i] = "stdev"
                if aggregation_method_names[i] == "total":
                    aggregation_method_names[i] = "sum"
                if aggregation_method_names[i] == "add":
                    aggregation_method_names[i] = "sum"
                if aggregation_method_names[i] == "summing":
                    aggregation_method_names[i] = "sum"
                            
                current = aggregation_method_names[i]

                # don't print warnings here, since we already print them in the conversation_level_features equivalent
                if current != "mean" and current != "max" and current != "min" and current != "stdev" and current != "median" and current != "sum":
                    aggregation_method_names.remove(current)

            return aggregation_method_names

        def ensure_aggregation_columns_present(user_inputted_columns:list, agg_param:str) -> list:
            
            """
            An error checking function to ensure that the columns inputted by the user are present in the data.

            Does not print warnings, since equivalent warnings are already printed at the conversation level.

            :param user_inputted_columns: The list of columns requested by the user for aggregation
            :type user_inputted_columns: list

            :param user_inputted_columns: The name of the parameter the user specified for aggregation (convo_columns or user_columns)
            :type user_inputted_columns: str

            :return: the list of valid columns that can be aggregated (they are present in the chat data AND generated by us)
            :rtype: list
            """
            columns_in_data = list(set(user_inputted_columns).intersection(set(self.chat_features).intersection(set(self.chat_data.columns))))
            return columns_in_data
        
        # check if user inputted user_columns is None
        # we default to aggregating all generated chat-level features
        if user_columns is None:
            self.columns_to_summarize = [column for column in set(self.chat_features).intersection(set(self.chat_data.columns)) \
                                        if pd.api.types.is_numeric_dtype(self.chat_data[column])]
        else:
            if user_aggregation == True and (len(user_columns) == 0 or len(user_methods) == 0):
                self.user_aggregation = False
            else:
                # to check if columns are in the data
                user_columns_in_data = ensure_aggregation_columns_present(user_inputted_columns = user_columns, agg_param = "user_columns")
                self.columns_to_summarize = user_columns_in_data
                
                # ensure all lowercase
                self.user_methods = [col.lower() for col in self.user_methods]
                self.columns_to_summarize = [col.lower() for col in self.columns_to_summarize]
                
                # check if columns are numeric
                for col in self.columns_to_summarize:
                    if pd.api.types.is_numeric_dtype(self.chat_data[col]) is False:
                        self.columns_to_summarize.remove(col)
                
        # replace interchangable words in user_methods and remove invalid methods
        self.user_methods = clean_up_aggregation_method_names(aggregation_method_names = self.user_methods)

        # columns that need to be summed due to dependency on gini coefficient                        
        self.summable_columns = ["num_words", "num_chars", "num_messages"]
                
    def calculate_user_level_features(self) -> pd.DataFrame:
        """
        Main driver function for creating user-level features.

        This function computes various user-level features by aggregating chat-level data,
        and appends them as new columns to the input user-level data.

        :return: The user-level dataset with new columns for each user-level feature
        :rtype: pd.DataFrame
        """

        # Get total counts for features that need to be summed, regardless of what the user specified
        self.get_user_level_summed_features()
        
        # Get user summary statistics for all features (e.g. mean, min, max, stdev)
        self.get_user_level_summary_statistics_features()
        
        # Get 4 discursive features (discursive diversity, variance in DD, incongruent modulation, within-person discursive range)
        self.get_centroids()

        # Get list of other users in a given conversation
        self.get_user_network()

        return self.user_data

    def get_user_level_summary_statistics_features(self) -> None:
        """
            This function is used to aggregate the summary statistics from 
            chat level features to user level features.
            
            There are many possible ways to aggregate user level features, e.g.:
            - Mean of all chats by a given user;
            - Max of all chats by a given user;
            - Weighted mean (e.g., looking at different time points?)
            ... and so on.

            This is an open question, so we are putting a TODO here.
        """
                
        if self.user_aggregation == True:
            
            # For each summarizable feature
            for column in self.columns_to_summarize:
                
                # Average/Mean of feature across the User
                if 'mean' in self.user_methods:
                    self.user_data = pd.merge(
                        left=self.user_data,
                        right=get_user_mean_dataframe(self.chat_data, column, self.conversation_id_col, self.speaker_id_col),
                        on=[self.conversation_id_col, self.speaker_id_col],
                        how="inner"
                    )
                    
                # Maxima for the feature across the User
                if 'max' in self.user_methods:
                    self.user_data = pd.merge(
                        left=self.user_data,
                        right=get_user_max_dataframe(self.chat_data, column, self.conversation_id_col, self.speaker_id_col),
                        on=[self.conversation_id_col, self.speaker_id_col],
                        how="inner"
                    )
                    
                # Minima for the feature across the User
                if 'min' in self.user_methods:
                    self.user_data = pd.merge(
                        left=self.user_data,
                        right=get_user_min_dataframe(self.chat_data, column, self.conversation_id_col, self.speaker_id_col),
                        on=[self.conversation_id_col, self.speaker_id_col],
                        how="inner"
                    )
                    
                # Standard Deviation of feature across the User
                if 'stdev' in self.user_methods:
                    self.user_data = pd.merge(
                        left=self.user_data,
                        right=get_user_stdev_dataframe(self.chat_data, column, self.conversation_id_col, self.speaker_id_col),
                        on=[self.conversation_id_col, self.speaker_id_col],
                        how="inner"
                    )
                    
                # Median of feature across the User
                if 'median' in self.user_methods:
                    self.user_data = pd.merge(
                        left=self.user_data,
                        right=get_user_median_dataframe(self.chat_data, column, self.conversation_id_col, self.speaker_id_col),
                        on=[self.conversation_id_col, self.speaker_id_col],
                        how="inner"
                    )

                # Sum of feature across the User
                if column not in self.summable_columns: # do this only for things we are not already auto-summarizing
                    if 'sum' in self.user_methods:
                        self.user_data = pd.merge(
                            left=self.user_data,
                            right=get_user_sum_dataframe(self.chat_data, column, self.conversation_id_col, self.speaker_id_col),
                            on=[self.conversation_id_col, self.speaker_id_col],
                            how="inner"
                        )

    def get_user_level_summed_features(self) -> None:
        """
        Aggregate summary statistics from chat-level features that need to be summed together.

        Features for which summing makes sense include:
        - Word count (total number of words)
        - Character count
        - Message count

        This function calculates and merges the summed features into the user-level data.

        :return: None
        :rtype: None
        """
        
        # For each summarizable feature
        for column in self.summable_columns:
                
            # Sum of feature across the Conversation
            self.user_data = pd.merge(
                left=self.user_data,
                right=get_user_sum_dataframe(self.chat_data, column, self.conversation_id_col, self.speaker_id_col),
                on=[self.conversation_id_col, self.speaker_id_col],
                how="inner"
            )

    def get_centroids(self) -> None:
        """
        Calculate the centroid of each user's chats in a given conversation for future discursive metric calculations.

        This function computes and appends the mean embedding (centroid) of each user's chats to the user-level data.

        :return: None
        :rtype: None
        """
        if self.vect_data is not None: # only do this if we have vector data for each user
            self.user_data['mean_embedding'] = get_user_centroids(self.chat_data, self.vect_data, self.conversation_id_col, self.speaker_id_col)

    def get_user_network(self) -> None:
        """
        Get the user list per user per conversation.

        This function calculates and appends the list of other users in a given conversation to the user-level data.

        :return: None
        :rtype: None
        """
        self.user_data = pd.merge(
                left=self.user_data,
                right=get_user_network(self.user_data, self.conversation_id_col, self.speaker_id_col),
                on=[self.conversation_id_col, self.speaker_id_col],
                how="inner"
            )