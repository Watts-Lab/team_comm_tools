{"cells":[{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["import pickle\n","import re\n","import pandas as pd\n","import os\n","from pathlib import Path\n","\n","lexicon_pkl_file_path = \"feature_engine/features/lexicons_dict.pkl\"\n","with open(lexicon_pkl_file_path, \"rb\") as lexicons_pickle_file:\n","\tlexicons_dict = pickle.load(lexicons_pickle_file)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["import os\n","import random\n","import csv\n","\n","alphabet = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\"]\n","filler = [\"Lorem\", \"ipsum\", \"dolor\", \"amet\", \"consectetur\", \"adipiscing\", \"sed\", \"euismod\", \"tempor\"]\n","\n","def generate_random_strings_from_wordlist(wordlist, num_strings, min_words=1, max_words=5):\n","    max_words = min(max_words, len(wordlist))\n","    strings = []\n","    expected_value = []\n","    for _ in range(num_strings):\n","        num_words = random.randint(min_words, max_words)\n","        expected_value.append(num_words/100)\n","        selected_words = random.sample(wordlist, num_words)\n","\n","         # for strings in selected_words that end with *, append a random number of letters to that string\n","        for i in range(len(selected_words)):\n","            selected_words[i] = selected_words[i].strip()\n","            if selected_words[i].endswith(\"*\"):\n","                selected_words[i] = selected_words[i][:-1] + ''.join(random.sample(alphabet, random.randint(1, 5)))\n","\n","\n","        # num_fillers = random.randint(1, 3)\n","        # filler_words = random.sample(filler, num_fillers)\n","        # final_words = random.choices(selected_words) + random.choices(filler_words)\n","        \n","        strings.append(' '.join(selected_words))\n","    return [strings, expected_value]\n","\n","def write_to_csv(strings, expected_vals, wordlist_name, filename='output.csv'):\n","    with open(filename, 'a', newline='') as csvfile:\n","        writer = csv.writer(csvfile)\n","        for string, expected_val in zip(strings, expected_vals):\n","            writer.writerow([0, 0, string, wordlist_name + \"_lexical_per_100\", expected_val])\n","\n","directory = ['feature_engine/features/lexicons/liwc_lexicons','feature_engine/features/lexicons/liwc_lexicons_small_test','feature_engine/features/lexicons/other_lexicons']\n","for d in directory:\n","    for filename in os.listdir(d):\n","        with open(d + \"/\" + filename, encoding=\"mac_roman\") as lexicons:\n","            if filename.startswith(\".\"):\n","                    continue\n","            wordlist = lexicons.read().splitlines()\n","            output = generate_random_strings_from_wordlist(wordlist, num_strings=5)\n","            filename = filename[:-4] if filename.endswith(\".txt\") else filename\n","            write_to_csv(output[0], output[1], filename)\n","\n","# manually appended output.csv to test_chat_level.csv"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":2}
