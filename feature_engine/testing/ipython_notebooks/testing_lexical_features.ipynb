{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexicon Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import re\n",
    "import os,glob\n",
    "\n",
    "\"\"\"\n",
    "file: lexical_features.py\n",
    "---\n",
    "Defines features that involve bag-of-words counts from a lexicon.\n",
    "\"\"\"\n",
    "\n",
    "'''\n",
    "function: get_lexicon_list_from_txt\n",
    "\n",
    "Takes in a .txt file, in which each line is a lexicon term, and reads it into a list.\n",
    "\n",
    "@param txt_file: name of the text file\n",
    "'''\n",
    "def get_lexicon_list_from_txt(txt_file):\n",
    "\twith open(txt_file) as lexicon:\n",
    "\t\t# return list of each word\n",
    "\n",
    "\t\t'''\n",
    "\t\tThis list comprehension is a bit complicated, since it embeds some preprocessing.\n",
    "\t\t- What we really want to do is return line.rstrip(). However, we have to also do the following:\n",
    "\t\t- We want to capture each word, so we have to append the string start (^) and string end ($) characters\n",
    "\t\t- We have to replace any cases where \"**\" occurs, as python throws an error\n",
    "\t\t- The escape character, backslash, also breaks python's regex , so we have to remove it\n",
    "\t\t'''\n",
    "\t\treturn([\"^\" + re.sub(\"\\\\\\\\\", \"\", re.sub(\"\\*\", \".\\*\", re.sub(\"\\*\\*\", \"\\*\", line.rstrip()))) + \"$\" for line in lexicon])\n",
    "\n",
    "'''\n",
    "function: get_lexical_value_from_text\n",
    "\n",
    "Takes in a lexicon list, and returns the number of matches within a given message or string.\n",
    "\n",
    "@param text: the message/text that we are searching for lexicon words in.\n",
    "@param lexicon_list: output of `get_lexicon_list_from_text`; a list of regexes or words that \n",
    "we are searching for inside the text.\n",
    "'''\n",
    "def get_lexical_value_from_text(text, lexicon_list):\n",
    "\n",
    "\t# preprocess to remove special characters\n",
    "\t# TODO -- remove any feature-level preprocessing, as we are combining them into preprocess.py\n",
    "\ttext = re.sub('[^a-zA-Z ]+', '', text).lower()\n",
    "\n",
    "\t# Finds all matches from the lexicon, and flattens into a single list\n",
    "\tmatches = list(itertools.chain(*[re.findall(regex, word) for word in text.split(' ') for regex in lexicon_list]))\n",
    "\treturn(len(matches))\n",
    "\n",
    "\"\"\"\n",
    "LIWC Features\n",
    "\n",
    "Create features drawn from the LIWC lexicons.\n",
    "\n",
    "@ param text: the text being evaluated.\n",
    "@ return value: a dictionary, in which each key is the name of the feature, and each value\n",
    "is the leixcal value (count) within the text.\n",
    "\"\"\"\n",
    "def liwc_features(text):\n",
    "\n",
    "\tlexical_feature_dictionary = {}\n",
    "\n",
    "\t# Open every file in the folder\n",
    "\tdirectory = 'features/lexicons/liwc_lexicons/'\n",
    "\tfor filename in os.listdir(directory):\n",
    "\t\tlexicon_list = get_lexicon_list_from_txt(directory + filename)\n",
    "\t\tlexical_value = get_lexical_value_from_text(text, lexicon_list)\n",
    "\t\tlexical_feature_dictionary[filename] = lexical_value\n",
    "\n",
    "\treturn(lexical_feature_dictionary)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_num</th>\n",
       "      <th>round_num</th>\n",
       "      <th>speaker_hash</th>\n",
       "      <th>speaker_nickname</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>message</th>\n",
       "      <th>majority_pct</th>\n",
       "      <th>num_flipped</th>\n",
       "      <th>flipped_pct</th>\n",
       "      <th>num_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5e7e1e0031f4e454e196c30b</td>\n",
       "      <td>niceRhino</td>\n",
       "      <td>2020-04-20T18:27:20.125Z</td>\n",
       "      <td>Hello!</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5e31d6e4e31c5304c46f1413</td>\n",
       "      <td>culturedCow</td>\n",
       "      <td>2020-04-20T18:27:23.764Z</td>\n",
       "      <td>Hi!</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5e7e4f4c31f4e454e196c9c4</td>\n",
       "      <td>spryBison</td>\n",
       "      <td>2020-04-20T18:27:27.724Z</td>\n",
       "      <td>Hello</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5d482ea421c9be351f762255</td>\n",
       "      <td>youngLion</td>\n",
       "      <td>2020-04-20T18:27:30.410Z</td>\n",
       "      <td>Hi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5e84cc3c50f6e364321d6265</td>\n",
       "      <td>smallGiraffe</td>\n",
       "      <td>2020-04-20T18:27:35.506Z</td>\n",
       "      <td>hi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_num  round_num              speaker_hash speaker_nickname  \\\n",
       "0          0          0  5e7e1e0031f4e454e196c30b        niceRhino   \n",
       "1          0          0  5e31d6e4e31c5304c46f1413      culturedCow   \n",
       "2          0          0  5e7e4f4c31f4e454e196c9c4        spryBison   \n",
       "3          0          0  5d482ea421c9be351f762255        youngLion   \n",
       "4          0          0  5e84cc3c50f6e364321d6265     smallGiraffe   \n",
       "\n",
       "                  timestamp  message  majority_pct  num_flipped  flipped_pct  \\\n",
       "0  2020-04-20T18:27:20.125Z  Hello!            1.0            1     0.333333   \n",
       "1  2020-04-20T18:27:23.764Z      Hi!           1.0            1     0.333333   \n",
       "2  2020-04-20T18:27:27.724Z    Hello           1.0            1     0.333333   \n",
       "3  2020-04-20T18:27:30.410Z       Hi           1.0            1     0.333333   \n",
       "4  2020-04-20T18:27:35.506Z       hi           1.0            1     0.333333   \n",
       "\n",
       "   num_votes  \n",
       "0          3  \n",
       "1          3  \n",
       "2          3  \n",
       "3          3  \n",
       "4          3  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/raw_data/juries_tiny_for_testing.csv\")\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_num</th>\n",
       "      <th>round_num</th>\n",
       "      <th>speaker_nickname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>173</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>175</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>175</td>\n",
       "      <td>3</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>177</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>177</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>348 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     batch_num  round_num  speaker_nickname\n",
       "0            0          0                52\n",
       "1            0          2                45\n",
       "2            1          0                44\n",
       "3            1          3                42\n",
       "4            2          2                48\n",
       "..         ...        ...               ...\n",
       "343        173          2                28\n",
       "344        175          1                96\n",
       "345        175          3               102\n",
       "346        177          2                54\n",
       "347        177          3                64\n",
       "\n",
       "[348 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_data = pd.read_csv(\"data/raw_data/jury_conversations_with_outcome_var.csv\")\n",
    "big_data.groupby(by=[\"batch_num\", \"round_num\"]).count().iloc[:, 1].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.742268041237113"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_messages = []\n",
    "for message in data[\"message\"].str.split(\" \"):\n",
    "    len_messages.append(len(message))\n",
    "sum(len_messages)/len(len_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(\"features/lexicons/liwc_lexicons/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical_feature_dictionary = {}\n",
    "for filename in os.listdir(\"features/lexicons/liwc_lexicons/\"):\n",
    "    filepath = \"features/lexicons/liwc_lexicons/\"+filename\n",
    "    lexicon_list = get_lexicon_list_from_txt(filepath)\n",
    "    lexical_value = get_lexical_value_from_text('Hello! How are you?', lexicon_list)\n",
    "    lexical_feature_dictionary[filename] = lexical_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149.64705882352942"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_lex = []\n",
    "for filename in os.listdir(\"features/lexicons/liwc_lexicons/\"):\n",
    "    filepath = \"features/lexicons/liwc_lexicons/\"+filename\n",
    "    lexicon_list = get_lexicon_list_from_txt(filepath)\n",
    "    len_lex.append(len(lexicon_list))\n",
    "sum(len_lex)/len(len_lex)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lexical_value_from_text('Hello! How are you?', get_lexicon_list_from_txt(\"features/lexicons/liwc_lexicons/\"+\"social\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello how are you'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Hello! How are you?\"\n",
    "text = re.sub('[^a-zA-Z ]+', '', text).lower()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_list = get_lexicon_list_from_txt(\"features/lexicons/liwc_lexicons/\"+\"social\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^hello.*$ hello ['hello']\n",
      "^you$ you ['you']\n"
     ]
    }
   ],
   "source": [
    "for word in text.split(\" \"):\n",
    "    for regex in lexicon_list:\n",
    "        if re.search(regex, word):\n",
    "            print(regex, word, re.findall(regex, word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_regex = \"|\".join(lexicon_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"^acquainta.*$|^gives$|^persons$|^admit$|^giving$|^person's$|^admits$|^gossip.*$|^persua.*$|^admitted$|^grandchil.*$|^phone.*$|^admitting$|^granddad.*$|^phoning$|^adult$|^granddau.*$|^prais.*$|^adults$|^grandf.*$|^private$|^advice$|^grandkid.*$|^provide$|^advis.*$|^grandm.*$|^public$|^affair.*$|^grandpa.*$|^question.*$|^amigo.*$|^grandson.*$|^reassur.*$|^anybod.*$|^granny$|^receiv.*$|^anyone.*$|^group.*$|^refus.*$|^apolog.*$|^grownup.*$|^relationship.*$|^argu.*$|^grudge.*$|^relatives$|^armies$|^guest.*$|^replie.*$|^army$|^guy.*$|^reply.*$|^ask$|^he$|^request.*$|^asked$|^hear$|^respond.*$|^asking$|^heard$|^role.*$|^asks$|^hearing$|^roomate.*$|^assembl.*$|^hears$|^roomed$|^aunt.*$|^hed$|^roomie.*$|^babe.*$|^he'd$|^rooming$|^babies$|^he'll$|^roommate.*$|^baby.*$|^hello.*$|^rumor.*$|^bambino.*$|^help$|^rumour.*$|^band$|^helper.*$|^said$|^bands$|^helpful.*$|^say.*$|^bf.*$|^helping$|^secret$|^blam.*$|^helps$|^secretive.*$|^boy$|^her$|^secrets$|^boyf.*$|^hers$|^self$|^boy's$|^herself$|^send.*$|^boys.*$|^hes$|^sent$|^bro$|^he's$|^share$|^bros$|^hey$|^shared$|^brother.*$|^hi$|^shares$|^bud$|^him$|^sharing$|^buddies.*$|^himself$|^she$|^buddy.*$|^his$|^she'd$|^bye$|^honey$|^she'll$|^call$|^hubby$|^shes$|^called$|^human.*$|^she's$|^caller.*$|^husband.*$|^sir$|^calling$|^individual.*$|^sis$|^calls$|^infant$|^sister.*$|^captain$|^infant's$|^social.*$|^celebrat.*$|^infants.*$|^societ.*$|^cell$|^inform$|^somebod.*$|^cellphon.*$|^informs$|^someone.*$|^cells$|^insult.*$|^son$|^cellular.*$|^interact.*$|^sons$|^chat.*$|^interrup.*$|^son's$|^chick$|^interview.*$|^soulmate.*$|^chick'.*$|^involv.*$|^speak$|^chicks$|^kid$|^speaking$|^child$|^kid'.*$|^speaks$|^children.*$|^kidding$|^spoke.*$|^child's$|^kids.*$|^spous.*$|^citizen$|^kin$|^stepchild.*$|^citizen'.*$|^ladies$|^stepfat.*$|^citizens$|^lady$|^stepkid.*$|^colleague.*$|^lady's$|^stepmot.*$|^comment.*$|^language.*$|^stories$|^commun.*$|^lets$|^story$|^companion$|^let's$|^suggest.*$|^companions$|^letter$|^sweetheart.*$|^companionship.*$|^listen$|^sweetie.*$|^compassion.*$|^listened$|^talk$|^complain.*$|^listener.*$|^talkative.*$|^comrad.*$|^listening$|^talked$|^confess.*$|^listens$|^talker.*$|^confide$|^love$|^talking$|^confided$|^loved$|^talks$|^confides$|^lover.*$|^team.*$|^confiding$|^loves$|^teas.*$|^congregat.*$|^loving.*$|^telephon.*$|^consult.*$|^ma$|^tell$|^contact.*$|^ma'am$|^telling$|^contradic.*$|^mail$|^tells$|^convers.*$|^mailed$|^thee$|^counc.*$|^mailer.*$|^their.*$|^couns.*$|^mailing$|^them$|^cousin.*$|^mails$|^themselves$|^coworker.*$|^male$|^they$|^crowd.*$|^males$|^theyd$|^cultur.*$|^male's$|^they'd$|^dad.*$|^mam$|^theyll$|^dating$|^man$|^they'll$|^daughter.*$|^man's$|^theyre$|^deal$|^marriag.*$|^they're$|^describe$|^marrie.*$|^theyve$|^described$|^ma's$|^they've$|^describes$|^mate$|^thine$|^describing$|^mates$|^thou$|^disclo.*$|^mate's$|^thoust$|^discuss.*$|^mating$|^thy$|^divorc.*$|^meet$|^told$|^email$|^meeting.*$|^transact.*$|^email'.*$|^meets$|^uncle$|^emailed$|^members$|^uncles$|^emailer.*$|^men$|^uncle's$|^emailing$|^men'.*$|^ur$|^emails$|^mention.*$|^us$|^encourag.*$|^messag.*$|^visit.*$|^enemie.*$|^met$|^we$|^enemy.*$|^mob$|^wed$|^everybod.*$|^mobb.*$|^we'd$|^everyone.*$|^mobs$|^wedding.*$|^everything.*$|^mom$|^weds$|^ex$|^momma.*$|^welcom.*$|^exbf.*$|^mommy.*$|^we'll$|^exboyfriend.*$|^moms$|^we're$|^excus.*$|^mom's$|^weve$|^exes$|^mother$|^we've$|^exgf.*$|^motherly$|^who$|^exgirl.*$|^mothers$|^whod$|^exhubby.*$|^mr$|^who'd$|^exhusband.*$|^mrs$|^wholl$|^explain$|^mum$|^who'll$|^explained$|^mummy.*$|^whom$|^explaining$|^mums$|^whos$|^explains$|^mum's$|^who's$|^express.*$|^name$|^whose$|^exwife.*$|^negotiat.*$|^wife.*$|^exwive.*$|^neighbor.*$|^willing$|^families.*$|^neighbour.*$|^wive.*$|^family$|^nephew.*$|^woman$|^father.*$|^newborn.*$|^womanhood$|^fellow.*$|^niece.*$|^womanly$|^female.*$|^offer.*$|^woman's$|^feud.*$|^organiz.*$|^women.*$|^fiance.*$|^our$|^write$|^fight.*$|^ours$|^writing$|^flatter.*$|^ourselves$|^wrote$|^folks$|^outsider.*$|^ya$|^forgave$|^overhear.*$|^yall$|^forgiv.*$|^owner.*$|^y'all$|^fought$|^pa$|^ye$|^friend.*$|^pal$|^you$|^game.*$|^pals$|^youd$|^gather.*$|^pappy$|^you'd$|^gave$|^parent.*$|^youll$|^gentlem.*$|^participant.*$|^you'll$|^gf.*$|^participat.*$|^your$|^girl$|^partie.*$|^youre$|^girlfriend.*$|^partner.*$|^you're$|^girl's$|^party.*$|^yours$|^girls.*$|^pa's$|^youve$|^give$|^people.*$|^you've$|^giver.*$|^person$|^personal$\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = 0\n",
    "for word in text.split(\" \"):\n",
    "    if re.search(master_regex, word):\n",
    "        value+=1\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_regex_new = master_regex.replace(\"^\", \"\").replace(\"$\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"acquainta.*|gives|persons|admit|giving|person's|admits|gossip.*|persua.*|admitted|grandchil.*|phone.*|admitting|granddad.*|phoning|adult|granddau.*|prais.*|adults|grandf.*|private|advice|grandkid.*|provide|advis.*|grandm.*|public|affair.*|grandpa.*|question.*|amigo.*|grandson.*|reassur.*|anybod.*|granny|receiv.*|anyone.*|group.*|refus.*|apolog.*|grownup.*|relationship.*|argu.*|grudge.*|relatives|armies|guest.*|replie.*|army|guy.*|reply.*|ask|he|request.*|asked|hear|respond.*|asking|heard|role.*|asks|hearing|roomate.*|assembl.*|hears|roomed|aunt.*|hed|roomie.*|babe.*|he'd|rooming|babies|he'll|roommate.*|baby.*|hello.*|rumor.*|bambino.*|help|rumour.*|band|helper.*|said|bands|helpful.*|say.*|bf.*|helping|secret|blam.*|helps|secretive.*|boy|her|secrets|boyf.*|hers|self|boy's|herself|send.*|boys.*|hes|sent|bro|he's|share|bros|hey|shared|brother.*|hi|shares|bud|him|sharing|buddies.*|himself|she|buddy.*|his|she'd|bye|honey|she'll|call|hubby|shes|called|human.*|she's|caller.*|husband.*|sir|calling|individual.*|sis|calls|infant|sister.*|captain|infant's|social.*|celebrat.*|infants.*|societ.*|cell|inform|somebod.*|cellphon.*|informs|someone.*|cells|insult.*|son|cellular.*|interact.*|sons|chat.*|interrup.*|son's|chick|interview.*|soulmate.*|chick'.*|involv.*|speak|chicks|kid|speaking|child|kid'.*|speaks|children.*|kidding|spoke.*|child's|kids.*|spous.*|citizen|kin|stepchild.*|citizen'.*|ladies|stepfat.*|citizens|lady|stepkid.*|colleague.*|lady's|stepmot.*|comment.*|language.*|stories|commun.*|lets|story|companion|let's|suggest.*|companions|letter|sweetheart.*|companionship.*|listen|sweetie.*|compassion.*|listened|talk|complain.*|listener.*|talkative.*|comrad.*|listening|talked|confess.*|listens|talker.*|confide|love|talking|confided|loved|talks|confides|lover.*|team.*|confiding|loves|teas.*|congregat.*|loving.*|telephon.*|consult.*|ma|tell|contact.*|ma'am|telling|contradic.*|mail|tells|convers.*|mailed|thee|counc.*|mailer.*|their.*|couns.*|mailing|them|cousin.*|mails|themselves|coworker.*|male|they|crowd.*|males|theyd|cultur.*|male's|they'd|dad.*|mam|theyll|dating|man|they'll|daughter.*|man's|theyre|deal|marriag.*|they're|describe|marrie.*|theyve|described|ma's|they've|describes|mate|thine|describing|mates|thou|disclo.*|mate's|thoust|discuss.*|mating|thy|divorc.*|meet|told|email|meeting.*|transact.*|email'.*|meets|uncle|emailed|members|uncles|emailer.*|men|uncle's|emailing|men'.*|ur|emails|mention.*|us|encourag.*|messag.*|visit.*|enemie.*|met|we|enemy.*|mob|wed|everybod.*|mobb.*|we'd|everyone.*|mobs|wedding.*|everything.*|mom|weds|ex|momma.*|welcom.*|exbf.*|mommy.*|we'll|exboyfriend.*|moms|we're|excus.*|mom's|weve|exes|mother|we've|exgf.*|motherly|who|exgirl.*|mothers|whod|exhubby.*|mr|who'd|exhusband.*|mrs|wholl|explain|mum|who'll|explained|mummy.*|whom|explaining|mums|whos|explains|mum's|who's|express.*|name|whose|exwife.*|negotiat.*|wife.*|exwive.*|neighbor.*|willing|families.*|neighbour.*|wive.*|family|nephew.*|woman|father.*|newborn.*|womanhood|fellow.*|niece.*|womanly|female.*|offer.*|woman's|feud.*|organiz.*|women.*|fiance.*|our|write|fight.*|ours|writing|flatter.*|ourselves|wrote|folks|outsider.*|ya|forgave|overhear.*|yall|forgiv.*|owner.*|y'all|fought|pa|ye|friend.*|pal|you|game.*|pals|youd|gather.*|pappy|you'd|gave|parent.*|youll|gentlem.*|participant.*|you'll|gf.*|participat.*|your|girl|partie.*|youre|girlfriend.*|partner.*|you're|girl's|party.*|yours|girls.*|pa's|youve|give|people.*|you've|giver.*|person|personal\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_regex_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(re.findall(master_regex_new, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'discrepancies': 0,\n",
       " 'hear': 0,\n",
       " 'home': 0,\n",
       " 'conjunction': 1,\n",
       " 'certainty': 0,\n",
       " 'inclusive': 0,\n",
       " 'bio': 0,\n",
       " 'achievement': 0,\n",
       " 'adverbs': 1,\n",
       " 'anxiety': 0,\n",
       " 'third_person': 0,\n",
       " 'negation': 0,\n",
       " 'swear': 0,\n",
       " 'death': 0,\n",
       " 'health': 0,\n",
       " 'see': 0,\n",
       " 'body': 0,\n",
       " 'family': 0,\n",
       " 'negative_affect': 0,\n",
       " 'quantifier': 0,\n",
       " 'positive_affect': 0,\n",
       " 'insight': 0,\n",
       " 'humans': 0,\n",
       " 'present_tense': 1,\n",
       " 'future_tense': 0,\n",
       " 'past_tense': 0,\n",
       " 'relative': 0,\n",
       " 'sexual': 0,\n",
       " 'inhibition': 0,\n",
       " 'sadness': 0,\n",
       " 'social': 2,\n",
       " 'indefinite_pronoun': 0,\n",
       " 'religion': 0,\n",
       " 'work': 0,\n",
       " 'money': 0,\n",
       " 'causation': 1,\n",
       " 'anger': 0,\n",
       " 'first_person_singular': 0,\n",
       " 'feel': 0,\n",
       " 'tentativeness': 0,\n",
       " 'exclusive': 0,\n",
       " 'verbs': 1,\n",
       " 'friends': 0,\n",
       " 'article': 0,\n",
       " 'argue': 0,\n",
       " 'auxiliary_verbs': 1,\n",
       " 'cognitive_mech': 1,\n",
       " 'preposition': 0,\n",
       " 'first_person_plural': 0,\n",
       " 'percept': 0,\n",
       " 'second_person': 1}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_feature_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! '"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0, list(data.columns).index(\"message\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>discrepancies</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hear</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conjunction</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>certainty</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inclusive</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bio</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>achievement</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adverbs</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anxiety</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>third_person</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negation</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swear</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>death</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>see</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative_affect</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantifier</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive_affect</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insight</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humans</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>present_tense</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>future_tense</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>past_tense</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sexual</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inhibition</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>social</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indefinite_pronoun</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>religion</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>causation</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_person_singular</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feel</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tentativeness</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exclusive</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verbs</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>friends</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>argue</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auxiliary_verbs</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cognitive_mech</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preposition</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_person_plural</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percept</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second_person</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       message\n",
       "discrepancies                0\n",
       "hear                         0\n",
       "home                         0\n",
       "conjunction                  0\n",
       "certainty                    0\n",
       "inclusive                    0\n",
       "bio                          0\n",
       "achievement                  0\n",
       "adverbs                      0\n",
       "anxiety                      0\n",
       "third_person                 0\n",
       "negation                     0\n",
       "swear                        0\n",
       "death                        0\n",
       "health                       0\n",
       "see                          0\n",
       "body                         0\n",
       "family                       0\n",
       "negative_affect              0\n",
       "quantifier                   0\n",
       "positive_affect              0\n",
       "insight                      0\n",
       "humans                       0\n",
       "present_tense                0\n",
       "future_tense                 0\n",
       "past_tense                   0\n",
       "relative                     0\n",
       "sexual                       0\n",
       "inhibition                   0\n",
       "sadness                      0\n",
       "social                       1\n",
       "indefinite_pronoun           0\n",
       "religion                     0\n",
       "work                         0\n",
       "money                        0\n",
       "causation                    0\n",
       "anger                        0\n",
       "first_person_singular        0\n",
       "feel                         0\n",
       "tentativeness                0\n",
       "exclusive                    0\n",
       "verbs                        0\n",
       "friends                      0\n",
       "article                      0\n",
       "argue                        0\n",
       "auxiliary_verbs              0\n",
       "cognitive_mech               0\n",
       "preposition                  0\n",
       "first_person_plural          0\n",
       "percept                      0\n",
       "second_person                0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0, [list(data.columns).index(\"message\")]].apply(lambda x: pd.Series(liwc_features(str(x)))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "team_process_map",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4308115ec36d55d4bd05e5164490d17bc30a5f7275b0a0d4f3922ff237a9eaea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
