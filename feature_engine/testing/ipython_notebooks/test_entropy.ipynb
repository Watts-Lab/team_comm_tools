{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get priors using the previous conversations. and try to check how \n",
    "\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy.stats import entropy\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk import ngrams\n",
    "from collections import Counter\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "from nltk.tokenize import word_tokenize\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get priors using the previous conversations. and try to check how \n",
    "\n",
    "def ngram_dialog_act_entropy(df,on_column,n,set1,set2,set1_label,set2_label):\n",
    "\n",
    "    # Initialize count vectorizer - this will extract ngrams from 1 to n (this covers maximum words/combinations possible)\n",
    "    vectorizer = CountVectorizer(vocabulary=set1+set2)\n",
    "    print(vectorizer)\n",
    "\n",
    "    # Count occurrences of words in each bag. \n",
    "    #Each row of the matrix corresponds to a chat\n",
    "    # and each column corresponds to a word or n-gram from the vocabulary.\n",
    "    X = vectorizer.fit_transform(df[on_column])\n",
    "    \n",
    "    #convert sparse matrix to dense matrix\n",
    "    X_dense = X.toarray() \n",
    "    \n",
    "    #get the counts of the words in the matrix\n",
    "    set1_counts = [row[:len(set1)] for row in X_dense]\n",
    "    set2_counts = [row[-len(set2):] for row in X_dense]\n",
    "\n",
    "    #Structure Set 1 - 0 3 1 - means  sentence 1 has 0 words from set 1, sentence 2 has 3 words, sentence 3 has 1 word \n",
    "    set1_totals = np.sum(set1_counts,axis = 1)\n",
    "    set2_totals = np.sum(set2_counts,axis = 1)\n",
    "    \n",
    "    # Normalize counts to obtain probabilities\n",
    "    set1_probs = set1_totals/np.sum(set1_totals)\n",
    "    set2_probs = set2_totals/np.sum(set2_totals)\n",
    "\n",
    "    #create an input matrix for the scikit entropy function\n",
    "    entropy_matrix = []\n",
    "\n",
    "    for i in range(len(set1_probs)):\n",
    "        #create the array\n",
    "        sentence_array = np.array([set1_probs[i],set2_probs[i]])\n",
    "\n",
    "        probability = np.array(sentence_array)  \n",
    "        entropy_val = entropy(probability, base=2)\n",
    "        entropy_matrix.append(entropy_val)\n",
    "\n",
    "        df.at[i,\"entropy\"] = entropy_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(vocabulary=['happy', 'joyful', 'lovely', 'nice', 'bad'])\n",
      "0    0.000000\n",
      "1    0.000000\n",
      "2    0.918296\n",
      "Name: entropy, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Test for entropy \n",
    "data = {\n",
    "    \"name\": [\"you are a bad person\",\"You are a happy, joyful, lovely person\", \"you are nice and weird and bad\"]\n",
    "}\n",
    "\n",
    "# \n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "set1 = [\"happy\", \"joyful\", \"lovely\",\"nice\"]\n",
    "set2 = [\"bad\"]\n",
    "\n",
    "ngram_dialog_act_entropy(df,'name',1,set1,set2,'positive','negative')\n",
    "print(df[\"entropy\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
