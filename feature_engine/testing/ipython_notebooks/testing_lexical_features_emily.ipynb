{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'raw_message': [\n",
    "        'hello',\n",
    "        'hi', # for some reason this triggers really large values in things like 'bio' and 'cognitive mech'\n",
    "        'hi!',\n",
    "        'I am happy today', # first_person is always 0\n",
    "        'i am good', # first_person is always 0\n",
    "        '()()()()', # all symbols leads to the regex returning len(regex),\n",
    "        ':-|', # another all symbol one\n",
    "        'I think perhaps this is maybe fine', # hedge words\n",
    "        'who what when where why',\n",
    "        'I am good happy wonderful great excellent', # lots of positive words\n",
    "        'under the sea and above the waves', # prepositions,\n",
    "        'i can see how the family is upset because they feel the mother was disrespected but i can also understand the guy\\'s feelings. why should he have to work as interpreter for his mother in law?', # TODO - weirdly, the outputs in the real thing differ from the outputs in the test here...\n",
    "        'i was conflicted because i could understand his frustration however i feel he should have maybe discussed strategies with how to approach the mother in law with his wife first.'\n",
    "    ]\n",
    "}\n",
    "\n",
    "def preprocess_text(text):\n",
    "  \t# For each individual message: preprocess to remove anything that is not an alphabet or number from the string\n",
    "\treturn(re.sub(r\"[^a-zA-Z0-9 ]+\", '',text).lower())\n",
    "\n",
    "chat_df = pd.DataFrame(data)\n",
    "\n",
    "chat_df[\"message\"] = chat_df[\"raw_message\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_message</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hello</td>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hi</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hi!</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I am happy today</td>\n",
       "      <td>i am happy today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am good</td>\n",
       "      <td>i am good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>()()()()</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>:-|</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I think perhaps this is maybe fine</td>\n",
       "      <td>i think perhaps this is maybe fine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>who what when where why</td>\n",
       "      <td>who what when where why</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I am good happy wonderful great excellent</td>\n",
       "      <td>i am good happy wonderful great excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>under the sea and above the waves</td>\n",
       "      <td>under the sea and above the waves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>i can see how the family is upset because they...</td>\n",
       "      <td>i can see how the family is upset because they...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>i was conflicted because i could understand hi...</td>\n",
       "      <td>i was conflicted because i could understand hi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          raw_message   \n",
       "0                                               hello  \\\n",
       "1                                                  hi   \n",
       "2                                                 hi!   \n",
       "3                                    I am happy today   \n",
       "4                                           i am good   \n",
       "5                                            ()()()()   \n",
       "6                                                 :-|   \n",
       "7                  I think perhaps this is maybe fine   \n",
       "8                             who what when where why   \n",
       "9           I am good happy wonderful great excellent   \n",
       "10                  under the sea and above the waves   \n",
       "11  i can see how the family is upset because they...   \n",
       "12  i was conflicted because i could understand hi...   \n",
       "\n",
       "                                              message  \n",
       "0                                               hello  \n",
       "1                                                  hi  \n",
       "2                                                  hi  \n",
       "3                                    i am happy today  \n",
       "4                                           i am good  \n",
       "5                                                      \n",
       "6                                                      \n",
       "7                  i think perhaps this is maybe fine  \n",
       "8                             who what when where why  \n",
       "9           i am good happy wonderful great excellent  \n",
       "10                  under the sea and above the waves  \n",
       "11  i can see how the family is upset because they...  \n",
       "12  i was conflicted because i could understand hi...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../features/lexicons_dict.pkl\", \"rb\") as lexicons_pickle_file:\n",
    "    lexicons_dict = pickle.load(lexicons_pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.concat(\n",
    "\t\t# Finding the # of occurances of lexicons of each type for all the messages.\n",
    "\t\t[pd.DataFrame(chat_df[\"message\"].apply(lambda chat: len(re.findall(regex, chat))))\\\n",
    "\t\t\t  \t\t\t\t\t\t\t.rename({\"message\": lexicon_type}, axis=1)\\\n",
    "\t\t\tfor lexicon_type, regex in lexicons_dict.items()], \n",
    "\t\taxis=1\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discrepancies</th>\n",
       "      <th>hear</th>\n",
       "      <th>home</th>\n",
       "      <th>conjunction</th>\n",
       "      <th>certainty</th>\n",
       "      <th>inclusive</th>\n",
       "      <th>bio</th>\n",
       "      <th>achievement</th>\n",
       "      <th>adverbs</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>...</th>\n",
       "      <th>auxiliary_verbs</th>\n",
       "      <th>cognitive_mech</th>\n",
       "      <th>preposition</th>\n",
       "      <th>first_person_plural</th>\n",
       "      <th>percept</th>\n",
       "      <th>second_person</th>\n",
       "      <th>positive_words</th>\n",
       "      <th>first_person</th>\n",
       "      <th>nltk_english_stopwords</th>\n",
       "      <th>hedge_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    discrepancies  hear  home  conjunction  certainty  inclusive  bio   \n",
       "0               0     0     0            0          0          0    0  \\\n",
       "1               0     0     0            0          0          0    0   \n",
       "2               0     0     0            0          0          0    0   \n",
       "3               0     0     0            0          0          0    0   \n",
       "4               0     0     0            0          0          0    0   \n",
       "5               0     0     0            0          0          0    0   \n",
       "6               0     0     0            0          0          0    0   \n",
       "7               0     0     0            0          0          0    0   \n",
       "8               0     0     0            1          0          0    0   \n",
       "9               0     0     0            0          0          0    0   \n",
       "10              0     0     0            1          0          1    0   \n",
       "11              1     0     1            5          0          0    1   \n",
       "12              2     0     0            3          0          2    2   \n",
       "\n",
       "    achievement  adverbs  anxiety  ...  auxiliary_verbs  cognitive_mech   \n",
       "0             0        0        0  ...                0               0  \\\n",
       "1             0        0        0  ...                0               0   \n",
       "2             0        0        0  ...                0               0   \n",
       "3             0        0        0  ...                1               0   \n",
       "4             0        0        0  ...                1               0   \n",
       "5             0        0        0  ...                0               0   \n",
       "6             0        0        0  ...                0               0   \n",
       "7             0        2        0  ...                2               3   \n",
       "8             0        1        0  ...                0               1   \n",
       "9             2        0        0  ...                1               1   \n",
       "10            0        0        0  ...                0               1   \n",
       "11            1        2        1  ...                7              10   \n",
       "12            2        3        0  ...                6              12   \n",
       "\n",
       "    preposition  first_person_plural  percept  second_person  positive_words   \n",
       "0             0                    0        0              0               0  \\\n",
       "1             0                    0        0              0               0   \n",
       "2             0                    0        0              0               0   \n",
       "3             1                    0        0              0               2   \n",
       "4             0                    0        0              0               2   \n",
       "5             0                    0        0              0               0   \n",
       "6             0                    0        0              0               0   \n",
       "7             0                    0        1              0               1   \n",
       "8             0                    0        0              0               0   \n",
       "9             0                    0        0              0               6   \n",
       "10            2                    0        0              1               2   \n",
       "11            7                    0        3              2               3   \n",
       "12            5                    0        1              1               1   \n",
       "\n",
       "    first_person  nltk_english_stopwords  hedge_words  \n",
       "0              0                       1            0  \n",
       "1              0                       0            0  \n",
       "2              0                       0            0  \n",
       "3              1                       3            0  \n",
       "4              1                       2            0  \n",
       "5              0                       0            0  \n",
       "6              0                       0            0  \n",
       "7              2                       5            1  \n",
       "8              0                       5            0  \n",
       "9              1                       3            0  \n",
       "10             0                       6            0  \n",
       "11             5                      30            0  \n",
       "12             4                      23            1  \n",
       "\n",
       "[13 rows x 55 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few potential error cases below --- it seems we are returning more positives than necessary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'is', 'i', 'interpreter', 'in']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seems a bunch of false positives in the first person\n",
    "re.findall(lexicons_dict[\"first_person\"], \"i can see how the family is upset because they feel the mother was disrespected but i can also understand the guy\\'s feelings. why should he have to work as interpreter for his mother in law?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'can',\n",
       " 'see',\n",
       " 'how',\n",
       " 'the',\n",
       " 'is',\n",
       " 'upset',\n",
       " 'because',\n",
       " 'they',\n",
       " 'the',\n",
       " 'mother',\n",
       " 'was',\n",
       " 'disrespected',\n",
       " 'but',\n",
       " 'i',\n",
       " 'can',\n",
       " 'also',\n",
       " 'understand',\n",
       " 'the',\n",
       " 's',\n",
       " 'why',\n",
       " 'should',\n",
       " 'he',\n",
       " 'have',\n",
       " 'to',\n",
       " 'as',\n",
       " 'interpreter',\n",
       " 'for',\n",
       " 'his',\n",
       " 'mother',\n",
       " 'in']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(lexicons_dict[\"nltk_english_stopwords\"], \"i can see how the family is upset because they feel the mother was disrespected but i can also understand the guy\\'s feelings. why should he have to work as interpreter for his mother in law?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '', '', '', '', '', '']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(lexicons_dict[\"cognitive_mech\"], \"i can see how the family is upset because they feel the mother was disrespected but i can also understand the guy\\'s feelings. why should he have to work as interpreter for his mother in law?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['upset', 'understand', 'to', 'as', 'interpreter', 'for', 'in']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(lexicons_dict[\"preposition\"], \"i can see how the family is upset because they feel the mother was disrespected but i can also understand the guy\\'s feelings. why should he have to work as interpreter for his mother in law?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discrepancies             0\n",
       "hear                      0\n",
       "home                      0\n",
       "conjunction               0\n",
       "certainty                 0\n",
       "inclusive                 0\n",
       "bio                       0\n",
       "achievement               0\n",
       "adverbs                   0\n",
       "anxiety                   0\n",
       "third_person              0\n",
       "negation                  0\n",
       "swear                     0\n",
       "death                     0\n",
       "health                    0\n",
       "see                       0\n",
       "body                      0\n",
       "family                    0\n",
       "negative_affect           0\n",
       "quantifier                0\n",
       "positive_affect           1\n",
       "insight                   0\n",
       "humans                    0\n",
       "present_tense             2\n",
       "future_tense              0\n",
       "past_tense                0\n",
       "relative                  1\n",
       "sexual                    0\n",
       "inhibition                0\n",
       "sadness                   0\n",
       "social                    0\n",
       "indefinite_pronoun        0\n",
       "religion                  0\n",
       "work                      0\n",
       "money                     0\n",
       "causation                 0\n",
       "anger                     0\n",
       "first_person_singular     1\n",
       "feel                      0\n",
       "tentativeness             0\n",
       "exclusive                 0\n",
       "verbs                     2\n",
       "friends                   0\n",
       "article                   1\n",
       "argue                     0\n",
       "auxiliary_verbs           1\n",
       "cognitive_mech            0\n",
       "preposition               0\n",
       "first_person_plural       0\n",
       "percept                   0\n",
       "second_person             0\n",
       "positive_words            2\n",
       "first_person              1\n",
       "nltk_english_stopwords    2\n",
       "hedge_words               0\n",
       "Name: 4, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[4, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discrepancies\n",
      "['hi']\n"
     ]
    }
   ],
   "source": [
    "for lexicon_type, regex in lexicons_dict.items():\n",
    "    print(lexicon_type)\n",
    "    text = \"hi\"\n",
    "    search_hits = re.findall(text, regex)\n",
    "    print(search_hits)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\\\bbesides\\\\S*\\\\b|\\\\bcould\\\\S*\\\\b|\\\\bcouldnt\\\\S*\\\\b|\\\\bcouldn't\\\\S*\\\\b|\\\\bcouldve\\\\S*\\\\b|\\\\bcould've\\\\S*\\\\b|\\\\bdesir\\\\S*\\\\b|\\\\bexpect\\\\S*\\\\b|\\\\bhope\\\\S*\\\\b|\\\\bhoped\\\\S*\\\\b|\\\\bhopeful\\\\S*\\\\b|\\\\bhopefully\\\\S*\\\\b|\\\\bhopefulness\\\\S*\\\\b|\\\\bhopes\\\\S*\\\\b|\\\\bhoping\\\\S*\\\\b|\\\\bideal\\\\S*\\\\b|\\\\bif\\\\S*\\\\b|\\\\bimpossib\\\\S*\\\\b|\\\\binadequa\\\\S*\\\\b|\\\\black\\\\S*\\\\b|\\\\bliabilit\\\\S*\\\\b|\\\\bmistak\\\\S*\\\\b|\\\\bmust\\\\S*\\\\b|\\\\bmustnt\\\\S*\\\\b|\\\\bmust'nt\\\\S*\\\\b|\\\\bmustn't\\\\S*\\\\b|\\\\bmustve\\\\S*\\\\b|\\\\bmust've\\\\S*\\\\b|\\\\bneed\\\\S*\\\\b|\\\\bneeded\\\\S*\\\\b|\\\\bneeding\\\\S*\\\\b|\\\\bneednt\\\\S*\\\\b|\\\\bneed'nt\\\\S*\\\\b|\\\\bneedn't\\\\S*\\\\b|\\\\bneeds\\\\S*\\\\b|\\\\bnormal\\\\S*\\\\b|\\\\bought\\\\S*\\\\b|\\\\boughta\\\\S*\\\\b|\\\\boughtnt\\\\S*\\\\b|\\\\bought'nt\\\\S*\\\\b|\\\\boughtn't\\\\S*\\\\b|\\\\boughtve\\\\S*\\\\b|\\\\bought've\\\\S*\\\\b|\\\\boutstanding\\\\S*\\\\b|\\\\bprefer\\\\S*\\\\b|\\\\bproblem\\\\S*\\\\b|\\\\brather\\\\S*\\\\b|\\\\bregardless\\\\S*\\\\b|\\\\bregret\\\\S*\\\\b|\\\\bshould\\\\S*\\\\b|\\\\bshouldnt\\\\S*\\\\b|\\\\bshould'nt\\\\S*\\\\b|\\\\bshouldn't\\\\S*\\\\b|\\\\bshoulds\\\\S*\\\\b|\\\\bshouldve\\\\S*\\\\b|\\\\bshould've\\\\S*\\\\b|\\\\bundesire\\\\S*\\\\b|\\\\bundo\\\\S*\\\\b|\\\\bunneccess\\\\S*\\\\b|\\\\bunneed\\\\S*\\\\b|\\\\bunwant\\\\S*\\\\b|\\\\bwanna\\\\S*\\\\b|\\\\bwant\\\\S*\\\\b|\\\\bwanted\\\\S*\\\\b|\\\\bwanting\\\\S*\\\\b|\\\\bwants\\\\S*\\\\b|\\\\bwish\\\\S*\\\\b|\\\\bwished\\\\S*\\\\b|\\\\bwishes\\\\S*\\\\b|\\\\bwishing\\\\S*\\\\b|\\\\bwould\\\\S*\\\\b|\\\\bwouldnt\\\\S*\\\\b|\\\\bwouldn't\\\\S*\\\\b|\\\\bwouldve\\\\S*\\\\b|\\\\bwould've\\\\S*\\\\b|\\\\byearn\\\\S*\\\\b\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.match(\"hi\", regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(regex, \"hi\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "team_process_map",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4308115ec36d55d4bd05e5164490d17bc30a5f7275b0a0d4f3922ff237a9eaea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
