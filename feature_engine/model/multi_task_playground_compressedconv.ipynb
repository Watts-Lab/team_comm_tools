{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_builder import ModelBuilder\n",
    "from sklearn.linear_model import Lasso, Ridge, LassoCV, RidgeCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import json\n",
    "import os\n",
    "from model_utils import *\n",
    "import scipy.stats as stats \n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Task Modeling Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to prototype the modeling process for the team ingredient horse race project on the multi-task data.\n",
    "\n",
    "For *each task* ...\n",
    "\n",
    "We want to understand the effect of different \"ingredients of a team\" (Composition, Task, and Conversation) on its ultimate performance.\n",
    "\n",
    "Team Composition:\n",
    "- ['birth_year', 'CRT', 'income_max', 'income_min', 'IRCS_GS', 'IRCS_GV', 'IRCS_IB', 'IRCS_IR', 'IRCS_IV', 'IRCS_RS', 'political_fiscal', 'political_social', 'RME', 'country', 'education_level', 'gender', 'marital_status', 'political_party', 'race']\n",
    "- Number of players: 'playerCount'\n",
    "\n",
    "Task Features:\n",
    "- Need to append from the Task Map\n",
    "- ['complexity', 'task']\n",
    "\n",
    "Conversation Features (All)\n",
    "- Everything else that is NOT an ID or a dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Preprocess Data\n",
    "The function below reads in the dataframe and preprocesses each group of features:\n",
    "\n",
    "- Composition\n",
    "- Task\n",
    "- Conversation\n",
    "\n",
    "And also parses out the possible dependent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_invariant_columns(df):\n",
    "    \"\"\"\n",
    "    Certain features are invariant throughout the training data (e.g., the entire column is 0 throughout).\n",
    "\n",
    "    These feature obviously won't be very useful predictors, so we drop them.\n",
    "    \n",
    "    This function works by identifying columns that only have 1 unique value throughout the entire column,\n",
    "    and then dropping them.\n",
    "\n",
    "    @df: the dataframe containing the features (this should be X).\n",
    "    \"\"\"\n",
    "    nunique = df.nunique()\n",
    "    cols_to_drop = nunique[nunique == 1].index\n",
    "    return(df.drop(cols_to_drop, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_preprocess_data(path, min_num_chats):\n",
    "    conv_data  = pd.read_csv(path)\n",
    "\n",
    "    # Fill NA with mean\n",
    "    conv_data.fillna(conv_data.mean(), inplace=True) \n",
    "\n",
    "    # Filter this down to teams that have at least min_num of chats\n",
    "    # Can also comment this out to re-run results on *all* conversations!\n",
    "    conv_data = conv_data[conv_data[\"sum_num_messages\"] >= min_num_chats]\n",
    "\n",
    "\n",
    "    # Save the important information\n",
    "\n",
    "    # DV\n",
    "    dvs = conv_data[[\"score\",\"speed\",\"efficiency\",\"raw_duration_min\",\"default_duration_min\"]]\n",
    "\n",
    "    # Team Composition\n",
    "    composition_colnames = ['birth_year', 'CRT', 'income_max', 'income_min', 'IRCS_GS', 'IRCS_GV', 'IRCS_IB', 'IRCS_IR',\n",
    "                'IRCS_IV', 'IRCS_RS', 'political_fiscal', 'political_social', 'RME', 'country', 'education_level',\n",
    "                'gender', 'marital_status', 'political_party', 'race', 'playerCount']\n",
    "    \n",
    "    # Select columns that contain the specified keywords\n",
    "    composition = conv_data[[col for col in conv_data.columns if any(keyword in col for keyword in composition_colnames)]]\n",
    "\n",
    "    # Task\n",
    "    task = conv_data[['task', 'complexity']].copy()\n",
    "\n",
    "    task_map_path = '../utils/task_map.csv' # get task map\n",
    "    task_map = pd.read_csv(task_map_path)\n",
    "\n",
    "    task_name_mapping = {\n",
    "        \"Moral Reasoning\": \"Moral Reasoning (Disciplinary Action Case)\",\n",
    "        \"Wolf Goat Cabbage\": \"Wolf, goat and cabbage transfer\",\n",
    "        \"Guess the Correlation\": \"Guessing the correlation\",\n",
    "        \"Writing Story\": \"Writing story\",\n",
    "        \"Room Assignment\": \"Room assignment task\",\n",
    "        \"Allocating Resources\": \"Allocating resources to programs\",\n",
    "        \"Divergent Association\": \"Divergent Association Task\",\n",
    "        \"Word Construction\": \"Word construction from a subset of letters\",\n",
    "        \"Whac a Mole\": \"Whac-A-Mole\"\n",
    "    }\n",
    "    task.loc[:, 'task'] = task['task'].replace(task_name_mapping)\n",
    "    task = pd.merge(left=task, right=task_map, on = \"task\", how='left')\n",
    "    \n",
    "    # Create dummy columns for 'complexity'\n",
    "    complexity_dummies = pd.get_dummies(task['complexity'])\n",
    "    task = pd.concat([task, complexity_dummies], axis=1)   \n",
    "    task.drop(['complexity', 'task'], axis=1, inplace=True)\n",
    "\n",
    "    # Conversation\n",
    "    conversation = conv_data.drop(columns=list(dvs.columns) + list(composition.columns) + ['task', 'complexity', 'stageId', 'roundId', 'cumulative_stageId', 'gameId', 'message', 'message_lower_with_punc', 'speaker_nickname', 'conversation_num', 'timestamp'])\n",
    "    conversation = drop_invariant_columns(conversation) # drop invariant conv features\n",
    "\n",
    "    # additional preprocess --- get PC's of conversation to reduce dimensionality issues\n",
    "    pca = PCA(n_components=5)\n",
    "    pca_result = pca.fit_transform(conversation.transform(lambda x: (x - x.mean()) / x.std()))\n",
    "    print(\"PCA explained variance:\")\n",
    "    print(np.sum(pca.explained_variance_ratio_))\n",
    "    conversation = pd.DataFrame(pca_result, columns=[f'PC{i+1}' for i in range(pca_result.shape[1])])\n",
    "\n",
    "    return composition, task, conversation, dvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_multitask = 'conv/multi_task_TINY_output_conversation_level_stageId_cumulative.csv'\n",
    "multitask_cumulative_by_stage = 'conv/multi_task_output_conversation_level_stageId_cumulative.csv'\n",
    "multitask_cumulative_by_stage_and_task = 'conv/multi_task_output_conversation_level_stageId_cumulative_within_task.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "min_num_chats = 0\n",
    "desired_target = \"score\"\n",
    "data_path = \"../output/\"\n",
    "output_path = \"./results/multi_task_cumulative_stage/\" + \"min=\" + str(min_num_chats) + \"/\" + desired_target + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['stageId', 'cumulative_stageId', 'message_lower_with_punc'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gy/yd7v599s1qd49r7p_bgk88lr0000gn/T/ipykernel_51600/1197610138.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mteam_composition_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_and_preprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmultitask_cumulative_by_stage_and_task\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_num_chats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_num_chats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Number of points in dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/gy/yd7v599s1qd49r7p_bgk88lr0000gn/T/ipykernel_51600/3698621750.py\u001b[0m in \u001b[0;36mread_and_preprocess_data\u001b[0;34m(path, min_num_chats)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# Conversation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mconversation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomposition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'task'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'complexity'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stageId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roundId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cumulative_stageId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gameId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'message'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'message_lower_with_punc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'speaker_nickname'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'conversation_num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mconversation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrop_invariant_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconversation\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# drop invariant conv features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5386\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5387\u001b[0m         \"\"\"\n\u001b[0;32m-> 5388\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   5389\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5390\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4503\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4505\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4507\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4544\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4545\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4546\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4547\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6973\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6974\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6975\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{list(labels[mask])} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6976\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6977\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['stageId', 'cumulative_stageId', 'message_lower_with_punc'] not found in axis\""
     ]
    }
   ],
   "source": [
    "team_composition_features, task_features, conv_features, targets = read_and_preprocess_data(data_path + multitask_cumulative_by_stage_and_task, min_num_chats=min_num_chats)\n",
    "\n",
    "# Number of points in dataset\n",
    "len(conv_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(team_composition_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1concept_behav</th>\n",
       "      <th>Q3type_1_planning</th>\n",
       "      <th>Q4type_2_generate</th>\n",
       "      <th>Q6type_5_cc</th>\n",
       "      <th>Q7type_7_battle</th>\n",
       "      <th>Q8type_8_performance</th>\n",
       "      <th>Q9divisible_unitary</th>\n",
       "      <th>Q10maximizing</th>\n",
       "      <th>Q11optimizing</th>\n",
       "      <th>Q13outcome_multip</th>\n",
       "      <th>...</th>\n",
       "      <th>Q22confl_tradeoffs</th>\n",
       "      <th>Q23ss_out_uncert</th>\n",
       "      <th>Q24eureka_question</th>\n",
       "      <th>Q2intel_manip_1</th>\n",
       "      <th>Q21intellective_judg_1</th>\n",
       "      <th>Q5creativity_input_1</th>\n",
       "      <th>Q25_type6_mixed_motive</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.970833</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.970833</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.970833</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.916000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1018 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Q1concept_behav  Q3type_1_planning  Q4type_2_generate  Q6type_5_cc  \\\n",
       "0                 0.0              0.125           0.791667     0.041667   \n",
       "1                 0.0              0.125           0.791667     0.041667   \n",
       "2                 0.0              0.125           0.791667     0.041667   \n",
       "3                 0.0              0.125           0.791667     0.041667   \n",
       "4                 0.0              0.125           0.791667     0.041667   \n",
       "...               ...                ...                ...          ...   \n",
       "1013              0.0              0.375           0.125000     0.130435   \n",
       "1014              0.0              0.375           0.125000     0.130435   \n",
       "1015              0.0              0.375           0.125000     0.130435   \n",
       "1016              0.0              0.125           0.400000     0.360000   \n",
       "1017              0.0              0.750           0.333333     0.083333   \n",
       "\n",
       "      Q7type_7_battle  Q8type_8_performance  Q9divisible_unitary  \\\n",
       "0            0.208333              0.086957             0.227273   \n",
       "1            0.208333              0.086957             0.227273   \n",
       "2            0.208333              0.086957             0.227273   \n",
       "3            0.208333              0.086957             0.227273   \n",
       "4            0.208333              0.086957             0.227273   \n",
       "...               ...                   ...                  ...   \n",
       "1013         0.250000              0.125000             0.086957   \n",
       "1014         0.250000              0.125000             0.086957   \n",
       "1015         0.250000              0.125000             0.086957   \n",
       "1016         0.080000              0.040000             0.250000   \n",
       "1017         0.208333              0.750000             0.086957   \n",
       "\n",
       "      Q10maximizing  Q11optimizing  Q13outcome_multip  ...  \\\n",
       "0          0.583333       0.333333           0.208333  ...   \n",
       "1          0.583333       0.333333           0.208333  ...   \n",
       "2          0.583333       0.333333           0.208333  ...   \n",
       "3          0.583333       0.333333           0.208333  ...   \n",
       "4          0.583333       0.333333           0.208333  ...   \n",
       "...             ...            ...                ...  ...   \n",
       "1013       0.541667       0.708333           0.875000  ...   \n",
       "1014       0.541667       0.708333           0.875000  ...   \n",
       "1015       0.541667       0.708333           0.875000  ...   \n",
       "1016       0.160000       0.000000           0.000000  ...   \n",
       "1017       0.375000       0.791667           0.625000  ...   \n",
       "\n",
       "      Q22confl_tradeoffs  Q23ss_out_uncert  Q24eureka_question  \\\n",
       "0               0.208333          1.000000               0.000   \n",
       "1               0.208333          1.000000               0.000   \n",
       "2               0.208333          1.000000               0.000   \n",
       "3               0.208333          1.000000               0.000   \n",
       "4               0.208333          1.000000               0.000   \n",
       "...                  ...               ...                 ...   \n",
       "1013            0.791667          0.875000               0.125   \n",
       "1014            0.791667          0.875000               0.125   \n",
       "1015            0.791667          0.875000               0.125   \n",
       "1016            0.200000          0.363636               0.000   \n",
       "1017            0.333333          0.208333               0.875   \n",
       "\n",
       "      Q2intel_manip_1  Q21intellective_judg_1  Q5creativity_input_1  \\\n",
       "0            0.037500                0.466667              0.758333   \n",
       "1            0.037500                0.466667              0.758333   \n",
       "2            0.037500                0.466667              0.758333   \n",
       "3            0.037500                0.466667              0.758333   \n",
       "4            0.037500                0.466667              0.758333   \n",
       "...               ...                     ...                   ...   \n",
       "1013         0.050000                0.970833              0.325000   \n",
       "1014         0.050000                0.970833              0.325000   \n",
       "1015         0.050000                0.970833              0.325000   \n",
       "1016         0.088000                0.096000              0.916000   \n",
       "1017         0.066667                0.950000              0.633333   \n",
       "\n",
       "      Q25_type6_mixed_motive  High  Low  Medium  \n",
       "0                          0     0    0       1  \n",
       "1                          0     0    0       1  \n",
       "2                          0     0    0       1  \n",
       "3                          0     0    0       1  \n",
       "4                          0     0    0       1  \n",
       "...                      ...   ...  ...     ...  \n",
       "1013                       0     0    0       1  \n",
       "1014                       0     0    0       1  \n",
       "1015                       0     0    0       1  \n",
       "1016                       0     0    0       1  \n",
       "1017                       0     0    1       0  \n",
       "\n",
       "[1018 rows x 27 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up X's and y's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([team_composition_features, task_features, conv_features], axis = 1)\n",
    "y_train = targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try LASSO/Ridge Regression, one Set of Features at a Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we want to implement *leave-one-out cross-validation*, and use Q^2 as our metric.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two updates to make here:\n",
    "\n",
    "1. For nested LASSO/Ridge models, add the ability to initialize the model using the previous weights\n",
    "2. Visualize importance using another library, like SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note --- this uses k-fold cross-validation with k = 5 (the default)\n",
    "# We are testing 10,000 different alphas, so I feel like this is an OK heuristic\n",
    "def get_optimal_alpha(X_train, y_train, y_target, feature_columns_list, lasso):\n",
    "\n",
    "    if(lasso == True):\n",
    "        model = LassoCV(n_alphas = 10000)\n",
    "        model.fit(X_train[feature_columns_list], y_train[y_target])\n",
    "    else:\n",
    "        model = RidgeCV(n_alphas = 10000)\n",
    "        model.fit(X_train[feature_columns_list], y_train[y_target])\n",
    "        \n",
    "    return model.alpha_ # optimal alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_regularized_linear_model(X_train, y_train, y_target, feature_columns_list, lasso=True, tune_alpha=False, prev_coefs = None, prev_alpha = None):\n",
    "\n",
    "    if not tune_alpha:\n",
    "        alpha = 1.0\n",
    "    if (prev_alpha is not None):\n",
    "        alpha = prev_alpha # use previous alpha\n",
    "        print(\"Setting alpha to previous...\")\n",
    "        print(alpha)\n",
    "    else:\n",
    "        # Hyperparameter tune the alpha\n",
    "        alpha = get_optimal_alpha(X_train, y_train, y_target, feature_columns_list, lasso=True)\n",
    "\n",
    "    if lasso:\n",
    "        model = Lasso(alpha=alpha)\n",
    "    else:\n",
    "        model = Ridge(alpha=alpha)\n",
    "\n",
    "    if(prev_coefs is not None): # set weights to previous coefficients\n",
    "        print(\"Setting coefficients ....\")\n",
    "        model.coef_ = prev_coefs\n",
    "\n",
    "        print(model.coef_)\n",
    "\n",
    "    # Calculation of Q^2 metric\n",
    "    squared_model_prediction_errors = []\n",
    "    squared_average_prediction_errors = []\n",
    "\n",
    "    # Initialize a list to store coefficients\n",
    "    coefficients_list = []\n",
    "\n",
    "    # Leave one out -- iterate through the entire length of the dataset\n",
    "    for i in range(len(y_train)):\n",
    "        # Store the evaluation datapoint\n",
    "        evaluation_X = X_train.iloc[[i]]\n",
    "        evaluation_y = y_train.iloc[[i]][y_target]\n",
    "\n",
    "        # Drop the ith datapoint (leave this one out)\n",
    "        X_train_fold = X_train.drop(X_train.index[i])\n",
    "        y_train_fold = y_train.drop(y_train.index[i])[y_target]\n",
    "\n",
    "        # Fit the model\n",
    "        model.fit(X_train_fold[feature_columns_list], y_train_fold)\n",
    "\n",
    "        # Save the Prediction Error\n",
    "        prediction = model.predict(evaluation_X[feature_columns_list])[0]\n",
    "        squared_model_prediction_errors.append((evaluation_y - prediction) ** 2)\n",
    "\n",
    "        # Save the Total Error for this fold\n",
    "        squared_average_prediction_errors.append((evaluation_y - np.mean(y_train_fold)) ** 2)\n",
    "\n",
    "        # Append the coefficients to the list\n",
    "        coefficients_list.append(model.coef_)\n",
    "\n",
    "    # Create a DataFrame with feature names as rows and iteration results as columns\n",
    "    feature_coefficients = pd.DataFrame(coefficients_list, columns=feature_columns_list).T\n",
    "\n",
    "    q_squared = 1 - (np.sum(squared_model_prediction_errors) / np.sum(squared_average_prediction_errors))\n",
    "    print(\"Q^2: \" + str(q_squared))\n",
    "\n",
    "    return model, q_squared, feature_coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_feature_coefficients(feature_coef_df):\n",
    "    # Initialize a list to store DataFrames for each feature\n",
    "    dfs = []\n",
    "\n",
    "    # Iterate through the rows of the input DataFrame\n",
    "    for feature_name, coefficients in feature_coef_df.iterrows():\n",
    "        # Calculate the confidence interval without NaN values\n",
    "        non_nan_coefficients = coefficients[~np.isnan(coefficients)]\n",
    "        if len(non_nan_coefficients) == 0:\n",
    "            # Handle the case where there are no valid coefficients\n",
    "            continue\n",
    "\n",
    "        mean_coef = non_nan_coefficients.mean()\n",
    "\n",
    "        # Check if all coefficients in the row are the same\n",
    "        if len(coefficients.unique()) == 1:\n",
    "            # If all coefficients are the same, set the lower and upper CI to the mean\n",
    "            confidence_interval = (mean_coef, mean_coef)\n",
    "        else:\n",
    "            std_error = non_nan_coefficients.sem()\n",
    "            confidence_interval = stats.t.interval(0.95, len(non_nan_coefficients) - 1, loc=mean_coef, scale=std_error)\n",
    "\n",
    "        # Create a DataFrame for the summary data\n",
    "        temp_df = pd.DataFrame({\n",
    "            \"Feature\": [feature_name],\n",
    "            \"Mean\": [mean_coef],\n",
    "            \"Lower_CI\": [confidence_interval[0]],\n",
    "            \"Upper_CI\": [confidence_interval[1]]\n",
    "        })\n",
    "\n",
    "        # Append the temporary DataFrame to the list\n",
    "        dfs.append(temp_df)\n",
    "\n",
    "    # Concatenate all the DataFrames in the list into the final summary DataFrame\n",
    "    summary_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_mean_abs(df):\n",
    "    return df.reindex(df[\"Mean\"].abs().sort_values(ascending=False).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go through the different types of features and fit models\n",
    "\n",
    "# First, create a data structure that saves the result\n",
    "result = {\n",
    "    \"model\": [],\n",
    "    \"model_type\": [],\n",
    "    \"features_included\": [],\n",
    "    \"alpha\": [],\n",
    "    \"q_squared\": []\n",
    "}\n",
    "\n",
    "result_df = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to Run all Experiments in 1 Go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_with_replacement(df):\n",
    "    num_rows = len(df)\n",
    "    resampled_indices = pd.Series(range(num_rows)).sample(n=num_rows, replace=True).reset_index(drop=True)\n",
    "    resampled_dataframe = df.iloc[resampled_indices]\n",
    "\n",
    "    return resampled_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample():\n",
    "    total_data = pd.concat([X_train, y_train], axis = 1)\n",
    "    resampled_data = get_sample_with_replacement(total_data)\n",
    "    resampled_X_train = resampled_data[list(X_train.columns)]\n",
    "    resampled_y_train = resampled_data[list(y_train.columns)]\n",
    "\n",
    "    return resampled_X_train, resampled_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_three_models(random_seed):\n",
    "    random.seed(random_seed)\n",
    "\n",
    "    # Set up the dataset by drawing 1,000 samples\n",
    "    resampled_X_train, resampled_y_train = resample()\n",
    "\n",
    "    # Composition Features\n",
    "    model_ridge_composition, mrc_q2, mrc_feature_coefficients = fit_regularized_linear_model(resampled_X_train, resampled_y_train, desired_target, team_composition_features.columns, lasso = False, tune_alpha = True)\n",
    "\n",
    "    # Composition + Task (Map Only)\n",
    "    task_map_path = '../utils/task_map.csv' # get task map\n",
    "    task_map_columns = list(pd.read_csv(task_map_path).drop([\"task\"], axis = 1).columns)\n",
    "    task_gen_comp_features = task_map_columns + list(team_composition_features.columns)\n",
    "    model_ridge_taskgencomp, mrtgc_q2, mrtgc_feature_coefficients = fit_regularized_linear_model(resampled_X_train, resampled_y_train, desired_target, task_gen_comp_features, lasso = False, tune_alpha = True)\n",
    "\n",
    "    # Composition + Task (Map + Complexity)\n",
    "    task_comp_features = list(task_features.columns) + list(team_composition_features.columns)\n",
    "    model_ridge_taskcomp, mrtc_q2, mrtc_feature_coefficients = fit_regularized_linear_model(resampled_X_train, resampled_y_train, desired_target, task_comp_features, lasso = False, tune_alpha = True)\n",
    "\n",
    "    # Composition + Task + Conversation\n",
    "    all_features = list(task_features.columns) + list(team_composition_features.columns) + list(conv_features.columns)\n",
    "    model_ridge_all, mrall_q2, mrall_feature_coefficients = fit_regularized_linear_model(resampled_X_train, resampled_y_train, desired_target, all_features, lasso = False, tune_alpha = True)\n",
    "\n",
    "    return mrc_q2, mrtgc_q2, mrtc_q2, mrall_q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: 0.12948846787808654\n",
      "Q^2: 0.24792021736817904\n",
      "Q^2: 0.2509706911043057\n",
      "Q^2: 0.23846567303484845\n",
      "Q^2: 0.11767942256389075\n",
      "Q^2: 0.24127706757284206\n",
      "Q^2: 0.23861894799705863\n",
      "Q^2: 0.2311439445418082\n",
      "Q^2: 0.09831787441344075\n",
      "Q^2: 0.21354914039515438\n",
      "Q^2: 0.22439545000563887\n",
      "Q^2: 0.21850594166791804\n",
      "Q^2: 0.06584915698807381\n",
      "Q^2: 0.0870000137435668\n",
      "Q^2: 0.09128210375002754\n",
      "Q^2: 0.0558728495809665\n",
      "Q^2: 0.11383188836687619\n",
      "Q^2: 0.2134480521561024\n",
      "Q^2: 0.21038510700326307\n",
      "Q^2: 0.19924451533330978\n",
      "Q^2: 0.10120887920578947\n",
      "Q^2: 0.24022548610423033\n",
      "Q^2: 0.24072847015524135\n",
      "Q^2: 0.23030422083981272\n",
      "Q^2: 0.04457413159803092\n",
      "Q^2: 0.04528654355784223\n",
      "Q^2: 0.04543894817403471\n",
      "Q^2: 0.034746432557306806\n",
      "Q^2: 0.07257898086409309\n",
      "Q^2: 0.10118494929226507\n",
      "Q^2: 0.10260353067736638\n",
      "Q^2: 0.0948352403168442\n",
      "Q^2: 0.022748969210753756\n",
      "Q^2: 0.025524832048803958\n",
      "Q^2: 0.026330242618293087\n",
      "Q^2: 0.02513184692845072\n",
      "Q^2: 0.13311086336187927\n",
      "Q^2: 0.23500162990897266\n",
      "Q^2: 0.23529822598122374\n",
      "Q^2: 0.22124335582293908\n",
      "Q^2: 0.10303367981511746\n",
      "Q^2: 0.24999383561425015\n",
      "Q^2: 0.2546223470394633\n",
      "Q^2: 0.24176684868575715\n",
      "Q^2: 0.12406414791046283\n",
      "Q^2: 0.2503060450996818\n",
      "Q^2: 0.2522718440545081\n",
      "Q^2: 0.24315980682006777\n",
      "Q^2: 0.09442127319226301\n",
      "Q^2: 0.20570072495814518\n",
      "Q^2: 0.20523072503187245\n",
      "Q^2: 0.1890497574469091\n",
      "Q^2: 0.03785384597476937\n",
      "Q^2: 0.0391520056500152\n",
      "Q^2: 0.039581302831042\n",
      "Q^2: 0.01646385194144162\n",
      "Q^2: 0.1213932168367916\n",
      "Q^2: 0.2407887182236148\n",
      "Q^2: 0.26128268861575243\n",
      "Q^2: 0.24373934252293672\n",
      "Q^2: 0.161315463948844\n",
      "Q^2: 0.2769169489457105\n",
      "Q^2: 0.2788254596805172\n",
      "Q^2: 0.25083056965547346\n",
      "Q^2: 0.027343752561652335\n",
      "Q^2: 0.028906985197281854\n",
      "Q^2: 0.030162923114081863\n",
      "Q^2: 0.022614893048167772\n",
      "Q^2: 0.048139795945751684\n",
      "Q^2: 0.05068256941909277\n",
      "Q^2: 0.05149561735588126\n",
      "Q^2: 0.05138425249056111\n",
      "Q^2: 0.11291660656322922\n",
      "Q^2: 0.23066248371272047\n",
      "Q^2: 0.22892925371494888\n",
      "Q^2: 0.22419033986522818\n",
      "Q^2: 0.08156149624282949\n",
      "Q^2: 0.12400535877972307\n",
      "Q^2: 0.1334086086499363\n",
      "Q^2: 0.11241504900996058\n"
     ]
    }
   ],
   "source": [
    "composition_only = []\n",
    "composition_task_general = []\n",
    "composition_task = []\n",
    "all = []\n",
    "N_ITERS = 20\n",
    "random_seeds = [random.randint(1, 999999999) for i in range(N_ITERS)]\n",
    "\n",
    "for seed in random_seeds: # bootstrap 20 times\n",
    "    comp, taskgencomp, taskcomp, taskcompconv = train_and_evaluate_three_models(seed)\n",
    "    composition_only.append(comp)\n",
    "    composition_task_general.append(taskgencomp)\n",
    "    composition_task.append(taskcomp)\n",
    "    all.append(taskcompconv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0723414203300617, 0.10880177101420084)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.DescrStatsW(composition_only).tconfint_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.12447816659147048, 0.21027519418334906)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.DescrStatsW(composition_task_general).tconfint_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.12677357841734982, 0.2134126703380959)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.DescrStatsW(composition_task).tconfint_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11416571390718777, 0.20034515930388297)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.DescrStatsW(all).tconfint_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_means_with_confidence_intervals_and_ttests(observation_lists, labels, confidence_level=0.95, alpha=0.05):\n",
    "    # Calculate means and confidence intervals\n",
    "    means = [np.mean(observation) for observation in observation_lists]\n",
    "    errors = [(sms.DescrStatsW(observation).tconfint_mean()[1] - sms.DescrStatsW(observation).tconfint_mean()[0]) / 2. for observation in observation_lists]\n",
    "    colors = plt.cm.tab20(np.arange(len(labels)))\n",
    "\n",
    "    # Plot the bar graph with error bars\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.bar(range(len(means)), means, yerr=errors, align='center', alpha=0.7, ecolor='black', color=colors, capsize=10)\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xticks(range(len(means)), labels, rotation=45, ha=\"right\")  # Rotate x-axis labels by 45 degrees\n",
    "    plt.ylabel('Prediction Q^2', size = 16)\n",
    "    plt.title('Predictive Power of Models; Pairwise t-test with B-H Correction', size = 18)\n",
    "\n",
    "    # Perform pairwise t-tests\n",
    "    p_values = []\n",
    "    line_height = np.mean(max(observation_lists)) * 0.1\n",
    "    for i in range(len(observation_lists)):\n",
    "        for j in range(i + 1, len(observation_lists)):\n",
    "            t_stat, p_value = stats.ttest_ind(observation_lists[i], observation_lists[j])\n",
    "            p_values.append(p_value)\n",
    "\n",
    "            # Draw horizontal bar between compared groups only if p-value is significant\n",
    "            if p_value < alpha:\n",
    "                line_y = max(means) + max(errors) + np.mean(max(observation_lists)) * 0.03 + (i + j) * line_height * 1.5  # Adjust the multiplier for better spacing\n",
    "                plt.plot([i, j], [line_y, line_y], color='black')\n",
    "\n",
    "                # Display significance stars based on p-value\n",
    "                if p_value < 0.001:\n",
    "                    significance_label = '***'\n",
    "                elif p_value < 0.01:\n",
    "                    significance_label = '**'\n",
    "                elif p_value < 0.05:\n",
    "                    significance_label = '*'\n",
    "                else:\n",
    "                    significance_label = 'n.s.'\n",
    "\n",
    "                # Display significance labels on the plot\n",
    "                plt.text((i + j) / 2, line_y + np.mean(max(observation_lists)) * 0.025, significance_label, ha='center', va='center')\n",
    "\n",
    "    # Correct p-values for multiple comparisons using Benjamini-Hochberg procedure\n",
    "    _, p_values_corrected, _, _ = multipletests(p_values, alpha=alpha, method='fdr_bh')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_means_with_confidence_intervals_and_ttests([composition_only, composition_task_general, composition_task, all], [\"Composition Only\", \"Composition + Task Map\", \"Composition + Task Map + Complexity\", \"Composition + Tasm Map + Complexity + Communication\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
