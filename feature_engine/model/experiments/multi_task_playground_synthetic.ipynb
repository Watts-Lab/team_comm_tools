{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_builder import ModelBuilder\n",
    "from sklearn.linear_model import Lasso, Ridge, LassoCV, RidgeCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import json\n",
    "import os\n",
    "from model_utils import *\n",
    "import scipy.stats as stats \n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.stats.api as sms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Task Modeling Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to prototype the modeling process for the team ingredient horse race project on the multi-task data.\n",
    "\n",
    "For *each task* ...\n",
    "\n",
    "We want to understand the effect of different \"ingredients of a team\" (Composition, Task, and Conversation) on its ultimate performance.\n",
    "\n",
    "Team Composition:\n",
    "- ['birth_year', 'CRT', 'income_max', 'income_min', 'IRCS_GS', 'IRCS_GV', 'IRCS_IB', 'IRCS_IR', 'IRCS_IV', 'IRCS_RS', 'political_fiscal', 'political_social', 'RME', 'country', 'education_level', 'gender', 'marital_status', 'political_party', 'race']\n",
    "- Number of players: 'playerCount'\n",
    "\n",
    "Task Features:\n",
    "- Need to append from the Task Map\n",
    "- ['complexity', 'task']\n",
    "\n",
    "Conversation Features (All)\n",
    "- Everything else that is NOT an ID or a dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Tiny Test Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_cols(name, num_cols):\n",
    "    random_data = np.random.normal(size=(1000, num_cols))\n",
    "    random_df = pd.DataFrame(random_data, columns=[name + f'_{i+1}' for i in range(num_cols)])\n",
    "    return random_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_combination(dataframe):\n",
    "    columns = dataframe.columns\n",
    "    combined_column = np.zeros(len(dataframe))\n",
    "    for col in columns:\n",
    "        combined_column += dataframe[col] + dataframe[col]*dataframe[col]\n",
    "    combined_column =  combined_column*np.random.rand()\n",
    "    result_df = pd.DataFrame({'score': combined_column})\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data():\n",
    "    team_composition_features = get_random_cols(\"composition\", 30)\n",
    "    task_features = get_random_cols(\"task\", 30)\n",
    "    conv_features = get_random_cols(\"conv\", 1000)\n",
    "    unobserved_features = get_random_cols(\"unobserved\", 10) # these are unobserved features\n",
    "\n",
    "    composition = random_combination(team_composition_features)\n",
    "    task = random_combination(task_features)\n",
    "    conv = random_combination(conv_features)\n",
    "    unobs = random_combination(unobserved_features)\n",
    "    \n",
    "    targets = 3*composition + 5*task + 7*conv + np.random.rand() + unobs\n",
    "\n",
    "    synthetic_df = pd.concat(\n",
    "    [team_composition_features,\n",
    "    task_features,\n",
    "    conv_features], axis = 1)\n",
    "\n",
    "    return (team_composition_features, task_features, conv_features, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# team_composition_features, task_features, conv_features, targets = generate_synthetic_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Preprocess Data\n",
    "The function below reads in the dataframe and preprocesses each group of features:\n",
    "\n",
    "- Composition\n",
    "- Task\n",
    "- Conversation\n",
    "\n",
    "And also parses out the possible dependent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def drop_invariant_columns(df):\n",
    "#     \"\"\"\n",
    "#     Certain features are invariant throughout the training data (e.g., the entire column is 0 throughout).\n",
    "\n",
    "#     These feature obviously won't be very useful predictors, so we drop them.\n",
    "    \n",
    "#     This function works by identifying columns that only have 1 unique value throughout the entire column,\n",
    "#     and then dropping them.\n",
    "\n",
    "#     @df: the dataframe containing the features (this should be X).\n",
    "#     \"\"\"\n",
    "#     nunique = df.nunique()\n",
    "#     cols_to_drop = nunique[nunique == 1].index\n",
    "#     return(df.drop(cols_to_drop, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_and_preprocess_data(path, min_num_chats):\n",
    "#     conv_data  = pd.read_csv(path)\n",
    "\n",
    "#     # Filter this down to teams that have at least min_num of chats\n",
    "#     # Can also comment this out to re-run results on *all* conversations!\n",
    "#     conv_data = conv_data[conv_data[\"sum_num_messages\"] >= min_num_chats]\n",
    "\n",
    "\n",
    "#     # Save the important information\n",
    "\n",
    "#     # DV\n",
    "#     dvs = conv_data[[\"score\",\"speed\",\"efficiency\",\"raw_duration_min\",\"default_duration_min\"]]\n",
    "\n",
    "#     # Team Composition\n",
    "#     composition_colnames = ['birth_year', 'CRT', 'income_max', 'income_min', 'IRCS_GS', 'IRCS_GV', 'IRCS_IB', 'IRCS_IR',\n",
    "#                 'IRCS_IV', 'IRCS_RS', 'political_fiscal', 'political_social', 'RME', 'country', 'education_level',\n",
    "#                 'gender', 'marital_status', 'political_party', 'race', 'playerCount']\n",
    "    \n",
    "#     # Select columns that contain the specified keywords\n",
    "#     composition = conv_data[[col for col in conv_data.columns if any(keyword in col for keyword in composition_colnames)]]\n",
    "\n",
    "#     # Task\n",
    "#     task = conv_data[['task', 'complexity']].copy()\n",
    "\n",
    "#     task_map_path = '../utils/task_map.csv' # get task map\n",
    "#     task_map = pd.read_csv(task_map_path)\n",
    "\n",
    "#     task_name_mapping = {\n",
    "#         \"Moral Reasoning\": \"Moral Reasoning (Disciplinary Action Case)\",\n",
    "#         \"Wolf Goat Cabbage\": \"Wolf, goat and cabbage transfer\",\n",
    "#         \"Guess the Correlation\": \"Guessing the correlation\",\n",
    "#         \"Writing Story\": \"Writing story\",\n",
    "#         \"Room Assignment\": \"Room assignment task\",\n",
    "#         \"Allocating Resources\": \"Allocating resources to programs\",\n",
    "#         \"Divergent Association\": \"Divergent Association Task\",\n",
    "#         \"Word Construction\": \"Word construction from a subset of letters\",\n",
    "#         \"Whac a Mole\": \"Whac-A-Mole\"\n",
    "#     }\n",
    "#     task.loc[:, 'task'] = task['task'].replace(task_name_mapping)\n",
    "#     task = pd.merge(left=task, right=task_map, on = \"task\", how='left')\n",
    "    \n",
    "#     # Create dummy columns for 'complexity'\n",
    "#     complexity_dummies = pd.get_dummies(task['complexity'])\n",
    "#     task = pd.concat([task, complexity_dummies], axis=1)   \n",
    "#     task.drop(['complexity', 'task'], axis=1, inplace=True)\n",
    "\n",
    "#     # Conversation\n",
    "#     conversation = conv_data.drop(columns=list(dvs.columns) + list(composition.columns) + ['task', 'complexity', 'stageId', 'roundId', 'cumulative_stageId', 'gameId', 'message', 'message_lower_with_punc', 'speaker_nickname', 'conversation_num', 'timestamp'])\n",
    "#     conversation = drop_invariant_columns(conversation) # drop invariant conv features\n",
    "\n",
    "#     return composition, task, conversation, dvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiny_multitask = 'conv/multi_task_TINY_output_conversation_level_stageId_cumulative.csv'\n",
    "# multitask_cumulative_by_stage = 'conv/multi_task_output_conversation_level_stageId_cumulative.csv'\n",
    "# multitask_cumulative_by_stage_and_task = 'conv/multi_task_output_conversation_level_stageId_cumulative_within_task.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "# min_num_chats = 0\n",
    "desired_target = \"score\"\n",
    "# data_path = \"../output/\"\n",
    "# output_path = \"./results/multi_task_cumulative_stage/\" + \"min=\" + str(min_num_chats) + \"/\" + desired_target + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# team_composition_features, task_features, conv_features, targets = read_and_preprocess_data(data_path + multitask_cumulative_by_stage, min_num_chats=min_num_chats)\n",
    "\n",
    "# Number of points in dataset\n",
    "# len(conv_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up X's and y's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = pd.concat([team_composition_features, task_features, conv_features], axis = 1)\n",
    "# X_train = X_train.fillna(-1) # TODO --- need a better way to handle NA's!\n",
    "# y_train = targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try LASSO/Ridge Regression, one Set of Features at a Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we want to implement *leave-one-out cross-validation*, and use Q^2 as our metric.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two updates to make here:\n",
    "\n",
    "1. For nested LASSO/Ridge models, add the ability to initialize the model using the previous weights\n",
    "2. Visualize importance using another library, like SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note --- this uses k-fold cross-validation with k = 5 (the default)\n",
    "# We are testing 10,000 different alphas, so I feel like this is an OK heuristic\n",
    "def get_optimal_alpha(X_train, y_train, y_target, feature_columns_list, lasso):\n",
    "\n",
    "    if(lasso == True):\n",
    "        model = LassoCV(n_alphas = 10000)\n",
    "        model.fit(X_train[feature_columns_list], y_train[y_target])\n",
    "    else:\n",
    "        model = RidgeCV(n_alphas = 10000)\n",
    "        model.fit(X_train[feature_columns_list], y_train[y_target])\n",
    "        \n",
    "    return model.alpha_ # optimal alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_regularized_linear_model(X_train, y_train, y_target, feature_columns_list, lasso=True, tune_alpha=False, prev_coefs = None, prev_alpha = None):\n",
    "\n",
    "    if not tune_alpha:\n",
    "        alpha = 1.0\n",
    "    if (prev_alpha is not None):\n",
    "        alpha = prev_alpha # use previous alpha\n",
    "        print(\"Setting alpha to previous...\")\n",
    "        print(alpha)\n",
    "    else:\n",
    "        # Hyperparameter tune the alpha\n",
    "        alpha = get_optimal_alpha(X_train, y_train, y_target, feature_columns_list, lasso=True)\n",
    "\n",
    "    if lasso:\n",
    "        model = Lasso(alpha=alpha)\n",
    "    else:\n",
    "        model = Ridge(alpha=alpha)\n",
    "\n",
    "    if(prev_coefs is not None): # set weights to previous coefficients\n",
    "        print(\"Setting coefficients ....\")\n",
    "        model.coef_ = prev_coefs\n",
    "\n",
    "        print(model.coef_)\n",
    "\n",
    "    # Calculation of Q^2 metric\n",
    "    squared_model_prediction_errors = []\n",
    "    squared_average_prediction_errors = []\n",
    "\n",
    "    # Initialize a list to store coefficients\n",
    "    coefficients_list = []\n",
    "\n",
    "    # Leave one out -- iterate through the entire length of the dataset\n",
    "    for i in range(len(y_train)):\n",
    "        # Store the evaluation datapoint\n",
    "        evaluation_X = X_train.iloc[[i]]\n",
    "        evaluation_y = y_train.iloc[[i]][y_target]\n",
    "\n",
    "        # Drop the ith datapoint (leave this one out)\n",
    "        X_train_fold = X_train.drop(X_train.index[i])\n",
    "        y_train_fold = y_train.drop(y_train.index[i])[y_target]\n",
    "\n",
    "        # Fit the model\n",
    "        model.fit(X_train_fold[feature_columns_list], y_train_fold)\n",
    "\n",
    "        # Save the Prediction Error\n",
    "        prediction = model.predict(evaluation_X[feature_columns_list])[0]\n",
    "        squared_model_prediction_errors.append((evaluation_y - prediction) ** 2)\n",
    "\n",
    "        # Save the Total Error for this fold\n",
    "        squared_average_prediction_errors.append((evaluation_y - np.mean(y_train_fold)) ** 2)\n",
    "\n",
    "        # Append the coefficients to the list\n",
    "        coefficients_list.append(model.coef_)\n",
    "\n",
    "    # Create a DataFrame with feature names as rows and iteration results as columns\n",
    "    feature_coefficients = pd.DataFrame(coefficients_list, columns=feature_columns_list).T\n",
    "\n",
    "    q_squared = 1 - (np.sum(squared_model_prediction_errors) / np.sum(squared_average_prediction_errors))\n",
    "    print(\"Q^2: \" + str(q_squared))\n",
    "\n",
    "    return model, q_squared, feature_coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_feature_coefficients(feature_coef_df):\n",
    "    # Initialize a list to store DataFrames for each feature\n",
    "    dfs = []\n",
    "\n",
    "    # Iterate through the rows of the input DataFrame\n",
    "    for feature_name, coefficients in feature_coef_df.iterrows():\n",
    "        # Calculate the confidence interval without NaN values\n",
    "        non_nan_coefficients = coefficients[~np.isnan(coefficients)]\n",
    "        if len(non_nan_coefficients) == 0:\n",
    "            # Handle the case where there are no valid coefficients\n",
    "            continue\n",
    "\n",
    "        mean_coef = non_nan_coefficients.mean()\n",
    "\n",
    "        # Check if all coefficients in the row are the same\n",
    "        if len(coefficients.unique()) == 1:\n",
    "            # If all coefficients are the same, set the lower and upper CI to the mean\n",
    "            confidence_interval = (mean_coef, mean_coef)\n",
    "        else:\n",
    "            std_error = non_nan_coefficients.sem()\n",
    "            confidence_interval = stats.t.interval(0.95, len(non_nan_coefficients) - 1, loc=mean_coef, scale=std_error)\n",
    "\n",
    "        # Create a DataFrame for the summary data\n",
    "        temp_df = pd.DataFrame({\n",
    "            \"Feature\": [feature_name],\n",
    "            \"Mean\": [mean_coef],\n",
    "            \"Lower_CI\": [confidence_interval[0]],\n",
    "            \"Upper_CI\": [confidence_interval[1]]\n",
    "        })\n",
    "\n",
    "        # Append the temporary DataFrame to the list\n",
    "        dfs.append(temp_df)\n",
    "\n",
    "    # Concatenate all the DataFrames in the list into the final summary DataFrame\n",
    "    summary_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_mean_abs(df):\n",
    "    return df.reindex(df[\"Mean\"].abs().sort_values(ascending=False).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go through the different types of features and fit models\n",
    "\n",
    "# First, create a data structure that saves the result\n",
    "result = {\n",
    "    \"model\": [],\n",
    "    \"model_type\": [],\n",
    "    \"features_included\": [],\n",
    "    \"alpha\": [],\n",
    "    \"q_squared\": []\n",
    "}\n",
    "\n",
    "result_df = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team composition features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: 0.4960398859150198\n"
     ]
    }
   ],
   "source": [
    "# model_ridge_composition, mrc_q2, mrc_feature_coefficients = fit_regularized_linear_model(desired_target, team_composition_features.columns, lasso = False, tune_alpha = True)\n",
    "\n",
    "# result_df = pd.concat([result_df, pd.DataFrame({\"model\": [model_ridge_composition], \"model_type\": [\"Ridge\"], \"features_included\": [\"Team Composition\"], \"alpha\": [model_ridge_composition.alpha.round(4)], \"q_squared\": [mrc_q2]})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort_by_mean_abs(display_feature_coefficients(mrc_feature_coefficients))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task + Composition Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: 0.6797296553270269\n"
     ]
    }
   ],
   "source": [
    "# task_comp_features = list(task_features.columns) + list(team_composition_features.columns)\n",
    "\n",
    "# model_ridge_taskcomp, mrtc_q2, mrtc_feature_coefficients = fit_regularized_linear_model(desired_target, task_comp_features, lasso = False, tune_alpha = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df = pd.concat([result_df, pd.DataFrame({\"model\": [model_ridge_taskcomp], \"model_type\": [\"Ridge\"], \"features_included\": [\"Team Composition + Task Complexity\"], \"alpha\": [model_ridge_taskcomp.alpha.round(4)], \"q_squared\": [mrtc_q2]})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort_by_mean_abs(display_feature_coefficients(mrtc_feature_coefficients))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with All Features (Composition + Task + Conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_features = list(task_features.columns) + list(team_composition_features.columns) + list(conv_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: 0.9999999999853215\n"
     ]
    }
   ],
   "source": [
    "# model_ridge_all, mrall_q2, mrall_feature_coefficients = fit_regularized_linear_model(desired_target, all_features, lasso = False, tune_alpha = True)\n",
    "# result_df = pd.concat([result_df, pd.DataFrame({\"model\": [model_ridge_all], \"model_type\": [\"Ridge\"], \"features_included\": [\"All Features\"], \"alpha\": [model_ridge_all.alpha.round(4)], \"q_squared\": [mrall_q2]})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort_by_mean_abs(display_feature_coefficients(mrall_feature_coefficients))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to Run all Experiments in 1 Go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_three_models(random_seed):\n",
    "    random.seed(random_seed)\n",
    "\n",
    "    # Set up the dataset by drawing 1,000 samples\n",
    "    team_composition_features, task_features, conv_features, targets = generate_synthetic_data()\n",
    "    X_train = pd.concat([team_composition_features, task_features, conv_features], axis = 1)\n",
    "    y_train = targets\n",
    "\n",
    "    # Composition Features\n",
    "    model_ridge_composition, mrc_q2, mrc_feature_coefficients = fit_regularized_linear_model(X_train, y_train, desired_target, team_composition_features.columns, lasso = False, tune_alpha = True)\n",
    "\n",
    "    # Composition + Task\n",
    "    task_comp_features = list(task_features.columns) + list(team_composition_features.columns)\n",
    "    model_ridge_taskcomp, mrtc_q2, mrtc_feature_coefficients = fit_regularized_linear_model(X_train, y_train, desired_target, task_comp_features, lasso = False, tune_alpha = True)\n",
    "\n",
    "    # Composition + Task + Conversation\n",
    "    all_features = list(task_features.columns) + list(team_composition_features.columns) + list(conv_features.columns)\n",
    "    model_ridge_all, mrall_q2, mrall_feature_coefficients = fit_regularized_linear_model(X_train, y_train, desired_target, all_features, lasso = False, tune_alpha = True)\n",
    "\n",
    "    return mrc_q2, mrtc_q2, mrall_q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: -0.027854604042430786\n",
      "Q^2: -0.03997430351604114\n",
      "Q^2: -2.201968642941365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: 0.13789581164021925\n",
      "Q^2: 0.10350661250998583\n",
      "Q^2: -3.9697391391853953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: -0.044113179899151644\n",
      "Q^2: -0.07608366565832747\n",
      "Q^2: -1.4161091905337782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: -0.03043831511640538\n",
      "Q^2: -0.03724459158579885\n",
      "Q^2: -1.4098641610711664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: -0.02598630390973966\n",
      "Q^2: -0.057225535260683635\n",
      "Q^2: -1.4538843011709206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: -0.011039133363859088\n",
      "Q^2: 0.12044616213662951\n",
      "Q^2: -6.544349760804107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: -0.03981558456608392\n",
      "Q^2: -0.0733817607197802\n",
      "Q^2: -1.7886154655919353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: -0.021314669074076642\n",
      "Q^2: -0.04391069800715419\n",
      "Q^2: -3.126495510849886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: -0.024942459645739268\n",
      "Q^2: -0.024574750894853947\n",
      "Q^2: -1.1270316756110526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: -0.025304597702356935\n",
      "Q^2: -0.026929647658021638\n",
      "Q^2: -1.8796326249054247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: -0.035587037381716424\n",
      "Q^2: -0.07037056187306101\n",
      "Q^2: -1.5155911503917374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: -0.023379749479466527\n",
      "Q^2: -0.04741344692843019\n",
      "Q^2: -1.1545724257219416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: -0.01625363894382792\n",
      "Q^2: -0.03896050794831707\n",
      "Q^2: -1.245306746204872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: -0.03296427843088412\n",
      "Q^2: 0.0005222359639537322\n",
      "Q^2: -3.436334812702089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: -0.013138857077946042\n",
      "Q^2: -0.01336655760486849\n",
      "Q^2: -2.788512181922537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: -0.02203295432029795\n",
      "Q^2: -0.04023872955403718\n",
      "Q^2: -2.3666187494166584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: -0.030258251915555423\n",
      "Q^2: 0.019683192307917707\n",
      "Q^2: -4.608442834441876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: -0.04037024628611441\n",
      "Q^2: -0.040551988994872\n",
      "Q^2: -3.2483925015767783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: -0.022480164791320867\n",
      "Q^2: -0.058875379729418365\n",
      "Q^2: -1.9784788518188634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: -0.008362522062902888\n",
      "Q^2: -0.03378410509455021\n",
      "Q^2: -4.0015831072601005\n"
     ]
    }
   ],
   "source": [
    "composition_only = []\n",
    "composition_task = []\n",
    "all = []\n",
    "random_seeds = np.random.randint(999999999999, size=20)\n",
    "\n",
    "for seed in random_seeds: # bootstrap 20 times\n",
    "    comp, taskcomp, taskcompconv = train_and_evaluate_three_models(seed)\n",
    "    composition_only.append(comp)\n",
    "    composition_task.append(taskcomp)\n",
    "    all.append(taskcompconv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.035629541051154984, -0.00014453258581068398)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.DescrStatsW(composition_only).tconfint_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.04832809695063995, 0.0004552941396670715)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.DescrStatsW(composition_task).tconfint_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.2250859861930974, -1.9010663972191515)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.DescrStatsW(all).tconfint_mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe that summarizes all these experiments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>model_type</th>\n",
       "      <th>features_included</th>\n",
       "      <th>alpha</th>\n",
       "      <th>q_squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge(alpha=0.002904485249183131)</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge(alpha=0.002904485249183131)</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>Team Composition + Task Complexity</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.67973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge(alpha=0.011839413838757983)</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>Team Composition</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.49604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               model model_type  \\\n",
       "2  Ridge(alpha=0.002904485249183131)      Ridge   \n",
       "1  Ridge(alpha=0.002904485249183131)      Ridge   \n",
       "0  Ridge(alpha=0.011839413838757983)      Ridge   \n",
       "\n",
       "                    features_included   alpha  q_squared  \n",
       "2                        All Features  0.0029    1.00000  \n",
       "1  Team Composition + Task Complexity  0.0029    0.67973  \n",
       "0                    Team Composition  0.0118    0.49604  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.sort_values(by = \"q_squared\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_by_mean_abs(display_feature_coefficients(mrall_feature_coefficients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_n_features(data, n, filepath):\n",
    "    # Calculate the absolute mean value and sort the DataFrame in descending order\n",
    "    data['Absolute_Mean'] = data['Mean'].abs()\n",
    "    top_n_features = data.sort_values(by='Absolute_Mean', ascending=False).head(n)\n",
    "\n",
    "    # Define color mapping for the features\n",
    "    color_map = {}\n",
    "    name_map = {}\n",
    "    for feature in task_features.columns:\n",
    "        color_map[feature] = 'yellowgreen'\n",
    "        name_map[feature] = \"Task Feature\"\n",
    "    for feature in conv_features.columns:\n",
    "        color_map[feature] = 'powderblue'\n",
    "        name_map[feature] = \"Conversation Feature\"\n",
    "    for feature in team_composition_features.columns:\n",
    "        color_map[feature] = 'lightpink'\n",
    "        name_map[feature] = \"Team Composition Feature\"\n",
    "\n",
    "    # Create a horizontal bar graph\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    handles = []\n",
    "\n",
    "    for feature in top_n_features['Feature']:\n",
    "        color = color_map.get(feature, 'k')  # Default to black if not in any list\n",
    "        bars = plt.barh(feature, top_n_features[top_n_features['Feature'] == feature]['Mean'], color=color)\n",
    "        handles.append(bars[0])\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.xlabel('Mean Coefficient (Across LOO Cross Validation)', fontsize = 14)\n",
    "    plt.title(f'Top {n} features for {desired_target} (min chats = {min_num_chats})', fontsize=20)\n",
    "    plt.gca().invert_yaxis()  # Invert the y-axis to display the highest value at the top\n",
    "\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "\n",
    "    # Create a legend outside the plot area with unique labels\n",
    "    unique_features = []\n",
    "    unique_labels = []\n",
    "    for feature in top_n_features['Feature']:\n",
    "        if name_map.get(feature, feature) not in unique_labels:\n",
    "            unique_labels.append(name_map.get(feature, feature))\n",
    "            unique_features.append(feature)\n",
    "\n",
    "    legend_handles = [plt.Line2D([0], [0], color=color_map.get(feature, 'k'), lw=4, label=name_map.get(feature, feature)) for feature in unique_features]\n",
    "    plt.legend(handles=legend_handles, loc='center left', fontsize = 14, bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    # Add labels to the bars with increased text size and Mean rounded to 2 decimals, consistently inside the bar\n",
    "    label_offset = 0.4  # Adjust this value for proper spacing\n",
    "    for bar, value, feature in zip(handles, top_n_features['Mean'], top_n_features['Feature']):\n",
    "        label_x = (max(value, 0) if value >= 0 else min(value, 0))\n",
    "        bbox = bar.get_bbox()\n",
    "        label_y = bbox.bounds[1] + label_offset\n",
    "        if value >= 0:\n",
    "            plt.text(label_x, label_y, f'{value:.2f}', va='center', fontsize=12)\n",
    "        else:\n",
    "            plt.text(label_x, label_y, f'{value:.2f}', ha='right', va='center', fontsize=12)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.savefig(filepath + \".svg\")\n",
    "    plt.savefig(filepath + \".png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_n_features(display_feature_coefficients(mlall_feature_coefficients), 10, filepath = \"./figures/multi_task_cumulative_stage\" + \"_\" + desired_target + \"_min_chat_num_\" + str(min_num_chats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "- More deeply understand difference between LASSO and Ridge\n",
    "- Better understand `alpha` hyperparameter\n",
    "- Why doesn't more features mean a better R^2? (Wouldn't the model 'throw out' features that don't work?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
