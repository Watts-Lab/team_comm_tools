{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_builder import ModelBuilder\n",
    "from sklearn.linear_model import Lasso, Ridge, LassoCV, RidgeCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import json\n",
    "import os\n",
    "from model_utils import *\n",
    "import scipy.stats as stats \n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Task Modeling Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to prototype the modeling process for the team ingredient horse race project on the multi-task data.\n",
    "\n",
    "For *each task* ...\n",
    "\n",
    "We want to understand the effect of different \"ingredients of a team\" (Composition, Task, and Conversation) on its ultimate performance.\n",
    "\n",
    "Team Composition:\n",
    "- ['birth_year', 'CRT', 'income_max', 'income_min', 'IRCS_GS', 'IRCS_GV', 'IRCS_IB', 'IRCS_IR', 'IRCS_IV', 'IRCS_RS', 'political_fiscal', 'political_social', 'RME', 'country', 'education_level', 'gender', 'marital_status', 'political_party', 'race']\n",
    "- Number of players: 'playerCount'\n",
    "\n",
    "Task Features:\n",
    "- Need to append from the Task Map\n",
    "- ['complexity', 'task']\n",
    "\n",
    "Conversation Features (All)\n",
    "- Everything else that is NOT an ID or a dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Preprocess Data\n",
    "The function below reads in the dataframe and preprocesses each group of features:\n",
    "\n",
    "- Composition\n",
    "- Task\n",
    "- Conversation\n",
    "\n",
    "And also parses out the possible dependent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_invariant_columns(df):\n",
    "    \"\"\"\n",
    "    Certain features are invariant throughout the training data (e.g., the entire column is 0 throughout).\n",
    "\n",
    "    These feature obviously won't be very useful predictors, so we drop them.\n",
    "    \n",
    "    This function works by identifying columns that only have 1 unique value throughout the entire column,\n",
    "    and then dropping them.\n",
    "\n",
    "    @df: the dataframe containing the features (this should be X).\n",
    "    \"\"\"\n",
    "    nunique = df.nunique()\n",
    "    cols_to_drop = nunique[nunique == 1].index\n",
    "    return(df.drop(cols_to_drop, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_preprocess_data(path, min_num_chats):\n",
    "    conv_data  = pd.read_csv(path)\n",
    "\n",
    "    # Fill NA with mean\n",
    "    conv_data.fillna(conv_data.mean(), inplace=True) \n",
    "\n",
    "    # Filter this down to teams that have at least min_num of chats\n",
    "    # Can also comment this out to re-run results on *all* conversations!\n",
    "    conv_data = conv_data[conv_data[\"sum_num_messages\"] >= min_num_chats]\n",
    "\n",
    "\n",
    "    # Save the important information\n",
    "\n",
    "    # DV\n",
    "    dvs = conv_data[[\"score\",\"speed\",\"efficiency\",\"raw_duration_min\",\"default_duration_min\"]]\n",
    "\n",
    "    # Team Composition\n",
    "    composition_colnames = ['birth_year', 'CRT', 'income_max', 'income_min', 'IRCS_GS', 'IRCS_GV', 'IRCS_IB', 'IRCS_IR',\n",
    "                'IRCS_IV', 'IRCS_RS', 'political_fiscal', 'political_social', 'RME', 'country', 'education_level',\n",
    "                'gender', 'marital_status', 'political_party', 'race', 'playerCount']\n",
    "    \n",
    "    # Select columns that contain the specified keywords\n",
    "    composition = conv_data[[col for col in conv_data.columns if any(keyword in col for keyword in composition_colnames)]]\n",
    "\n",
    "    # Task\n",
    "    task = conv_data[['task', 'complexity']].copy()\n",
    "\n",
    "    task_map_path = '../utils/task_map.csv' # get task map\n",
    "    task_map = pd.read_csv(task_map_path)\n",
    "\n",
    "    task_name_mapping = {\n",
    "        \"Moral Reasoning\": \"Moral Reasoning (Disciplinary Action Case)\",\n",
    "        \"Wolf Goat Cabbage\": \"Wolf, goat and cabbage transfer\",\n",
    "        \"Guess the Correlation\": \"Guessing the correlation\",\n",
    "        \"Writing Story\": \"Writing story\",\n",
    "        \"Room Assignment\": \"Room assignment task\",\n",
    "        \"Allocating Resources\": \"Allocating resources to programs\",\n",
    "        \"Divergent Association\": \"Divergent Association Task\",\n",
    "        \"Word Construction\": \"Word construction from a subset of letters\",\n",
    "        \"Whac a Mole\": \"Whac-A-Mole\"\n",
    "    }\n",
    "    task.loc[:, 'task'] = task['task'].replace(task_name_mapping)\n",
    "    task = pd.merge(left=task, right=task_map, on = \"task\", how='left')\n",
    "    \n",
    "    # Create dummy columns for 'complexity'\n",
    "    complexity_dummies = pd.get_dummies(task['complexity'])\n",
    "    task = pd.concat([task, complexity_dummies], axis=1)   \n",
    "    task.drop(['complexity', 'task'], axis=1, inplace=True)\n",
    "\n",
    "    # Conversation\n",
    "    conversation = conv_data.drop(columns=list(dvs.columns) + list(composition.columns) + ['task', 'complexity', 'stageId', 'roundId', 'cumulative_stageId', 'gameId', 'message', 'message_lower_with_punc', 'speaker_nickname', 'conversation_num', 'timestamp'])\n",
    "    conversation = drop_invariant_columns(conversation) # drop invariant conv features\n",
    "\n",
    "    # experiment: drop lexical columns\n",
    "    conversation = conversation.drop(columns=[col for col in conversation.columns if \"lexical\" in col], axis=1)\n",
    "\n",
    "    # additional preprocess --- get PC's of conversation to reduce dimensionality issues\n",
    "    pca = PCA(n_components=20)\n",
    "    pca_result = pca.fit_transform(conversation.transform(lambda x: (x - x.mean()) / x.std()))\n",
    "    print(\"PCA explained variance:\")\n",
    "    print(np.sum(pca.explained_variance_ratio_))\n",
    "    conversation = pd.DataFrame(pca_result, columns=[f'PC{i+1}' for i in range(pca_result.shape[1])])\n",
    "\n",
    "    return composition, task, conversation, dvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_multitask = 'conv/multi_task_TINY_output_conversation_level_stageId_cumulative.csv'\n",
    "multitask_cumulative_by_stage = 'conv/multi_task_output_conversation_level_stageId_cumulative.csv'\n",
    "multitask_cumulative_by_stage_and_task = 'conv/multi_task_output_conversation_level_stageId_cumulative_within_task.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "min_num_chats = 0\n",
    "desired_target = \"score\"\n",
    "data_path = \"../output/\"\n",
    "output_path = \"./results/multi_task_cumulative_stage/\" + \"min=\" + str(min_num_chats) + \"/\" + desired_target + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA explained variance:\n",
      "0.6319643237290705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1018"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_composition_features, task_features, conv_features, targets = read_and_preprocess_data(data_path + multitask_cumulative_by_stage, min_num_chats=min_num_chats)\n",
    "\n",
    "# Number of points in dataset\n",
    "len(conv_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up X's and y's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([team_composition_features, task_features, conv_features], axis = 1)\n",
    "y_train = targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try LASSO/Ridge Regression, one Set of Features at a Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we want to implement *leave-one-out cross-validation*, and use Q^2 as our metric.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two updates to make here:\n",
    "\n",
    "1. For nested LASSO/Ridge models, add the ability to initialize the model using the previous weights\n",
    "2. Visualize importance using another library, like SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note --- this uses k-fold cross-validation with k = 5 (the default)\n",
    "# We are testing 10,000 different alphas, so I feel like this is an OK heuristic\n",
    "def get_optimal_alpha(X_train, y_train, y_target, feature_columns_list, lasso):\n",
    "\n",
    "    if(lasso == True):\n",
    "        model = LassoCV(n_alphas = 10000)\n",
    "        model.fit(X_train[feature_columns_list], y_train[y_target])\n",
    "    else:\n",
    "        model = RidgeCV(n_alphas = 10000)\n",
    "        model.fit(X_train[feature_columns_list], y_train[y_target])\n",
    "        \n",
    "    return model.alpha_ # optimal alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_regularized_linear_model(X_train, y_train, y_target, feature_columns_list, lasso=True, tune_alpha=False, prev_coefs = None, prev_alpha = None):\n",
    "\n",
    "    if not tune_alpha:\n",
    "        alpha = 1.0\n",
    "    if (prev_alpha is not None):\n",
    "        alpha = prev_alpha # use previous alpha\n",
    "        print(\"Setting alpha to previous...\")\n",
    "        print(alpha)\n",
    "    else:\n",
    "        # Hyperparameter tune the alpha\n",
    "        alpha = get_optimal_alpha(X_train, y_train, y_target, feature_columns_list, lasso=True)\n",
    "\n",
    "    if lasso:\n",
    "        model = Lasso(alpha=alpha)\n",
    "    else:\n",
    "        model = Ridge(alpha=alpha)\n",
    "\n",
    "    if(prev_coefs is not None): # set weights to previous coefficients\n",
    "        print(\"Setting coefficients ....\")\n",
    "        model.coef_ = prev_coefs\n",
    "\n",
    "        print(model.coef_)\n",
    "\n",
    "    # Calculation of Q^2 metric\n",
    "    squared_model_prediction_errors = []\n",
    "    squared_average_prediction_errors = []\n",
    "\n",
    "    # Initialize a list to store coefficients\n",
    "    coefficients_list = []\n",
    "\n",
    "    # Leave one out -- iterate through the entire length of the dataset\n",
    "    for i in range(len(y_train)):\n",
    "        # Store the evaluation datapoint\n",
    "        evaluation_X = X_train.iloc[[i]]\n",
    "        evaluation_y = y_train.iloc[[i]][y_target]\n",
    "\n",
    "        # Drop the ith datapoint (leave this one out)\n",
    "        X_train_fold = X_train.drop(X_train.index[i])\n",
    "        y_train_fold = y_train.drop(y_train.index[i])[y_target]\n",
    "\n",
    "        # Fit the model\n",
    "        model.fit(X_train_fold[feature_columns_list], y_train_fold)\n",
    "\n",
    "        # Save the Prediction Error\n",
    "        prediction = model.predict(evaluation_X[feature_columns_list])[0]\n",
    "        squared_model_prediction_errors.append((evaluation_y - prediction) ** 2)\n",
    "\n",
    "        # Save the Total Error for this fold\n",
    "        squared_average_prediction_errors.append((evaluation_y - np.mean(y_train_fold)) ** 2)\n",
    "\n",
    "        # Append the coefficients to the list\n",
    "        coefficients_list.append(model.coef_)\n",
    "\n",
    "    # Create a DataFrame with feature names as rows and iteration results as columns\n",
    "    feature_coefficients = pd.DataFrame(coefficients_list, columns=feature_columns_list).T\n",
    "\n",
    "    q_squared = 1 - (np.sum(squared_model_prediction_errors) / np.sum(squared_average_prediction_errors))\n",
    "    print(\"Q^2: \" + str(q_squared))\n",
    "\n",
    "    return model, q_squared, feature_coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_feature_coefficients(feature_coef_df):\n",
    "    # Initialize a list to store DataFrames for each feature\n",
    "    dfs = []\n",
    "\n",
    "    # Iterate through the rows of the input DataFrame\n",
    "    for feature_name, coefficients in feature_coef_df.iterrows():\n",
    "        # Calculate the confidence interval without NaN values\n",
    "        non_nan_coefficients = coefficients[~np.isnan(coefficients)]\n",
    "        if len(non_nan_coefficients) == 0:\n",
    "            # Handle the case where there are no valid coefficients\n",
    "            continue\n",
    "\n",
    "        mean_coef = non_nan_coefficients.mean()\n",
    "\n",
    "        # Check if all coefficients in the row are the same\n",
    "        if len(coefficients.unique()) == 1:\n",
    "            # If all coefficients are the same, set the lower and upper CI to the mean\n",
    "            confidence_interval = (mean_coef, mean_coef)\n",
    "        else:\n",
    "            std_error = non_nan_coefficients.sem()\n",
    "            confidence_interval = stats.t.interval(0.95, len(non_nan_coefficients) - 1, loc=mean_coef, scale=std_error)\n",
    "\n",
    "        # Create a DataFrame for the summary data\n",
    "        temp_df = pd.DataFrame({\n",
    "            \"Feature\": [feature_name],\n",
    "            \"Mean\": [mean_coef],\n",
    "            \"Lower_CI\": [confidence_interval[0]],\n",
    "            \"Upper_CI\": [confidence_interval[1]]\n",
    "        })\n",
    "\n",
    "        # Append the temporary DataFrame to the list\n",
    "        dfs.append(temp_df)\n",
    "\n",
    "    # Concatenate all the DataFrames in the list into the final summary DataFrame\n",
    "    summary_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_mean_abs(df):\n",
    "    return df.reindex(df[\"Mean\"].abs().sort_values(ascending=False).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go through the different types of features and fit models\n",
    "\n",
    "# First, create a data structure that saves the result\n",
    "result = {\n",
    "    \"model\": [],\n",
    "    \"model_type\": [],\n",
    "    \"features_included\": [],\n",
    "    \"alpha\": [],\n",
    "    \"q_squared\": []\n",
    "}\n",
    "\n",
    "result_df = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to Run all Experiments in 1 Go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_with_replacement(df):\n",
    "    num_rows = len(df)\n",
    "    resampled_indices = pd.Series(range(num_rows)).sample(n=num_rows, replace=True).reset_index(drop=True)\n",
    "    resampled_dataframe = df.iloc[resampled_indices]\n",
    "\n",
    "    return resampled_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample():\n",
    "    total_data = pd.concat([X_train, y_train], axis = 1)\n",
    "    resampled_data = get_sample_with_replacement(total_data)\n",
    "    resampled_X_train = resampled_data[list(X_train.columns)]\n",
    "    resampled_y_train = resampled_data[list(y_train.columns)]\n",
    "\n",
    "    return resampled_X_train, resampled_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_three_models(random_seed):\n",
    "    random.seed(random_seed)\n",
    "\n",
    "    # Set up the dataset by drawing 1,000 samples\n",
    "    resampled_X_train, resampled_y_train = resample()\n",
    "\n",
    "    # Composition Features\n",
    "    model_ridge_composition, mrc_q2, mrc_feature_coefficients = fit_regularized_linear_model(resampled_X_train, resampled_y_train, desired_target, team_composition_features.columns, lasso = False, tune_alpha = True)\n",
    "\n",
    "    # Composition + Task\n",
    "    task_comp_features = list(task_features.columns) + list(team_composition_features.columns)\n",
    "    model_ridge_taskcomp, mrtc_q2, mrtc_feature_coefficients = fit_regularized_linear_model(resampled_X_train, resampled_y_train, desired_target, task_comp_features, lasso = False, tune_alpha = True)\n",
    "\n",
    "    # Composition + Task + Conversation\n",
    "    all_features = list(task_features.columns) + list(team_composition_features.columns) + list(conv_features.columns)\n",
    "    model_ridge_all, mrall_q2, mrall_feature_coefficients = fit_regularized_linear_model(resampled_X_train, resampled_y_train, desired_target, all_features, lasso = False, tune_alpha = True)\n",
    "\n",
    "    return mrc_q2, mrtc_q2, mrall_q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: 0.12775782505021316\n",
      "Q^2: 0.24221931859314916\n",
      "Q^2: 0.09165992891017505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: 0.09469336253387961\n",
      "Q^2: 0.18317987220140097\n",
      "Q^2: 0.08648172904480445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: 0.1335761909183809\n",
      "Q^2: 0.20903152370619715\n",
      "Q^2: 0.02042748518698534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: 0.07154225760023047\n",
      "Q^2: 0.2102316747779408\n",
      "Q^2: 0.19800820849781775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: 0.10697909288823693\n",
      "Q^2: 0.22044907627932053\n",
      "Q^2: 0.2104610840509844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: 0.11763993881519397\n",
      "Q^2: 0.23698421736476338\n",
      "Q^2: 0.21988915999871272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: 0.11774292890480265\n",
      "Q^2: 0.26085934567553004\n",
      "Q^2: 0.07102377917393943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: 0.04934288324659164\n",
      "Q^2: 0.06944837670713366\n",
      "Q^2: 0.06985968476421345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: 0.10940302194321472\n",
      "Q^2: 0.25308533658845367\n",
      "Q^2: 0.27366207981305024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: 0.14412593557673814\n",
      "Q^2: 0.2630629704963626\n",
      "Q^2: 0.007383598710319905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: 0.13143765660540419\n",
      "Q^2: 0.2636025637306959\n",
      "Q^2: -0.015084078365373621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: 0.1091879716877513\n",
      "Q^2: 0.25694422209460377\n",
      "Q^2: 0.26401840388863396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: 0.09032030287630621\n",
      "Q^2: 0.2246073190707183\n",
      "Q^2: 0.25259781557519356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: 0.039985534658930844\n",
      "Q^2: 0.04159908295349757\n",
      "Q^2: 0.08119494952729811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: 0.05030681609662879\n",
      "Q^2: 0.0520630187618788\n",
      "Q^2: 0.08229793354667736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: 0.11654524537191024\n",
      "Q^2: 0.2488706075986138\n",
      "Q^2: -0.26761750492927705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: 0.06154815002650804\n",
      "Q^2: 0.11201234592274367\n",
      "Q^2: 0.10816418678327322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: 0.06438871886690323\n",
      "Q^2: 0.06633153256437974\n",
      "Q^2: 0.08612654122661079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: 0.14809254668662786\n",
      "Q^2: 0.2505669545026916\n",
      "Q^2: 0.26914246457751123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seeding based on hashing is deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version. The only \n",
      "supported seed types are: None, int, float, str, bytes, and bytearray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q^2: 0.034769745925977036\n",
      "Q^2: 0.036801944651685514\n",
      "Q^2: 0.05377629062125533\n"
     ]
    }
   ],
   "source": [
    "composition_only = []\n",
    "composition_task = []\n",
    "all = []\n",
    "random_seeds = np.random.randint(999999999999, size=20)\n",
    "\n",
    "for seed in random_seeds: # bootstrap 20 times\n",
    "    comp, taskcomp, taskcompconv = train_and_evaluate_three_models(seed)\n",
    "    composition_only.append(comp)\n",
    "    composition_task.append(taskcomp)\n",
    "    all.append(taskcompconv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07915873724414574, 0.11277987538389725)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.DescrStatsW(composition_only).tconfint_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1450389244365196, 0.22515620598765645)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.DescrStatsW(composition_task).tconfint_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.048184768544317684, 0.16816260551596285)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.DescrStatsW(all).tconfint_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_means_with_confidence_intervals_and_ttests(observation_lists, labels, confidence_level=0.95, alpha=0.05):\n",
    "    # Calculate means and confidence intervals\n",
    "    means = [np.mean(observation) for observation in observation_lists]\n",
    "    errors = [(sms.DescrStatsW(observation).tconfint_mean()[1]-sms.DescrStatsW(observation).tconfint_mean()[0])/2. for observation in observation_lists]\n",
    "    colors = plt.cm.tab20(np.arange(len(labels)))\n",
    "\n",
    "    # Plot the bar graph with error bars\n",
    "    plt.bar(range(len(means)), means, yerr=errors, align='center', alpha=0.7, ecolor='black', color = colors, capsize=10)\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xticks(range(len(means)), labels)\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Prediction Q^2')\n",
    "    plt.title('Predictive Power of Models; Pairwise t-test with B-H Correction')\n",
    "\n",
    "    # Perform pairwise t-tests\n",
    "    p_values = []\n",
    "    line_height = np.mean(max(observation_lists))*0.1\n",
    "    for i in range(len(observation_lists)):\n",
    "        for j in range(i + 1, len(observation_lists)):\n",
    "            t_stat, p_value = stats.ttest_ind(observation_lists[i], observation_lists[j])\n",
    "            p_values.append(p_value)\n",
    "\n",
    "            # Draw horizontal bar between compared groups\n",
    "            line_y = max(means) + max(errors) + np.mean(max(observation_lists))*0.03 + (i + j) * line_height\n",
    "            plt.plot([i, j], [line_y, line_y], color='black')\n",
    "\n",
    "            # Display significance stars or 'n.s.' based on corrected p-values\n",
    "            significance_label = '*' if p_value < alpha else 'n.s.'\n",
    "\n",
    "            # Display significance labels on the plot\n",
    "            plt.text((i + j) / 2, line_y + np.mean(max(observation_lists))*0.05, significance_label, ha='center', va='center')\n",
    "\n",
    "    # Correct p-values for multiple comparisons using Benjamini-Hochberg procedure\n",
    "    _, p_values_corrected, _, _ = multipletests(p_values, alpha=alpha, method='fdr_bh')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_means_with_confidence_intervals_and_ttests([composition_only, composition_task, all], [\"Composition Only\", \"Composition + Task\", \"All\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe that summarizes all these experiments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>model_type</th>\n",
       "      <th>features_included</th>\n",
       "      <th>alpha</th>\n",
       "      <th>q_squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge(alpha=0.002904485249183131)</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>All Features</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge(alpha=0.002904485249183131)</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>Team Composition + Task Complexity</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.67973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge(alpha=0.011839413838757983)</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>Team Composition</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.49604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               model model_type  \\\n",
       "2  Ridge(alpha=0.002904485249183131)      Ridge   \n",
       "1  Ridge(alpha=0.002904485249183131)      Ridge   \n",
       "0  Ridge(alpha=0.011839413838757983)      Ridge   \n",
       "\n",
       "                    features_included   alpha  q_squared  \n",
       "2                        All Features  0.0029    1.00000  \n",
       "1  Team Composition + Task Complexity  0.0029    0.67973  \n",
       "0                    Team Composition  0.0118    0.49604  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.sort_values(by = \"q_squared\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_by_mean_abs(display_feature_coefficients(mrall_feature_coefficients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_n_features(data, n, filepath):\n",
    "    # Calculate the absolute mean value and sort the DataFrame in descending order\n",
    "    data['Absolute_Mean'] = data['Mean'].abs()\n",
    "    top_n_features = data.sort_values(by='Absolute_Mean', ascending=False).head(n)\n",
    "\n",
    "    # Define color mapping for the features\n",
    "    color_map = {}\n",
    "    name_map = {}\n",
    "    for feature in task_features.columns:\n",
    "        color_map[feature] = 'yellowgreen'\n",
    "        name_map[feature] = \"Task Feature\"\n",
    "    for feature in conv_features.columns:\n",
    "        color_map[feature] = 'powderblue'\n",
    "        name_map[feature] = \"Conversation Feature\"\n",
    "    for feature in team_composition_features.columns:\n",
    "        color_map[feature] = 'lightpink'\n",
    "        name_map[feature] = \"Team Composition Feature\"\n",
    "\n",
    "    # Create a horizontal bar graph\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    handles = []\n",
    "\n",
    "    for feature in top_n_features['Feature']:\n",
    "        color = color_map.get(feature, 'k')  # Default to black if not in any list\n",
    "        bars = plt.barh(feature, top_n_features[top_n_features['Feature'] == feature]['Mean'], color=color)\n",
    "        handles.append(bars[0])\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.xlabel('Mean Coefficient (Across LOO Cross Validation)', fontsize = 14)\n",
    "    plt.title(f'Top {n} features for {desired_target} (min chats = {min_num_chats})', fontsize=20)\n",
    "    plt.gca().invert_yaxis()  # Invert the y-axis to display the highest value at the top\n",
    "\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "\n",
    "    # Create a legend outside the plot area with unique labels\n",
    "    unique_features = []\n",
    "    unique_labels = []\n",
    "    for feature in top_n_features['Feature']:\n",
    "        if name_map.get(feature, feature) not in unique_labels:\n",
    "            unique_labels.append(name_map.get(feature, feature))\n",
    "            unique_features.append(feature)\n",
    "\n",
    "    legend_handles = [plt.Line2D([0], [0], color=color_map.get(feature, 'k'), lw=4, label=name_map.get(feature, feature)) for feature in unique_features]\n",
    "    plt.legend(handles=legend_handles, loc='center left', fontsize = 14, bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    # Add labels to the bars with increased text size and Mean rounded to 2 decimals, consistently inside the bar\n",
    "    label_offset = 0.4  # Adjust this value for proper spacing\n",
    "    for bar, value, feature in zip(handles, top_n_features['Mean'], top_n_features['Feature']):\n",
    "        label_x = (max(value, 0) if value >= 0 else min(value, 0))\n",
    "        bbox = bar.get_bbox()\n",
    "        label_y = bbox.bounds[1] + label_offset\n",
    "        if value >= 0:\n",
    "            plt.text(label_x, label_y, f'{value:.2f}', va='center', fontsize=12)\n",
    "        else:\n",
    "            plt.text(label_x, label_y, f'{value:.2f}', ha='right', va='center', fontsize=12)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.savefig(filepath + \".svg\")\n",
    "    plt.savefig(filepath + \".png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_n_features(display_feature_coefficients(mlall_feature_coefficients), 10, filepath = \"./figures/multi_task_cumulative_stage\" + \"_\" + desired_target + \"_min_chat_num_\" + str(min_num_chats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "- More deeply understand difference between LASSO and Ridge\n",
    "- Better understand `alpha` hyperparameter\n",
    "- Why doesn't more features mean a better R^2? (Wouldn't the model 'throw out' features that don't work?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
