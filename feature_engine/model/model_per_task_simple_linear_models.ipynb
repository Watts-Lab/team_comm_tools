{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_builder import ModelBuilder\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import colorsys\n",
    "from scipy.interpolate import splrep, BSpline # for Spline graphs\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import seaborn as sns\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'becker': {'filename': 'beckerestimation_output_conversation_level.csv',\n",
       "  'cols_to_ignore': ['conversation_num',\n",
       "   'mean_pre_discussion_error',\n",
       "   'mean_post_discussion_error',\n",
       "   'mean_pre_discussion_error_pct',\n",
       "   'mean_post_discussion_error_pct',\n",
       "   'question',\n",
       "   'chatrooms',\n",
       "   'trial_indx']},\n",
       " 'csop': {'filename': 'csop_output_conversation_level.csv',\n",
       "  'cols_to_ignore': ['conversation_num',\n",
       "   'batch_num',\n",
       "   'round_num',\n",
       "   'round_index',\n",
       "   'task_index',\n",
       "   'complexity',\n",
       "   'type',\n",
       "   'social_perceptiveness',\n",
       "   'skill',\n",
       "   'normalized_score',\n",
       "   'zscore_score',\n",
       "   'zscore_round_duration',\n",
       "   'zscore_efficiency']},\n",
       " 'csopII': {'filename': 'csopII_output_conversation_level.csv',\n",
       "  'cols_to_ignore': ['conversation_num',\n",
       "   'batch_num',\n",
       "   'vis_img',\n",
       "   'int_verb',\n",
       "   'ort_img',\n",
       "   'rep_man',\n",
       "   'soc_pers',\n",
       "   'team_size',\n",
       "   'difficulty',\n",
       "   'score',\n",
       "   'duration',\n",
       "   'efficiency',\n",
       "   'timestamp']},\n",
       " 'dat': {'filename': 'DAT_output_conversation_level.csv',\n",
       "  'cols_to_ignore': ['conversation_num',\n",
       "   'batch_num',\n",
       "   'vis_img',\n",
       "   'int_verb',\n",
       "   'ort_img',\n",
       "   'rep_man',\n",
       "   'soc_pers',\n",
       "   'team_size',\n",
       "   'score',\n",
       "   'duration',\n",
       "   'efficiency',\n",
       "   'timestamp']},\n",
       " 'gurcay': {'filename': 'gurcay2015estimation_output_conversation_level.csv',\n",
       "  'cols_to_ignore': ['conversation_num',\n",
       "   'mean_pre_discussion_error',\n",
       "   'mean_post_discussion_error',\n",
       "   'mean_pre_discussion_error_pct',\n",
       "   'mean_post_discussion_error_pct',\n",
       "   'question']},\n",
       " 'juries': {'filename': 'jury_output_conversation_level.csv',\n",
       "  'cols_to_ignore': ['conversation_num',\n",
       "   'batch_num',\n",
       "   'round_num',\n",
       "   'timestamp',\n",
       "   'majority_pct',\n",
       "   'num_flipped',\n",
       "   'flipped_pct',\n",
       "   'num_votes']},\n",
       " 'pgg': {'filename': 'pgg_output_conversation_level.csv',\n",
       "  'cols_to_ignore': ['conversation_num',\n",
       "   'treatmentName',\n",
       "   'punishmentCost',\n",
       "   'punishmentMagnitude',\n",
       "   'total_costs',\n",
       "   'total_penalties',\n",
       "   'total_rewards',\n",
       "   'multiplier',\n",
       "   'punishmentExists',\n",
       "   'rewardExists',\n",
       "   'playerCount',\n",
       "   'numRounds',\n",
       "   'timestamp',\n",
       "   'score']},\n",
       " 'task_mapping_keys': {'juries': 'Mock jury',\n",
       "  'csop': 'Room assignment task',\n",
       "  'csopII': 'Room assignment task',\n",
       "  'dat': 'Divergent Association Task',\n",
       "  'becker': 'Estimating Factual Quantities',\n",
       "  'gurcay': 'Estimating Factual Quantities'},\n",
       " 'task_names': ['Mock jury',\n",
       "  'Room assignment task',\n",
       "  'Room assignment task',\n",
       "  'Divergent Association Task',\n",
       "  'Estimating Factual Quantities']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"config.json\", \"rb\") as json_file:\n",
    "    config = json.load(json_file)\n",
    "config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per-Task Linear Models\n",
    "This notebook contains univariate linear models models to show how different independent variables relate to the dependent variable(s) of interest, for each task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For manually fitting and visualizing linear models\n",
    "sns.set_context(\"paper\", rc={\"axes.labelsize\":20})\n",
    "sns.set_context(\"talk\", font_scale=1.4)\n",
    "\n",
    "def plot_single_linear_model(conversation_data, x_vars, y_vars, num_top_plots=None):\n",
    "    num_plots = len(x_vars) * len(y_vars)\n",
    "    num_rows = len(y_vars)\n",
    "    num_cols = len(x_vars)\n",
    "    num_plots_per_row = min(5, num_cols)\n",
    "\n",
    "    num_rows_needed = math.ceil(num_plots / num_plots_per_row)\n",
    "    fig_height = num_rows_needed * 5\n",
    "    fig_width = num_plots_per_row * 5\n",
    "\n",
    "    plt.figure(figsize=(fig_width, fig_height))\n",
    "    \n",
    "    plot_num = 1\n",
    "    metrics_values = []\n",
    "    \n",
    "    if num_top_plots is not None:\n",
    "        all_metrics = []\n",
    "\n",
    "    for y_var in y_vars:\n",
    "        for x_var in x_vars:\n",
    "            if num_top_plots is not None:\n",
    "                x_data = conversation_data[x_var].values.reshape(-1, 1)\n",
    "                y_data = conversation_data[y_var].values\n",
    "\n",
    "                # Fit linear regression model\n",
    "                model = LinearRegression()\n",
    "                model.fit(x_data, y_data)\n",
    "\n",
    "                # Predict using the model\n",
    "                y_pred = model.predict(x_data)\n",
    "\n",
    "                # Calculate metrics\n",
    "                r_squared = r2_score(y_data, y_pred)\n",
    "                mse = mean_squared_error(y_data, y_pred)\n",
    "                mae = mean_absolute_error(y_data, y_pred)\n",
    "                all_metrics.append((x_var, y_var, r_squared, mse, mae))\n",
    "            \n",
    "            if num_top_plots is None or plot_num <= num_top_plots:\n",
    "                plt.subplot(num_rows_needed, num_plots_per_row, plot_num)\n",
    "                sns.scatterplot(x=x_var, y=y_var, data=conversation_data)\n",
    "                \n",
    "                if num_top_plots is not None:\n",
    "                    plt.plot(x_data, y_pred, color='red')\n",
    "                    \n",
    "                plot_num += 1\n",
    "                \n",
    "                if plot_num > num_plots:\n",
    "                    break\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    if num_top_plots is not None:\n",
    "        metrics_df = pd.DataFrame(all_metrics, columns=['x_var', 'y_var', 'r_squared', 'mse', 'mae'])\n",
    "        metrics_df = metrics_df.sort_values(by='r_squared', ascending=False).head(num_top_plots)\n",
    "\n",
    "    return(metrics_df)\n",
    "\n",
    "# Example call\n",
    "# r2_jury_simple_models = plot_single_linear_model(juries_model.conv, juries_model.conv.drop([\"target_raw\", \"target_std\"], axis = 1), [\"target_std\"], num_top_plots=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_metrics_dict_to_sorted_df(data):\n",
    "    # Convert the nested dictionary to a DataFrame\n",
    "    df = pd.DataFrame(data).T\n",
    "\n",
    "    # Reset index to move the 'feature' names to a column\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'feature'}, inplace=True)\n",
    "\n",
    "    # Sort the DataFrame by 'r2' values in descending order\n",
    "    df_sorted = df.sort_values(by='r2', ascending=False)\n",
    "\n",
    "    # Reorder the columns as required\n",
    "    columns_order = ['feature', 'r2', 'mae', 'mse', 'rmse']\n",
    "    df_sorted = df_sorted[columns_order]\n",
    "    return(df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeated_kfold_cv_simplelinear(model, k = 10, seed = 19104):\n",
    "\n",
    "    # Store metrics --- R^2, MAE, MSE\n",
    "    metrics = ['r2', 'mae', 'mse', 'rmse']\n",
    "    feature_metric_dictionary = {}\n",
    "\n",
    "    # Assumes that we already called split datasets before we called this function!\n",
    "    all_features = model.X.columns # include all possible features at this stage\n",
    "\n",
    "    # set up to store results for this feature\n",
    "    for feature in all_features:\n",
    "        feature_metric_dictionary[feature] = {\"train\": None, \"test\": None}\n",
    "        feature_metric_dictionary[feature][\"train\"] = pd.DataFrame(columns=metrics)\n",
    "        feature_metric_dictionary[feature][\"test\"] = pd.DataFrame(columns=metrics)\n",
    "\n",
    "    # Outer loop --- repeat this k times for k-fold CV\n",
    "    # Repeated k-fold cross-validation\n",
    "    random.seed(seed) # set seed for reproducibility\n",
    "    random_states_list = [random.randint(100, 1000000) for _ in range(k)] # create a bunch of different random states\n",
    "\n",
    "    for i in range(len(random_states_list)):\n",
    "        # create an entirely different train-test split for each random iteration\n",
    "        model.get_split_datasets(model.baseline_model, val_size = 0.2, test_size = None, random_state = random_states_list[i])\n",
    "\n",
    "        # Save X_train, y_train, X_val, and y_val so that we don't have to split anew every time\n",
    "        X_train = model.X_train\n",
    "        X_val = model.X_val\n",
    "        y_train = model.y_train\n",
    "        y_val = model.y_val\n",
    "\n",
    "        # Fit a single linear regression on each of the features and report the results\n",
    "        for feature in model.X_train: # do this only for the features that made it into this split\n",
    "            # train a linear regression on just this one feature\n",
    "            evaluation_metrics = model.train_simple_model(model.baseline_model, feature_subset = [feature])\n",
    "            # store the results for that feature\n",
    "            feature_metric_dictionary[feature][\"train\"] = feature_metric_dictionary[feature][\"train\"].append(evaluation_metrics['train'], ignore_index=True)\n",
    "            feature_metric_dictionary[feature][\"test\"] = feature_metric_dictionary[feature][\"test\"].append(evaluation_metrics['val'], ignore_index=True)\n",
    "            # reset the train-test-split, as the underlying X_test got modified\n",
    "            model.set_datasets(X_train=X_train, y_train = y_train, X_val = X_val, y_val = y_val)\n",
    "\n",
    "    # Get mean metrics for each feature\n",
    "    '''\n",
    "    Optimal format:\n",
    "\n",
    "    feature 1    r2   mae   mse  rmse\n",
    "    feature 2    r2   mae   mse  rmse\n",
    "    feature 3    r2   mae   mse  rmse\n",
    "    '''\n",
    "    final_feature_metrics_train = {}\n",
    "    final_feature_metrics_test = {}\n",
    "\n",
    "    for feature in feature_metric_dictionary.keys():\n",
    "        final_feature_metrics_train[feature]=feature_metric_dictionary[feature][\"train\"].mean()\n",
    "        final_feature_metrics_test[feature]=feature_metric_dictionary[feature][\"test\"].mean()\n",
    "\n",
    "    return final_feature_metrics_train, final_feature_metrics_test\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jury"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Data (100)%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Define the basic model\n",
    "juries_model = ModelBuilder(dataset_names = [\"juries\"])\n",
    "juries_model.select_target(target=[\"majority_pct\"])\n",
    "juries_model.define_model(model_type = 'linear')\n",
    "juries_model.get_split_datasets(juries_model.baseline_model, val_size = 0.2, test_size = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "final_feature_metrics_train,final_feature_metrics_test=repeated_kfold_cv_simplelinear(juries_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "jury_train_metrics=convert_metrics_dict_to_sorted_df(final_feature_metrics_train)\n",
    "jury_test_metrics=convert_metrics_dict_to_sorted_df(final_feature_metrics_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>average_user_sum_positivity_zscore_chats</td>\n",
       "      <td>0.05382</td>\n",
       "      <td>0.82843</td>\n",
       "      <td>0.90805</td>\n",
       "      <td>0.95205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>average_positive_bert</td>\n",
       "      <td>0.05127</td>\n",
       "      <td>0.82797</td>\n",
       "      <td>0.91023</td>\n",
       "      <td>0.95289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>average_positivity_zscore_chats</td>\n",
       "      <td>0.05127</td>\n",
       "      <td>0.82797</td>\n",
       "      <td>0.91023</td>\n",
       "      <td>0.95289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>average_user_sum_hashedge</td>\n",
       "      <td>0.05048</td>\n",
       "      <td>0.83199</td>\n",
       "      <td>0.91168</td>\n",
       "      <td>0.95403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>min_user_sum_positivity_zscore_chats</td>\n",
       "      <td>0.04782</td>\n",
       "      <td>0.83173</td>\n",
       "      <td>0.91415</td>\n",
       "      <td>0.95476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>max_user_sum_verbs</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>0.83777</td>\n",
       "      <td>0.91449</td>\n",
       "      <td>0.95548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>average_user_sum_hedges</td>\n",
       "      <td>0.04739</td>\n",
       "      <td>0.83457</td>\n",
       "      <td>0.91489</td>\n",
       "      <td>0.95586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>max_user_sum_hedges</td>\n",
       "      <td>0.04522</td>\n",
       "      <td>0.83664</td>\n",
       "      <td>0.91665</td>\n",
       "      <td>0.95684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>average_user_sum_verbs</td>\n",
       "      <td>0.04518</td>\n",
       "      <td>0.8339</td>\n",
       "      <td>0.91593</td>\n",
       "      <td>0.95614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>max_user_sum_hashedge</td>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.83925</td>\n",
       "      <td>0.91687</td>\n",
       "      <td>0.95698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      feature       r2      mae      mse  \\\n",
       "682  average_user_sum_positivity_zscore_chats  0.05382  0.82843  0.90805   \n",
       "3                       average_positive_bert  0.05127  0.82797  0.91023   \n",
       "291           average_positivity_zscore_chats  0.05127  0.82797  0.91023   \n",
       "706                 average_user_sum_hashedge  0.05048  0.83199  0.91168   \n",
       "684      min_user_sum_positivity_zscore_chats  0.04782  0.83173  0.91415   \n",
       "593                        max_user_sum_verbs   0.0475  0.83777  0.91449   \n",
       "714                   average_user_sum_hedges  0.04739  0.83457  0.91489   \n",
       "717                       max_user_sum_hedges  0.04522  0.83664  0.91665   \n",
       "590                    average_user_sum_verbs  0.04518   0.8339  0.91593   \n",
       "709                     max_user_sum_hashedge   0.0447  0.83925  0.91687   \n",
       "\n",
       "        rmse  \n",
       "682  0.95205  \n",
       "3    0.95289  \n",
       "291  0.95289  \n",
       "706  0.95403  \n",
       "684  0.95476  \n",
       "593  0.95548  \n",
       "714  0.95586  \n",
       "717  0.95684  \n",
       "590  0.95614  \n",
       "709  0.95698  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jury_test_metrics.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 75% of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>average_user_sum_positivity_zscore_chats</td>\n",
       "      <td>0.05382</td>\n",
       "      <td>0.82843</td>\n",
       "      <td>0.90805</td>\n",
       "      <td>0.95205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>average_user_sum_hashedge</td>\n",
       "      <td>0.05048</td>\n",
       "      <td>0.83199</td>\n",
       "      <td>0.91168</td>\n",
       "      <td>0.95403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>min_user_sum_positivity_zscore_chats</td>\n",
       "      <td>0.04782</td>\n",
       "      <td>0.83173</td>\n",
       "      <td>0.91415</td>\n",
       "      <td>0.95476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>max_user_sum_verbs</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>0.83777</td>\n",
       "      <td>0.91449</td>\n",
       "      <td>0.95548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>average_user_sum_hedges</td>\n",
       "      <td>0.04739</td>\n",
       "      <td>0.83457</td>\n",
       "      <td>0.91489</td>\n",
       "      <td>0.95586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>max_user_sum_hedges</td>\n",
       "      <td>0.04522</td>\n",
       "      <td>0.83664</td>\n",
       "      <td>0.91665</td>\n",
       "      <td>0.95684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>average_user_sum_verbs</td>\n",
       "      <td>0.04518</td>\n",
       "      <td>0.8339</td>\n",
       "      <td>0.91593</td>\n",
       "      <td>0.95614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>max_user_sum_hashedge</td>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.83925</td>\n",
       "      <td>0.91687</td>\n",
       "      <td>0.95698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>average_user_sum_cognitive_mech</td>\n",
       "      <td>0.04279</td>\n",
       "      <td>0.83487</td>\n",
       "      <td>0.9195</td>\n",
       "      <td>0.95805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>average_user_sum_social</td>\n",
       "      <td>0.04209</td>\n",
       "      <td>0.83727</td>\n",
       "      <td>0.91865</td>\n",
       "      <td>0.95777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      feature       r2      mae      mse  \\\n",
       "682  average_user_sum_positivity_zscore_chats  0.05382  0.82843  0.90805   \n",
       "706                 average_user_sum_hashedge  0.05048  0.83199  0.91168   \n",
       "684      min_user_sum_positivity_zscore_chats  0.04782  0.83173  0.91415   \n",
       "593                        max_user_sum_verbs   0.0475  0.83777  0.91449   \n",
       "714                   average_user_sum_hedges  0.04739  0.83457  0.91489   \n",
       "717                       max_user_sum_hedges  0.04522  0.83664  0.91665   \n",
       "590                    average_user_sum_verbs  0.04518   0.8339  0.91593   \n",
       "709                     max_user_sum_hashedge   0.0447  0.83925  0.91687   \n",
       "610           average_user_sum_cognitive_mech  0.04279  0.83487   0.9195   \n",
       "546                   average_user_sum_social  0.04209  0.83727  0.91865   \n",
       "\n",
       "        rmse  \n",
       "682  0.95205  \n",
       "706  0.95403  \n",
       "684  0.95476  \n",
       "593  0.95548  \n",
       "714  0.95586  \n",
       "717  0.95684  \n",
       "590  0.95614  \n",
       "709  0.95698  \n",
       "610  0.95805  \n",
       "546  0.95777  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "juries_model75 = ModelBuilder(dataset_names = [\"juries\"], output_dir = '../output/first_75/')\n",
    "juries_model75.select_target(target=[\"majority_pct\"])\n",
    "juries_model75.define_model(model_type = 'linear')\n",
    "juries_model75.get_split_datasets(juries_model75.baseline_model, val_size = 0.2, test_size = None)\n",
    "\n",
    "final_feature_metrics_train,final_feature_metrics_test=repeated_kfold_cv_simplelinear(juries_model75)\n",
    "jury_train_metrics75=convert_metrics_dict_to_sorted_df(final_feature_metrics_train)\n",
    "jury_test_metrics75=convert_metrics_dict_to_sorted_df(final_feature_metrics_test)\n",
    "\n",
    "jury_test_metrics75.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50% Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>average_user_sum_positivity_zscore_chats</td>\n",
       "      <td>0.05382</td>\n",
       "      <td>0.82843</td>\n",
       "      <td>0.90805</td>\n",
       "      <td>0.95205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>average_user_sum_hashedge</td>\n",
       "      <td>0.05048</td>\n",
       "      <td>0.83199</td>\n",
       "      <td>0.91168</td>\n",
       "      <td>0.95403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>min_user_sum_positivity_zscore_chats</td>\n",
       "      <td>0.04782</td>\n",
       "      <td>0.83173</td>\n",
       "      <td>0.91415</td>\n",
       "      <td>0.95476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>max_user_sum_verbs</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>0.83777</td>\n",
       "      <td>0.91449</td>\n",
       "      <td>0.95548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>average_user_sum_hedges</td>\n",
       "      <td>0.04739</td>\n",
       "      <td>0.83457</td>\n",
       "      <td>0.91489</td>\n",
       "      <td>0.95586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>max_user_sum_hedges</td>\n",
       "      <td>0.04522</td>\n",
       "      <td>0.83664</td>\n",
       "      <td>0.91665</td>\n",
       "      <td>0.95684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>average_user_sum_verbs</td>\n",
       "      <td>0.04518</td>\n",
       "      <td>0.8339</td>\n",
       "      <td>0.91593</td>\n",
       "      <td>0.95614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>max_user_sum_hashedge</td>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.83925</td>\n",
       "      <td>0.91687</td>\n",
       "      <td>0.95698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>average_user_sum_cognitive_mech</td>\n",
       "      <td>0.04279</td>\n",
       "      <td>0.83487</td>\n",
       "      <td>0.9195</td>\n",
       "      <td>0.95805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>average_user_sum_social</td>\n",
       "      <td>0.04209</td>\n",
       "      <td>0.83727</td>\n",
       "      <td>0.91865</td>\n",
       "      <td>0.95777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      feature       r2      mae      mse  \\\n",
       "682  average_user_sum_positivity_zscore_chats  0.05382  0.82843  0.90805   \n",
       "706                 average_user_sum_hashedge  0.05048  0.83199  0.91168   \n",
       "684      min_user_sum_positivity_zscore_chats  0.04782  0.83173  0.91415   \n",
       "593                        max_user_sum_verbs   0.0475  0.83777  0.91449   \n",
       "714                   average_user_sum_hedges  0.04739  0.83457  0.91489   \n",
       "717                       max_user_sum_hedges  0.04522  0.83664  0.91665   \n",
       "590                    average_user_sum_verbs  0.04518   0.8339  0.91593   \n",
       "709                     max_user_sum_hashedge   0.0447  0.83925  0.91687   \n",
       "610           average_user_sum_cognitive_mech  0.04279  0.83487   0.9195   \n",
       "546                   average_user_sum_social  0.04209  0.83727  0.91865   \n",
       "\n",
       "        rmse  \n",
       "682  0.95205  \n",
       "706  0.95403  \n",
       "684  0.95476  \n",
       "593  0.95548  \n",
       "714  0.95586  \n",
       "717  0.95684  \n",
       "590  0.95614  \n",
       "709  0.95698  \n",
       "610  0.95805  \n",
       "546  0.95777  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "juries_model50 = ModelBuilder(dataset_names = [\"juries\"], output_dir = '../output/first_50/')\n",
    "juries_model50.select_target(target=[\"majority_pct\"])\n",
    "juries_model50.define_model(model_type = 'linear')\n",
    "juries_model50.get_split_datasets(juries_model50.baseline_model, val_size = 0.2, test_size = None)\n",
    "\n",
    "final_feature_metrics_train,final_feature_metrics_test=repeated_kfold_cv_simplelinear(juries_model50)\n",
    "jury_train_metrics50=convert_metrics_dict_to_sorted_df(final_feature_metrics_train)\n",
    "jury_test_metrics50=convert_metrics_dict_to_sorted_df(final_feature_metrics_test)\n",
    "\n",
    "jury_test_metrics50.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25% of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>average_user_sum_positivity_zscore_chats</td>\n",
       "      <td>0.05382</td>\n",
       "      <td>0.82843</td>\n",
       "      <td>0.90805</td>\n",
       "      <td>0.95205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>average_user_sum_hashedge</td>\n",
       "      <td>0.05048</td>\n",
       "      <td>0.83199</td>\n",
       "      <td>0.91168</td>\n",
       "      <td>0.95403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>min_user_sum_positivity_zscore_chats</td>\n",
       "      <td>0.04782</td>\n",
       "      <td>0.83173</td>\n",
       "      <td>0.91415</td>\n",
       "      <td>0.95476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>max_user_sum_verbs</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>0.83777</td>\n",
       "      <td>0.91449</td>\n",
       "      <td>0.95548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>average_user_sum_hedges</td>\n",
       "      <td>0.04739</td>\n",
       "      <td>0.83457</td>\n",
       "      <td>0.91489</td>\n",
       "      <td>0.95586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>max_user_sum_hedges</td>\n",
       "      <td>0.04522</td>\n",
       "      <td>0.83664</td>\n",
       "      <td>0.91665</td>\n",
       "      <td>0.95684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>average_user_sum_verbs</td>\n",
       "      <td>0.04518</td>\n",
       "      <td>0.8339</td>\n",
       "      <td>0.91593</td>\n",
       "      <td>0.95614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>max_user_sum_hashedge</td>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.83925</td>\n",
       "      <td>0.91687</td>\n",
       "      <td>0.95698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>average_user_sum_cognitive_mech</td>\n",
       "      <td>0.04279</td>\n",
       "      <td>0.83487</td>\n",
       "      <td>0.9195</td>\n",
       "      <td>0.95805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>average_user_sum_social</td>\n",
       "      <td>0.04209</td>\n",
       "      <td>0.83727</td>\n",
       "      <td>0.91865</td>\n",
       "      <td>0.95777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      feature       r2      mae      mse  \\\n",
       "682  average_user_sum_positivity_zscore_chats  0.05382  0.82843  0.90805   \n",
       "706                 average_user_sum_hashedge  0.05048  0.83199  0.91168   \n",
       "684      min_user_sum_positivity_zscore_chats  0.04782  0.83173  0.91415   \n",
       "593                        max_user_sum_verbs   0.0475  0.83777  0.91449   \n",
       "714                   average_user_sum_hedges  0.04739  0.83457  0.91489   \n",
       "717                       max_user_sum_hedges  0.04522  0.83664  0.91665   \n",
       "590                    average_user_sum_verbs  0.04518   0.8339  0.91593   \n",
       "709                     max_user_sum_hashedge   0.0447  0.83925  0.91687   \n",
       "610           average_user_sum_cognitive_mech  0.04279  0.83487   0.9195   \n",
       "546                   average_user_sum_social  0.04209  0.83727  0.91865   \n",
       "\n",
       "        rmse  \n",
       "682  0.95205  \n",
       "706  0.95403  \n",
       "684  0.95476  \n",
       "593  0.95548  \n",
       "714  0.95586  \n",
       "717  0.95684  \n",
       "590  0.95614  \n",
       "709  0.95698  \n",
       "610  0.95805  \n",
       "546  0.95777  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "juries_model25 = ModelBuilder(dataset_names = [\"juries\"], output_dir = '../output/first_25/')\n",
    "juries_model25.select_target(target=[\"majority_pct\"])\n",
    "juries_model25.define_model(model_type = 'linear')\n",
    "juries_model25.get_split_datasets(juries_model25.baseline_model, val_size = 0.2, test_size = None)\n",
    "\n",
    "final_feature_metrics_train,final_feature_metrics_test=repeated_kfold_cv_simplelinear(juries_model25)\n",
    "jury_train_metrics25=convert_metrics_dict_to_sorted_df(final_feature_metrics_train)\n",
    "jury_test_metrics25=convert_metrics_dict_to_sorted_df(final_feature_metrics_test)\n",
    "\n",
    "jury_test_metrics25.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSOP (blended)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Data (100%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>average_user_sum_auxiliary_verbs</td>\n",
       "      <td>0.18715</td>\n",
       "      <td>0.68746</td>\n",
       "      <td>0.86391</td>\n",
       "      <td>0.92866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>average_user_sum_nltk_english_stopwords</td>\n",
       "      <td>0.18615</td>\n",
       "      <td>0.68593</td>\n",
       "      <td>0.86474</td>\n",
       "      <td>0.9291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>average_user_sum_num_words</td>\n",
       "      <td>0.18453</td>\n",
       "      <td>0.68683</td>\n",
       "      <td>0.86649</td>\n",
       "      <td>0.93004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>average_user_sum_verbs</td>\n",
       "      <td>0.18011</td>\n",
       "      <td>0.69108</td>\n",
       "      <td>0.87117</td>\n",
       "      <td>0.93255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>max_user_sum_verbs</td>\n",
       "      <td>0.17961</td>\n",
       "      <td>0.68958</td>\n",
       "      <td>0.87091</td>\n",
       "      <td>0.93253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>average_user_sum_num_chars</td>\n",
       "      <td>0.1781</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.87348</td>\n",
       "      <td>0.93376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>max_user_sum_auxiliary_verbs</td>\n",
       "      <td>0.17583</td>\n",
       "      <td>0.69693</td>\n",
       "      <td>0.87506</td>\n",
       "      <td>0.93483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>max_user_sum_num_words</td>\n",
       "      <td>0.17333</td>\n",
       "      <td>0.69185</td>\n",
       "      <td>0.87791</td>\n",
       "      <td>0.93627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>max_user_sum_nltk_english_stopwords</td>\n",
       "      <td>0.17009</td>\n",
       "      <td>0.69428</td>\n",
       "      <td>0.88117</td>\n",
       "      <td>0.93802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>max_user_sum_num_chars</td>\n",
       "      <td>0.16736</td>\n",
       "      <td>0.69608</td>\n",
       "      <td>0.88457</td>\n",
       "      <td>0.93974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     feature       r2      mae      mse  \\\n",
       "602         average_user_sum_auxiliary_verbs  0.18715  0.68746  0.86391   \n",
       "634  average_user_sum_nltk_english_stopwords  0.18615  0.68593  0.86474   \n",
       "402               average_user_sum_num_words  0.18453  0.68683  0.86649   \n",
       "586                   average_user_sum_verbs  0.18011  0.69108  0.87117   \n",
       "589                       max_user_sum_verbs  0.17961  0.68958  0.87091   \n",
       "406               average_user_sum_num_chars   0.1781    0.692  0.87348   \n",
       "605             max_user_sum_auxiliary_verbs  0.17583  0.69693  0.87506   \n",
       "405                   max_user_sum_num_words  0.17333  0.69185  0.87791   \n",
       "637      max_user_sum_nltk_english_stopwords  0.17009  0.69428  0.88117   \n",
       "409                   max_user_sum_num_chars  0.16736  0.69608  0.88457   \n",
       "\n",
       "        rmse  \n",
       "602  0.92866  \n",
       "634   0.9291  \n",
       "402  0.93004  \n",
       "586  0.93255  \n",
       "589  0.93253  \n",
       "406  0.93376  \n",
       "605  0.93483  \n",
       "405  0.93627  \n",
       "637  0.93802  \n",
       "409  0.93974  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csop_blended_model = ModelBuilder(dataset_names = [\"csop\", \"csopII\"])\n",
    "csop_blended_model.select_target(target=[\"efficiency\", \"efficiency\"])\n",
    "csop_blended_model.define_model(model_type = 'linear')\n",
    "csop_blended_model.get_split_datasets(csop_blended_model.baseline_model, val_size = 0.2, test_size = None)\n",
    "\n",
    "final_feature_metrics_train,final_feature_metrics_test=repeated_kfold_cv_simplelinear(csop_blended_model)\n",
    "csop_blended_train_metrics=convert_metrics_dict_to_sorted_df(final_feature_metrics_train)\n",
    "csop_blended_test_metrics=convert_metrics_dict_to_sorted_df(final_feature_metrics_test)\n",
    "\n",
    "csop_blended_test_metrics.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 75% Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>average_user_sum_auxiliary_verbs</td>\n",
       "      <td>0.18715</td>\n",
       "      <td>0.68746</td>\n",
       "      <td>0.86391</td>\n",
       "      <td>0.92866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>average_user_sum_nltk_english_stopwords</td>\n",
       "      <td>0.18615</td>\n",
       "      <td>0.68593</td>\n",
       "      <td>0.86474</td>\n",
       "      <td>0.9291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>average_user_sum_num_words</td>\n",
       "      <td>0.18453</td>\n",
       "      <td>0.68683</td>\n",
       "      <td>0.86649</td>\n",
       "      <td>0.93004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>average_user_sum_verbs</td>\n",
       "      <td>0.18011</td>\n",
       "      <td>0.69108</td>\n",
       "      <td>0.87117</td>\n",
       "      <td>0.93255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>max_user_sum_verbs</td>\n",
       "      <td>0.17961</td>\n",
       "      <td>0.68958</td>\n",
       "      <td>0.87091</td>\n",
       "      <td>0.93253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>average_user_sum_num_chars</td>\n",
       "      <td>0.1781</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.87348</td>\n",
       "      <td>0.93376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>max_user_sum_auxiliary_verbs</td>\n",
       "      <td>0.17583</td>\n",
       "      <td>0.69693</td>\n",
       "      <td>0.87506</td>\n",
       "      <td>0.93483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>max_user_sum_num_words</td>\n",
       "      <td>0.17333</td>\n",
       "      <td>0.69185</td>\n",
       "      <td>0.87791</td>\n",
       "      <td>0.93627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>max_user_sum_nltk_english_stopwords</td>\n",
       "      <td>0.17009</td>\n",
       "      <td>0.69428</td>\n",
       "      <td>0.88117</td>\n",
       "      <td>0.93802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>max_user_sum_num_chars</td>\n",
       "      <td>0.16736</td>\n",
       "      <td>0.69608</td>\n",
       "      <td>0.88457</td>\n",
       "      <td>0.93974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     feature       r2      mae      mse  \\\n",
       "602         average_user_sum_auxiliary_verbs  0.18715  0.68746  0.86391   \n",
       "634  average_user_sum_nltk_english_stopwords  0.18615  0.68593  0.86474   \n",
       "402               average_user_sum_num_words  0.18453  0.68683  0.86649   \n",
       "586                   average_user_sum_verbs  0.18011  0.69108  0.87117   \n",
       "589                       max_user_sum_verbs  0.17961  0.68958  0.87091   \n",
       "406               average_user_sum_num_chars   0.1781    0.692  0.87348   \n",
       "605             max_user_sum_auxiliary_verbs  0.17583  0.69693  0.87506   \n",
       "405                   max_user_sum_num_words  0.17333  0.69185  0.87791   \n",
       "637      max_user_sum_nltk_english_stopwords  0.17009  0.69428  0.88117   \n",
       "409                   max_user_sum_num_chars  0.16736  0.69608  0.88457   \n",
       "\n",
       "        rmse  \n",
       "602  0.92866  \n",
       "634   0.9291  \n",
       "402  0.93004  \n",
       "586  0.93255  \n",
       "589  0.93253  \n",
       "406  0.93376  \n",
       "605  0.93483  \n",
       "405  0.93627  \n",
       "637  0.93802  \n",
       "409  0.93974  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csop_blended_model75 = ModelBuilder(dataset_names = [\"csop\", \"csopII\"], output_dir = '../output/first_75/')\n",
    "csop_blended_model75.select_target(target=[\"efficiency\", \"efficiency\"])\n",
    "csop_blended_model75.define_model(model_type = 'linear')\n",
    "csop_blended_model75.get_split_datasets(csop_blended_model75.baseline_model, val_size = 0.2, test_size = None)\n",
    "\n",
    "final_feature_metrics_train,final_feature_metrics_test=repeated_kfold_cv_simplelinear(csop_blended_model75)\n",
    "csop_blended_train_metrics75=convert_metrics_dict_to_sorted_df(final_feature_metrics_train)\n",
    "csop_blended_test_metrics75=convert_metrics_dict_to_sorted_df(final_feature_metrics_test)\n",
    "\n",
    "csop_blended_test_metrics75.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50% Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>average_user_sum_auxiliary_verbs</td>\n",
       "      <td>0.18715</td>\n",
       "      <td>0.68746</td>\n",
       "      <td>0.86391</td>\n",
       "      <td>0.92866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>average_user_sum_nltk_english_stopwords</td>\n",
       "      <td>0.18615</td>\n",
       "      <td>0.68593</td>\n",
       "      <td>0.86474</td>\n",
       "      <td>0.9291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>average_user_sum_num_words</td>\n",
       "      <td>0.18453</td>\n",
       "      <td>0.68683</td>\n",
       "      <td>0.86649</td>\n",
       "      <td>0.93004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>average_user_sum_verbs</td>\n",
       "      <td>0.18011</td>\n",
       "      <td>0.69108</td>\n",
       "      <td>0.87117</td>\n",
       "      <td>0.93255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>max_user_sum_verbs</td>\n",
       "      <td>0.17961</td>\n",
       "      <td>0.68958</td>\n",
       "      <td>0.87091</td>\n",
       "      <td>0.93253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>average_user_sum_num_chars</td>\n",
       "      <td>0.1781</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.87348</td>\n",
       "      <td>0.93376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>max_user_sum_auxiliary_verbs</td>\n",
       "      <td>0.17583</td>\n",
       "      <td>0.69693</td>\n",
       "      <td>0.87506</td>\n",
       "      <td>0.93483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>max_user_sum_num_words</td>\n",
       "      <td>0.17333</td>\n",
       "      <td>0.69185</td>\n",
       "      <td>0.87791</td>\n",
       "      <td>0.93627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>max_user_sum_nltk_english_stopwords</td>\n",
       "      <td>0.17009</td>\n",
       "      <td>0.69428</td>\n",
       "      <td>0.88117</td>\n",
       "      <td>0.93802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>max_user_sum_num_chars</td>\n",
       "      <td>0.16736</td>\n",
       "      <td>0.69608</td>\n",
       "      <td>0.88457</td>\n",
       "      <td>0.93974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     feature       r2      mae      mse  \\\n",
       "602         average_user_sum_auxiliary_verbs  0.18715  0.68746  0.86391   \n",
       "634  average_user_sum_nltk_english_stopwords  0.18615  0.68593  0.86474   \n",
       "402               average_user_sum_num_words  0.18453  0.68683  0.86649   \n",
       "586                   average_user_sum_verbs  0.18011  0.69108  0.87117   \n",
       "589                       max_user_sum_verbs  0.17961  0.68958  0.87091   \n",
       "406               average_user_sum_num_chars   0.1781    0.692  0.87348   \n",
       "605             max_user_sum_auxiliary_verbs  0.17583  0.69693  0.87506   \n",
       "405                   max_user_sum_num_words  0.17333  0.69185  0.87791   \n",
       "637      max_user_sum_nltk_english_stopwords  0.17009  0.69428  0.88117   \n",
       "409                   max_user_sum_num_chars  0.16736  0.69608  0.88457   \n",
       "\n",
       "        rmse  \n",
       "602  0.92866  \n",
       "634   0.9291  \n",
       "402  0.93004  \n",
       "586  0.93255  \n",
       "589  0.93253  \n",
       "406  0.93376  \n",
       "605  0.93483  \n",
       "405  0.93627  \n",
       "637  0.93802  \n",
       "409  0.93974  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csop_blended_model50 = ModelBuilder(dataset_names = [\"csop\", \"csopII\"], output_dir = '../output/first_50/')\n",
    "csop_blended_model50.select_target(target=[\"efficiency\", \"efficiency\"])\n",
    "csop_blended_model50.define_model(model_type = 'linear')\n",
    "csop_blended_model50.get_split_datasets(csop_blended_model50.baseline_model, val_size = 0.2, test_size = None)\n",
    "\n",
    "final_feature_metrics_train,final_feature_metrics_test=repeated_kfold_cv_simplelinear(csop_blended_model50)\n",
    "csop_blended_train_metrics50=convert_metrics_dict_to_sorted_df(final_feature_metrics_train)\n",
    "csop_blended_test_metrics50=convert_metrics_dict_to_sorted_df(final_feature_metrics_test)\n",
    "\n",
    "csop_blended_test_metrics50.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25% Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>average_user_sum_auxiliary_verbs</td>\n",
       "      <td>0.18715</td>\n",
       "      <td>0.68746</td>\n",
       "      <td>0.86391</td>\n",
       "      <td>0.92866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>average_user_sum_nltk_english_stopwords</td>\n",
       "      <td>0.18615</td>\n",
       "      <td>0.68593</td>\n",
       "      <td>0.86474</td>\n",
       "      <td>0.9291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>average_user_sum_num_words</td>\n",
       "      <td>0.18453</td>\n",
       "      <td>0.68683</td>\n",
       "      <td>0.86649</td>\n",
       "      <td>0.93004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>average_user_sum_verbs</td>\n",
       "      <td>0.18011</td>\n",
       "      <td>0.69108</td>\n",
       "      <td>0.87117</td>\n",
       "      <td>0.93255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>max_user_sum_verbs</td>\n",
       "      <td>0.17961</td>\n",
       "      <td>0.68958</td>\n",
       "      <td>0.87091</td>\n",
       "      <td>0.93253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>average_user_sum_num_chars</td>\n",
       "      <td>0.1781</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.87348</td>\n",
       "      <td>0.93376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>max_user_sum_auxiliary_verbs</td>\n",
       "      <td>0.17583</td>\n",
       "      <td>0.69693</td>\n",
       "      <td>0.87506</td>\n",
       "      <td>0.93483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>max_user_sum_num_words</td>\n",
       "      <td>0.17333</td>\n",
       "      <td>0.69185</td>\n",
       "      <td>0.87791</td>\n",
       "      <td>0.93627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>max_user_sum_nltk_english_stopwords</td>\n",
       "      <td>0.17009</td>\n",
       "      <td>0.69428</td>\n",
       "      <td>0.88117</td>\n",
       "      <td>0.93802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>max_user_sum_num_chars</td>\n",
       "      <td>0.16736</td>\n",
       "      <td>0.69608</td>\n",
       "      <td>0.88457</td>\n",
       "      <td>0.93974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     feature       r2      mae      mse  \\\n",
       "602         average_user_sum_auxiliary_verbs  0.18715  0.68746  0.86391   \n",
       "634  average_user_sum_nltk_english_stopwords  0.18615  0.68593  0.86474   \n",
       "402               average_user_sum_num_words  0.18453  0.68683  0.86649   \n",
       "586                   average_user_sum_verbs  0.18011  0.69108  0.87117   \n",
       "589                       max_user_sum_verbs  0.17961  0.68958  0.87091   \n",
       "406               average_user_sum_num_chars   0.1781    0.692  0.87348   \n",
       "605             max_user_sum_auxiliary_verbs  0.17583  0.69693  0.87506   \n",
       "405                   max_user_sum_num_words  0.17333  0.69185  0.87791   \n",
       "637      max_user_sum_nltk_english_stopwords  0.17009  0.69428  0.88117   \n",
       "409                   max_user_sum_num_chars  0.16736  0.69608  0.88457   \n",
       "\n",
       "        rmse  \n",
       "602  0.92866  \n",
       "634   0.9291  \n",
       "402  0.93004  \n",
       "586  0.93255  \n",
       "589  0.93253  \n",
       "406  0.93376  \n",
       "605  0.93483  \n",
       "405  0.93627  \n",
       "637  0.93802  \n",
       "409  0.93974  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csop_blended_model25 = ModelBuilder(dataset_names = [\"csop\", \"csopII\"], output_dir = '../output/first_25/')\n",
    "csop_blended_model25.select_target(target=[\"efficiency\", \"efficiency\"])\n",
    "csop_blended_model25.define_model(model_type = 'linear')\n",
    "csop_blended_model25.get_split_datasets(csop_blended_model25.baseline_model, val_size = 0.2, test_size = None)\n",
    "\n",
    "final_feature_metrics_train,final_feature_metrics_test=repeated_kfold_cv_simplelinear(csop_blended_model25)\n",
    "csop_blended_train_metrics25=convert_metrics_dict_to_sorted_df(final_feature_metrics_train)\n",
    "csop_blended_test_metrics25=convert_metrics_dict_to_sorted_df(final_feature_metrics_test)\n",
    "\n",
    "csop_blended_test_metrics25.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full data (100%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>min_user_sum_positive_bert</td>\n",
       "      <td>0.080767</td>\n",
       "      <td>0.779433</td>\n",
       "      <td>1.003467</td>\n",
       "      <td>0.994178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>min_user_sum_negation</td>\n",
       "      <td>0.06183</td>\n",
       "      <td>0.80798</td>\n",
       "      <td>1.05772</td>\n",
       "      <td>1.02161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>min_user_avg_negation</td>\n",
       "      <td>0.05877</td>\n",
       "      <td>0.79983</td>\n",
       "      <td>1.06019</td>\n",
       "      <td>1.02315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>average_user_sum_factuality</td>\n",
       "      <td>0.05635</td>\n",
       "      <td>0.7947</td>\n",
       "      <td>1.05999</td>\n",
       "      <td>1.02202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>min_user_sum_1st_person_start</td>\n",
       "      <td>0.046113</td>\n",
       "      <td>0.807787</td>\n",
       "      <td>1.032787</td>\n",
       "      <td>1.004725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>min_user_sum_haspositive</td>\n",
       "      <td>0.024711</td>\n",
       "      <td>0.816211</td>\n",
       "      <td>1.060133</td>\n",
       "      <td>1.024056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>min_user_sum_article</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.808733</td>\n",
       "      <td>1.075678</td>\n",
       "      <td>1.027856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>average_factuality</td>\n",
       "      <td>0.01355</td>\n",
       "      <td>0.81381</td>\n",
       "      <td>1.11196</td>\n",
       "      <td>1.04797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>min_user_sum_positive_affect</td>\n",
       "      <td>0.010738</td>\n",
       "      <td>0.812262</td>\n",
       "      <td>1.050812</td>\n",
       "      <td>1.019462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>min_user_sum_positive_words</td>\n",
       "      <td>0.009789</td>\n",
       "      <td>0.816467</td>\n",
       "      <td>1.098056</td>\n",
       "      <td>1.041378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           feature        r2       mae       mse      rmse\n",
       "396     min_user_sum_positive_bert  0.080767  0.779433  1.003467  0.994178\n",
       "472          min_user_sum_negation   0.06183   0.80798   1.05772   1.02161\n",
       "860          min_user_avg_negation   0.05877   0.79983   1.06019   1.02315\n",
       "718    average_user_sum_factuality   0.05635    0.7947   1.05999   1.02202\n",
       "744  min_user_sum_1st_person_start  0.046113  0.807787  1.032787  1.004725\n",
       "768       min_user_sum_haspositive  0.024711  0.816211  1.060133  1.024056\n",
       "600           min_user_sum_article    0.0222  0.808733  1.075678  1.027856\n",
       "327             average_factuality   0.01355   0.81381   1.11196   1.04797\n",
       "508   min_user_sum_positive_affect  0.010738  0.812262  1.050812  1.019462\n",
       "632    min_user_sum_positive_words  0.009789  0.816467  1.098056  1.041378"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_model = ModelBuilder(dataset_names = [\"dat\"])\n",
    "dat_model.select_target(target=[\"efficiency\"])\n",
    "dat_model.define_model(model_type = 'linear')\n",
    "dat_model.get_split_datasets(dat_model.baseline_model, val_size = 0.2, test_size = None)\n",
    "\n",
    "final_feature_metrics_train,final_feature_metrics_test=repeated_kfold_cv_simplelinear(dat_model)\n",
    "dat_train_metrics=convert_metrics_dict_to_sorted_df(final_feature_metrics_train)\n",
    "dat_test_metrics=convert_metrics_dict_to_sorted_df(final_feature_metrics_test)\n",
    "\n",
    "dat_test_metrics.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 75% Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>min_user_sum_positive_bert</td>\n",
       "      <td>0.080767</td>\n",
       "      <td>0.779433</td>\n",
       "      <td>1.003467</td>\n",
       "      <td>0.994178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>min_user_sum_negation</td>\n",
       "      <td>0.06183</td>\n",
       "      <td>0.80798</td>\n",
       "      <td>1.05772</td>\n",
       "      <td>1.02161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>min_user_avg_negation</td>\n",
       "      <td>0.05877</td>\n",
       "      <td>0.79983</td>\n",
       "      <td>1.06019</td>\n",
       "      <td>1.02315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>average_user_sum_factuality</td>\n",
       "      <td>0.05635</td>\n",
       "      <td>0.7947</td>\n",
       "      <td>1.05999</td>\n",
       "      <td>1.02202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>min_user_sum_1st_person_start</td>\n",
       "      <td>0.046113</td>\n",
       "      <td>0.807787</td>\n",
       "      <td>1.032787</td>\n",
       "      <td>1.004725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>stdev_neutral_bert</td>\n",
       "      <td>0.027744</td>\n",
       "      <td>0.798578</td>\n",
       "      <td>1.068422</td>\n",
       "      <td>1.0245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>min_user_sum_haspositive</td>\n",
       "      <td>0.024711</td>\n",
       "      <td>0.816211</td>\n",
       "      <td>1.060133</td>\n",
       "      <td>1.024056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stdev_positive_bert</td>\n",
       "      <td>0.022544</td>\n",
       "      <td>0.8036</td>\n",
       "      <td>1.073333</td>\n",
       "      <td>1.027189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>stdev_positivity_zscore_chats</td>\n",
       "      <td>0.022544</td>\n",
       "      <td>0.8036</td>\n",
       "      <td>1.073333</td>\n",
       "      <td>1.027189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>min_user_sum_article</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.808733</td>\n",
       "      <td>1.075678</td>\n",
       "      <td>1.027856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           feature        r2       mae       mse      rmse\n",
       "396     min_user_sum_positive_bert  0.080767  0.779433  1.003467  0.994178\n",
       "472          min_user_sum_negation   0.06183   0.80798   1.05772   1.02161\n",
       "860          min_user_avg_negation   0.05877   0.79983   1.06019   1.02315\n",
       "718    average_user_sum_factuality   0.05635    0.7947   1.05999   1.02202\n",
       "744  min_user_sum_1st_person_start  0.046113  0.807787  1.032787  1.004725\n",
       "12              stdev_neutral_bert  0.027744  0.798578  1.068422    1.0245\n",
       "768       min_user_sum_haspositive  0.024711  0.816211  1.060133  1.024056\n",
       "4              stdev_positive_bert  0.022544    0.8036  1.073333  1.027189\n",
       "292  stdev_positivity_zscore_chats  0.022544    0.8036  1.073333  1.027189\n",
       "600           min_user_sum_article    0.0222  0.808733  1.075678  1.027856"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_model75 = ModelBuilder(dataset_names = [\"dat\"], output_dir = '../output/first_75/')\n",
    "dat_model75.select_target(target=[\"efficiency\"])\n",
    "dat_model75.define_model(model_type = 'linear')\n",
    "dat_model75.get_split_datasets(dat_model75.baseline_model, val_size = 0.2, test_size = None)\n",
    "\n",
    "final_feature_metrics_train,final_feature_metrics_test=repeated_kfold_cv_simplelinear(dat_model75)\n",
    "dat_train_metrics75=convert_metrics_dict_to_sorted_df(final_feature_metrics_train)\n",
    "dat_test_metrics75=convert_metrics_dict_to_sorted_df(final_feature_metrics_test)\n",
    "\n",
    "dat_test_metrics75.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50% Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>min_user_sum_positive_bert</td>\n",
       "      <td>0.080767</td>\n",
       "      <td>0.779433</td>\n",
       "      <td>1.003467</td>\n",
       "      <td>0.994178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>min_user_sum_negation</td>\n",
       "      <td>0.06183</td>\n",
       "      <td>0.80798</td>\n",
       "      <td>1.05772</td>\n",
       "      <td>1.02161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>min_user_avg_negation</td>\n",
       "      <td>0.05877</td>\n",
       "      <td>0.79983</td>\n",
       "      <td>1.06019</td>\n",
       "      <td>1.02315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>average_user_sum_factuality</td>\n",
       "      <td>0.05635</td>\n",
       "      <td>0.7947</td>\n",
       "      <td>1.05999</td>\n",
       "      <td>1.02202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>min_user_sum_1st_person_start</td>\n",
       "      <td>0.046113</td>\n",
       "      <td>0.807787</td>\n",
       "      <td>1.032787</td>\n",
       "      <td>1.004725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>stdev_auxiliary_verbs</td>\n",
       "      <td>0.03146</td>\n",
       "      <td>0.78241</td>\n",
       "      <td>1.10917</td>\n",
       "      <td>1.04255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>min_user_sum_haspositive</td>\n",
       "      <td>0.024711</td>\n",
       "      <td>0.816211</td>\n",
       "      <td>1.060133</td>\n",
       "      <td>1.024056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>min_user_sum_article</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.808733</td>\n",
       "      <td>1.075678</td>\n",
       "      <td>1.027856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>min_user_sum_positive_affect</td>\n",
       "      <td>0.010738</td>\n",
       "      <td>0.812262</td>\n",
       "      <td>1.050812</td>\n",
       "      <td>1.019462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>min_user_sum_positive_words</td>\n",
       "      <td>0.009789</td>\n",
       "      <td>0.816467</td>\n",
       "      <td>1.098056</td>\n",
       "      <td>1.041378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           feature        r2       mae       mse      rmse\n",
       "396     min_user_sum_positive_bert  0.080767  0.779433  1.003467  0.994178\n",
       "472          min_user_sum_negation   0.06183   0.80798   1.05772   1.02161\n",
       "860          min_user_avg_negation   0.05877   0.79983   1.06019   1.02315\n",
       "718    average_user_sum_factuality   0.05635    0.7947   1.05999   1.02202\n",
       "744  min_user_sum_1st_person_start  0.046113  0.807787  1.032787  1.004725\n",
       "216          stdev_auxiliary_verbs   0.03146   0.78241   1.10917   1.04255\n",
       "768       min_user_sum_haspositive  0.024711  0.816211  1.060133  1.024056\n",
       "600           min_user_sum_article    0.0222  0.808733  1.075678  1.027856\n",
       "508   min_user_sum_positive_affect  0.010738  0.812262  1.050812  1.019462\n",
       "632    min_user_sum_positive_words  0.009789  0.816467  1.098056  1.041378"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_model50 = ModelBuilder(dataset_names = [\"dat\"], output_dir = '../output/first_50/')\n",
    "dat_model50.select_target(target=[\"efficiency\"])\n",
    "dat_model50.define_model(model_type = 'linear')\n",
    "\n",
    "dat_model50.get_split_datasets(dat_model50.baseline_model, val_size = 0.2, test_size = None)\n",
    "\n",
    "final_feature_metrics_train,final_feature_metrics_test=repeated_kfold_cv_simplelinear(dat_model50)\n",
    "dat_train_metrics50=convert_metrics_dict_to_sorted_df(final_feature_metrics_train)\n",
    "dat_test_metrics50=convert_metrics_dict_to_sorted_df(final_feature_metrics_test)\n",
    "\n",
    "dat_test_metrics50.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25% Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>min_user_sum_positive_bert</td>\n",
       "      <td>0.080767</td>\n",
       "      <td>0.779433</td>\n",
       "      <td>1.003467</td>\n",
       "      <td>0.994178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>min_user_sum_negation</td>\n",
       "      <td>0.06183</td>\n",
       "      <td>0.80798</td>\n",
       "      <td>1.05772</td>\n",
       "      <td>1.02161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>min_user_avg_negation</td>\n",
       "      <td>0.05877</td>\n",
       "      <td>0.79983</td>\n",
       "      <td>1.06019</td>\n",
       "      <td>1.02315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>average_user_sum_factuality</td>\n",
       "      <td>0.05635</td>\n",
       "      <td>0.7947</td>\n",
       "      <td>1.05999</td>\n",
       "      <td>1.02202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>min_user_sum_1st_person_start</td>\n",
       "      <td>0.046113</td>\n",
       "      <td>0.807787</td>\n",
       "      <td>1.032787</td>\n",
       "      <td>1.004725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>min_user_sum_haspositive</td>\n",
       "      <td>0.024711</td>\n",
       "      <td>0.816211</td>\n",
       "      <td>1.060133</td>\n",
       "      <td>1.024056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>min_user_sum_article</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.808733</td>\n",
       "      <td>1.075678</td>\n",
       "      <td>1.027856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>min_user_sum_positive_affect</td>\n",
       "      <td>0.010738</td>\n",
       "      <td>0.812262</td>\n",
       "      <td>1.050812</td>\n",
       "      <td>1.019462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>min_user_sum_positive_words</td>\n",
       "      <td>0.009789</td>\n",
       "      <td>0.816467</td>\n",
       "      <td>1.098056</td>\n",
       "      <td>1.041378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>max_user_sum_inhibition</td>\n",
       "      <td>0.00594</td>\n",
       "      <td>0.82132</td>\n",
       "      <td>1.13007</td>\n",
       "      <td>1.05434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           feature        r2       mae       mse      rmse\n",
       "396     min_user_sum_positive_bert  0.080767  0.779433  1.003467  0.994178\n",
       "472          min_user_sum_negation   0.06183   0.80798   1.05772   1.02161\n",
       "860          min_user_avg_negation   0.05877   0.79983   1.06019   1.02315\n",
       "718    average_user_sum_factuality   0.05635    0.7947   1.05999   1.02202\n",
       "744  min_user_sum_1st_person_start  0.046113  0.807787  1.032787  1.004725\n",
       "768       min_user_sum_haspositive  0.024711  0.816211  1.060133  1.024056\n",
       "600           min_user_sum_article    0.0222  0.808733  1.075678  1.027856\n",
       "508   min_user_sum_positive_affect  0.010738  0.812262  1.050812  1.019462\n",
       "632    min_user_sum_positive_words  0.009789  0.816467  1.098056  1.041378\n",
       "541        max_user_sum_inhibition   0.00594   0.82132   1.13007   1.05434"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_model25 = ModelBuilder(dataset_names = [\"dat\"], output_dir = '../output/first_25/')\n",
    "dat_model25.select_target(target=[\"efficiency\"])\n",
    "dat_model25.define_model(model_type = 'linear')\n",
    "\n",
    "dat_model25.get_split_datasets(dat_model25.baseline_model, val_size = 0.2, test_size = None)\n",
    "\n",
    "final_feature_metrics_train,final_feature_metrics_test=repeated_kfold_cv_simplelinear(dat_model25)\n",
    "dat_train_metrics25=convert_metrics_dict_to_sorted_df(final_feature_metrics_train)\n",
    "dat_test_metrics25=convert_metrics_dict_to_sorted_df(final_feature_metrics_test)\n",
    "\n",
    "dat_test_metrics25.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Data (100%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>average_user_avg_indefinite_pronoun</td>\n",
       "      <td>-0.02705</td>\n",
       "      <td>0.49415</td>\n",
       "      <td>4.1808</td>\n",
       "      <td>2.0447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>max_user_sum_gratitude</td>\n",
       "      <td>-0.0271</td>\n",
       "      <td>0.50045</td>\n",
       "      <td>4.18115</td>\n",
       "      <td>2.04475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>max_gratitude</td>\n",
       "      <td>-0.0271</td>\n",
       "      <td>0.50045</td>\n",
       "      <td>4.18115</td>\n",
       "      <td>2.04475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>average_user_sum_2nd_person_start</td>\n",
       "      <td>-0.0276</td>\n",
       "      <td>0.4976</td>\n",
       "      <td>4.1812</td>\n",
       "      <td>2.0448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>max_hedge_words</td>\n",
       "      <td>-0.02765</td>\n",
       "      <td>0.4933</td>\n",
       "      <td>4.18325</td>\n",
       "      <td>2.0453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>average_user_avg_certainty</td>\n",
       "      <td>-0.02805</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>4.1849</td>\n",
       "      <td>2.0457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>max_user_avg_gratitude</td>\n",
       "      <td>-0.0283</td>\n",
       "      <td>0.4941</td>\n",
       "      <td>4.184</td>\n",
       "      <td>2.0455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>stdev_user_avg_body</td>\n",
       "      <td>-0.0288</td>\n",
       "      <td>0.491</td>\n",
       "      <td>4.1858</td>\n",
       "      <td>2.0459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>average_user_avg_body</td>\n",
       "      <td>-0.0291</td>\n",
       "      <td>0.4898</td>\n",
       "      <td>4.1873</td>\n",
       "      <td>2.0463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>max_positivity_zscore_chats</td>\n",
       "      <td>-0.0291</td>\n",
       "      <td>0.4946</td>\n",
       "      <td>4.1892</td>\n",
       "      <td>2.0468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  feature       r2      mae      mse     rmse\n",
       "930   average_user_avg_indefinite_pronoun -0.02705  0.49415   4.1808   2.0447\n",
       "721                max_user_sum_gratitude  -0.0271  0.50045  4.18115  2.04475\n",
       "334                         max_gratitude  -0.0271  0.50045  4.18115  2.04475\n",
       "742     average_user_sum_2nd_person_start  -0.0276   0.4976   4.1812   2.0448\n",
       "254                       max_hedge_words -0.02765   0.4933  4.18325   2.0453\n",
       "822            average_user_avg_certainty -0.02805   0.5005   4.1849   2.0457\n",
       "1105               max_user_avg_gratitude  -0.0283   0.4941    4.184   2.0455\n",
       "871                   stdev_user_avg_body  -0.0288    0.491   4.1858   2.0459\n",
       "870                 average_user_avg_body  -0.0291   0.4898   4.1873   2.0463\n",
       "294           max_positivity_zscore_chats  -0.0291   0.4946   4.1892   2.0468"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation_blended_model = ModelBuilder(dataset_names = [\"gurcay\", \"becker\"])\n",
    "estimation_blended_model.select_target(target=[\"mean_post_discussion_error_pct\", \"mean_post_discussion_error_pct\"])\n",
    "estimation_blended_model.define_model(model_type = 'linear')\n",
    "\n",
    "estimation_blended_model.get_split_datasets(estimation_blended_model.baseline_model, val_size = 0.2, test_size = None)\n",
    "\n",
    "final_feature_metrics_train,final_feature_metrics_test=repeated_kfold_cv_simplelinear(estimation_blended_model)\n",
    "estimation_blended_train_metrics=convert_metrics_dict_to_sorted_df(final_feature_metrics_train)\n",
    "estimation_blended_test_metrics=convert_metrics_dict_to_sorted_df(final_feature_metrics_test)\n",
    "\n",
    "estimation_blended_test_metrics.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 75% Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>average_user_avg_indefinite_pronoun</td>\n",
       "      <td>-0.02705</td>\n",
       "      <td>0.49415</td>\n",
       "      <td>4.1808</td>\n",
       "      <td>2.0447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>max_user_sum_gratitude</td>\n",
       "      <td>-0.0271</td>\n",
       "      <td>0.50045</td>\n",
       "      <td>4.18115</td>\n",
       "      <td>2.04475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>max_gratitude</td>\n",
       "      <td>-0.0275</td>\n",
       "      <td>0.4992</td>\n",
       "      <td>4.18265</td>\n",
       "      <td>2.04515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>average_user_sum_2nd_person_start</td>\n",
       "      <td>-0.0276</td>\n",
       "      <td>0.4976</td>\n",
       "      <td>4.1812</td>\n",
       "      <td>2.0448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>average_user_avg_certainty</td>\n",
       "      <td>-0.02805</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>4.1849</td>\n",
       "      <td>2.0457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>max_percept</td>\n",
       "      <td>-0.0282</td>\n",
       "      <td>0.4941</td>\n",
       "      <td>4.1835</td>\n",
       "      <td>2.0454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>max_user_avg_gratitude</td>\n",
       "      <td>-0.0283</td>\n",
       "      <td>0.4941</td>\n",
       "      <td>4.184</td>\n",
       "      <td>2.0455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>stdev_2nd_person_start</td>\n",
       "      <td>-0.0285</td>\n",
       "      <td>0.4995</td>\n",
       "      <td>4.1848</td>\n",
       "      <td>2.0457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>stdev_user_avg_body</td>\n",
       "      <td>-0.0288</td>\n",
       "      <td>0.491</td>\n",
       "      <td>4.1858</td>\n",
       "      <td>2.0459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>average_user_avg_body</td>\n",
       "      <td>-0.0291</td>\n",
       "      <td>0.4898</td>\n",
       "      <td>4.1873</td>\n",
       "      <td>2.0463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  feature       r2      mae      mse     rmse\n",
       "930   average_user_avg_indefinite_pronoun -0.02705  0.49415   4.1808   2.0447\n",
       "721                max_user_sum_gratitude  -0.0271  0.50045  4.18115  2.04475\n",
       "334                         max_gratitude  -0.0275   0.4992  4.18265  2.04515\n",
       "742     average_user_sum_2nd_person_start  -0.0276   0.4976   4.1812   2.0448\n",
       "822            average_user_avg_certainty -0.02805   0.5005   4.1849   2.0457\n",
       "234                           max_percept  -0.0282   0.4941   4.1835   2.0454\n",
       "1105               max_user_avg_gratitude  -0.0283   0.4941    4.184   2.0455\n",
       "356                stdev_2nd_person_start  -0.0285   0.4995   4.1848   2.0457\n",
       "871                   stdev_user_avg_body  -0.0288    0.491   4.1858   2.0459\n",
       "870                 average_user_avg_body  -0.0291   0.4898   4.1873   2.0463"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation_blended_model75 = ModelBuilder(dataset_names = [\"gurcay\", \"becker\"],  output_dir = '../output/first_75/')\n",
    "estimation_blended_model75.select_target(target=[\"mean_post_discussion_error_pct\", \"mean_post_discussion_error_pct\"])\n",
    "estimation_blended_model75.define_model(model_type = 'linear')\n",
    "\n",
    "estimation_blended_model75.get_split_datasets(estimation_blended_model75.baseline_model, val_size = 0.2, test_size = None)\n",
    "\n",
    "final_feature_metrics_train,final_feature_metrics_test=repeated_kfold_cv_simplelinear(estimation_blended_model75)\n",
    "estimation_blended_train_metrics75=convert_metrics_dict_to_sorted_df(final_feature_metrics_train)\n",
    "estimation_blended_test_metrics75=convert_metrics_dict_to_sorted_df(final_feature_metrics_test)\n",
    "\n",
    "estimation_blended_test_metrics75.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50% Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>max_anxiety</td>\n",
       "      <td>-0.02495</td>\n",
       "      <td>0.49085</td>\n",
       "      <td>4.17225</td>\n",
       "      <td>2.0426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>stdev_sadness</td>\n",
       "      <td>-0.0262</td>\n",
       "      <td>0.50015</td>\n",
       "      <td>4.1775</td>\n",
       "      <td>2.0439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>average_bio</td>\n",
       "      <td>-0.0269</td>\n",
       "      <td>0.4891</td>\n",
       "      <td>4.1781</td>\n",
       "      <td>2.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>average_user_avg_indefinite_pronoun</td>\n",
       "      <td>-0.02705</td>\n",
       "      <td>0.49415</td>\n",
       "      <td>4.1808</td>\n",
       "      <td>2.0447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>max_user_sum_gratitude</td>\n",
       "      <td>-0.0271</td>\n",
       "      <td>0.50045</td>\n",
       "      <td>4.18115</td>\n",
       "      <td>2.04475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>stdev_article</td>\n",
       "      <td>-0.0271</td>\n",
       "      <td>0.4856</td>\n",
       "      <td>4.183</td>\n",
       "      <td>2.0452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>max_sexual</td>\n",
       "      <td>-0.02755</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>4.183</td>\n",
       "      <td>2.04525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>average_user_sum_2nd_person_start</td>\n",
       "      <td>-0.0276</td>\n",
       "      <td>0.4976</td>\n",
       "      <td>4.1812</td>\n",
       "      <td>2.0448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>stdev_swear</td>\n",
       "      <td>-0.02765</td>\n",
       "      <td>0.5081</td>\n",
       "      <td>4.18315</td>\n",
       "      <td>2.04525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>max_family</td>\n",
       "      <td>-0.0279</td>\n",
       "      <td>0.5064</td>\n",
       "      <td>4.1824</td>\n",
       "      <td>2.0451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 feature       r2      mae      mse     rmse\n",
       "74                           max_anxiety -0.02495  0.49085  4.17225   2.0426\n",
       "152                        stdev_sadness  -0.0262  0.50015   4.1775   2.0439\n",
       "59                           average_bio  -0.0269   0.4891   4.1781    2.044\n",
       "930  average_user_avg_indefinite_pronoun -0.02705  0.49415   4.1808   2.0447\n",
       "721               max_user_sum_gratitude  -0.0271  0.50045  4.18115  2.04475\n",
       "208                        stdev_article  -0.0271   0.4856    4.183   2.0452\n",
       "146                           max_sexual -0.02755   0.4958    4.183  2.04525\n",
       "742    average_user_sum_2nd_person_start  -0.0276   0.4976   4.1812   2.0448\n",
       "84                           stdev_swear -0.02765   0.5081  4.18315  2.04525\n",
       "106                           max_family  -0.0279   0.5064   4.1824   2.0451"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation_blended_model50 = ModelBuilder(dataset_names = [\"gurcay\", \"becker\"],  output_dir = '../output/first_50/')\n",
    "estimation_blended_model50.select_target(target=[\"mean_post_discussion_error_pct\", \"mean_post_discussion_error_pct\"])\n",
    "estimation_blended_model50.define_model(model_type = 'linear')\n",
    "\n",
    "estimation_blended_model50.get_split_datasets(estimation_blended_model50.baseline_model, val_size = 0.2, test_size = None)\n",
    "\n",
    "final_feature_metrics_train,final_feature_metrics_test=repeated_kfold_cv_simplelinear(estimation_blended_model50)\n",
    "estimation_blended_train_metrics50=convert_metrics_dict_to_sorted_df(final_feature_metrics_train)\n",
    "estimation_blended_test_metrics50=convert_metrics_dict_to_sorted_df(final_feature_metrics_test)\n",
    "\n",
    "estimation_blended_test_metrics50.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25% Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>average_user_avg_indefinite_pronoun</td>\n",
       "      <td>-0.02705</td>\n",
       "      <td>0.49415</td>\n",
       "      <td>4.1808</td>\n",
       "      <td>2.0447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>max_past_tense</td>\n",
       "      <td>-0.0271</td>\n",
       "      <td>0.5009</td>\n",
       "      <td>4.1831</td>\n",
       "      <td>2.0453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>max_user_sum_gratitude</td>\n",
       "      <td>-0.0271</td>\n",
       "      <td>0.50045</td>\n",
       "      <td>4.18115</td>\n",
       "      <td>2.04475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>max_anger</td>\n",
       "      <td>-0.0273</td>\n",
       "      <td>0.4984</td>\n",
       "      <td>4.1798</td>\n",
       "      <td>2.0445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>average_user_sum_2nd_person_start</td>\n",
       "      <td>-0.0276</td>\n",
       "      <td>0.4976</td>\n",
       "      <td>4.1812</td>\n",
       "      <td>2.0448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>average_user_avg_certainty</td>\n",
       "      <td>-0.02805</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>4.1849</td>\n",
       "      <td>2.0457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>max_user_avg_gratitude</td>\n",
       "      <td>-0.0283</td>\n",
       "      <td>0.4941</td>\n",
       "      <td>4.184</td>\n",
       "      <td>2.0455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>max_anxiety</td>\n",
       "      <td>-0.0286</td>\n",
       "      <td>0.4786</td>\n",
       "      <td>4.1853</td>\n",
       "      <td>2.0458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>stdev_user_avg_body</td>\n",
       "      <td>-0.0288</td>\n",
       "      <td>0.491</td>\n",
       "      <td>4.1858</td>\n",
       "      <td>2.0459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>max_sexual</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.495</td>\n",
       "      <td>4.18875</td>\n",
       "      <td>2.04665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  feature       r2      mae      mse     rmse\n",
       "930   average_user_avg_indefinite_pronoun -0.02705  0.49415   4.1808   2.0447\n",
       "138                        max_past_tense  -0.0271   0.5009   4.1831   2.0453\n",
       "721                max_user_sum_gratitude  -0.0271  0.50045  4.18115  2.04475\n",
       "182                             max_anger  -0.0273   0.4984   4.1798   2.0445\n",
       "742     average_user_sum_2nd_person_start  -0.0276   0.4976   4.1812   2.0448\n",
       "822            average_user_avg_certainty -0.02805   0.5005   4.1849   2.0457\n",
       "1105               max_user_avg_gratitude  -0.0283   0.4941    4.184   2.0455\n",
       "74                            max_anxiety  -0.0286   0.4786   4.1853   2.0458\n",
       "871                   stdev_user_avg_body  -0.0288    0.491   4.1858   2.0459\n",
       "146                            max_sexual   -0.029    0.495  4.18875  2.04665"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation_blended_model25 = ModelBuilder(dataset_names = [\"gurcay\", \"becker\"],  output_dir = '../output/first_25/')\n",
    "estimation_blended_model25.select_target(target=[\"mean_post_discussion_error_pct\", \"mean_post_discussion_error_pct\"])\n",
    "estimation_blended_model25.define_model(model_type = 'linear')\n",
    "\n",
    "estimation_blended_model25.get_split_datasets(estimation_blended_model25.baseline_model, val_size = 0.2, test_size = None)\n",
    "\n",
    "final_feature_metrics_train,final_feature_metrics_test=repeated_kfold_cv_simplelinear(estimation_blended_model25)\n",
    "estimation_blended_train_metrics25=convert_metrics_dict_to_sorted_df(final_feature_metrics_train)\n",
    "estimation_blended_test_metrics25=convert_metrics_dict_to_sorted_df(final_feature_metrics_test)\n",
    "\n",
    "estimation_blended_test_metrics25.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "team_process_map",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4308115ec36d55d4bd05e5164490d17bc30a5f7275b0a0d4f3922ff237a9eaea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
