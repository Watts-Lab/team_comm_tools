{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_builder import ModelBuilder\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import colorsys\n",
    "from scipy.interpolate import splrep, BSpline # for Spline graphs\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import seaborn as sns\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'becker': {'filename': 'beckerestimation_output_conversation_level.csv',\n",
       "  'cols_to_ignore': ['conversation_num',\n",
       "   'mean_pre_discussion_error',\n",
       "   'mean_post_discussion_error',\n",
       "   'mean_pre_discussion_error_pct',\n",
       "   'mean_post_discussion_error_pct',\n",
       "   'question',\n",
       "   'chatrooms',\n",
       "   'trial_indx']},\n",
       " 'csop': {'filename': 'csop_output_conversation_level.csv',\n",
       "  'cols_to_ignore': ['conversation_num',\n",
       "   'batch_num',\n",
       "   'round_num',\n",
       "   'round_index',\n",
       "   'task_index',\n",
       "   'complexity',\n",
       "   'type',\n",
       "   'social_perceptiveness',\n",
       "   'skill',\n",
       "   'normalized_score',\n",
       "   'zscore_score',\n",
       "   'zscore_round_duration',\n",
       "   'zscore_efficiency']},\n",
       " 'csopII': {'filename': 'csopII_output_conversation_level.csv',\n",
       "  'cols_to_ignore': ['conversation_num',\n",
       "   'batch_num',\n",
       "   'vis_img',\n",
       "   'int_verb',\n",
       "   'ort_img',\n",
       "   'rep_man',\n",
       "   'soc_pers',\n",
       "   'team_size',\n",
       "   'difficulty',\n",
       "   'score',\n",
       "   'duration',\n",
       "   'efficiency',\n",
       "   'timestamp']},\n",
       " 'dat': {'filename': 'DAT_output_conversation_level.csv',\n",
       "  'cols_to_ignore': ['conversation_num',\n",
       "   'batch_num',\n",
       "   'vis_img',\n",
       "   'int_verb',\n",
       "   'ort_img',\n",
       "   'rep_man',\n",
       "   'soc_pers',\n",
       "   'team_size',\n",
       "   'score',\n",
       "   'duration',\n",
       "   'efficiency',\n",
       "   'timestamp']},\n",
       " 'gurcay': {'filename': 'gurcay2015estimation_output_conversation_level.csv',\n",
       "  'cols_to_ignore': ['conversation_num',\n",
       "   'mean_pre_discussion_error',\n",
       "   'mean_post_discussion_error',\n",
       "   'mean_pre_discussion_error_pct',\n",
       "   'mean_post_discussion_error_pct',\n",
       "   'question']},\n",
       " 'juries': {'filename': 'jury_output_conversation_level.csv',\n",
       "  'cols_to_ignore': ['conversation_num',\n",
       "   'batch_num',\n",
       "   'round_num',\n",
       "   'timestamp',\n",
       "   'majority_pct',\n",
       "   'num_flipped',\n",
       "   'flipped_pct',\n",
       "   'num_votes']},\n",
       " 'pgg': {'filename': 'pgg_output_conversation_level.csv',\n",
       "  'cols_to_ignore': ['conversation_num',\n",
       "   'treatmentName',\n",
       "   'punishmentCost',\n",
       "   'punishmentMagnitude',\n",
       "   'total_costs',\n",
       "   'total_penalties',\n",
       "   'total_rewards',\n",
       "   'multiplier',\n",
       "   'punishmentExists',\n",
       "   'rewardExists',\n",
       "   'playerCount',\n",
       "   'numRounds',\n",
       "   'timestamp',\n",
       "   'score']},\n",
       " 'task_mapping_keys': {'juries': 'Mock jury',\n",
       "  'csop': 'Room assignment task',\n",
       "  'csopII': 'Room assignment task',\n",
       "  'dat': 'Divergent Association Task',\n",
       "  'becker': 'Estimating Factual Quantities',\n",
       "  'gurcay': 'Estimating Factual Quantities'},\n",
       " 'task_names': ['Mock jury',\n",
       "  'Room assignment task',\n",
       "  'Room assignment task',\n",
       "  'Divergent Association Task',\n",
       "  'Estimating Factual Quantities']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"config.json\", \"rb\") as json_file:\n",
    "    config = json.load(json_file)\n",
    "config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per-Task Linear Models\n",
    "This notebook contains univariate linear models models to show how different independent variables relate to the dependent variable(s) of interest, for each task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_metrics_dict_to_sorted_df(data):\n",
    "    # Convert the nested dictionary to a DataFrame\n",
    "    df = pd.DataFrame(data).T\n",
    "\n",
    "    # Reset index to move the 'feature' names to a column\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'feature'}, inplace=True)\n",
    "\n",
    "    # Sort the DataFrame by 'r2' values in descending order\n",
    "    df_sorted = df.sort_values(by='r2', ascending=False)\n",
    "\n",
    "    # Reorder the columns as required\n",
    "    columns_order = ['feature', 'r2', 'mae', 'mse', 'rmse']\n",
    "    df_sorted = df_sorted[columns_order]\n",
    "    return(df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeated_kfold_cv_simplelinear(model, k = 10, seed = 19104):\n",
    "\n",
    "    # Store metrics --- R^2, MAE, MSE\n",
    "    metrics = ['r2', 'mae', 'mse', 'rmse']\n",
    "    feature_metric_dictionary = {}\n",
    "\n",
    "    # Assumes that we already called split datasets before we called this function!\n",
    "    all_features = model.X.columns # include all possible features at this stage\n",
    "\n",
    "    # set up to store results for this feature\n",
    "    for feature in all_features:\n",
    "        feature_metric_dictionary[feature] = {\"train\": None, \"test\": None}\n",
    "        feature_metric_dictionary[feature][\"train\"] = pd.DataFrame(columns=metrics)\n",
    "        feature_metric_dictionary[feature][\"test\"] = pd.DataFrame(columns=metrics)\n",
    "\n",
    "    # Outer loop --- repeat this k times for k-fold CV\n",
    "    # Repeated k-fold cross-validation\n",
    "    random.seed(seed) # set seed for reproducibility\n",
    "    random_states_list = [random.randint(100, 1000000) for _ in range(k)] # create a bunch of different random states\n",
    "\n",
    "    for i in range(len(random_states_list)):\n",
    "        # create an entirely different train-test split\n",
    "        model.get_split_datasets(model.baseline_model, val_size = 0.2, test_size = None, random_state = random_states_list[i])\n",
    "\n",
    "        # Fit a single linear regression on each of the features and report the results\n",
    "        for feature in model.X_train: # do this only for the features that made it into this split\n",
    "            # train a linear regression on just this one feature\n",
    "            evaluation_metrics = model.train_simple_model(model.baseline_model, feature_subset = [feature])\n",
    "            # store the results for that feature\n",
    "            feature_metric_dictionary[feature][\"train\"] = feature_metric_dictionary[feature][\"train\"].append(evaluation_metrics['train'], ignore_index=True)\n",
    "            feature_metric_dictionary[feature][\"test\"] = feature_metric_dictionary[feature][\"test\"].append(evaluation_metrics['val'], ignore_index=True)\n",
    "            # reset the train-test-split, as the underlying X_test got modified\n",
    "            model.get_split_datasets(model.baseline_model, val_size = 0.2, test_size = None, random_state = random_states_list[i])\n",
    "\n",
    "    # Get mean metrics for each feature\n",
    "    '''\n",
    "    Optimal format:\n",
    "\n",
    "    feature 1    r2   mae   mse  rmse\n",
    "    feature 2    r2   mae   mse  rmse\n",
    "    feature 3    r2   mae   mse  rmse\n",
    "    '''\n",
    "    final_feature_metrics_train = {}\n",
    "    final_feature_metrics_test = {}\n",
    "\n",
    "    for feature in feature_metric_dictionary.keys():\n",
    "        final_feature_metrics_train[feature]=feature_metric_dictionary[feature][\"train\"].mean()\n",
    "        final_feature_metrics_test[feature]=feature_metric_dictionary[feature][\"test\"].mean()\n",
    "\n",
    "    return final_feature_metrics_train, final_feature_metrics_test\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jury"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Data (100)%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Define the basic model\n",
    "juries_model = ModelBuilder(dataset_names = [\"juries\"])\n",
    "juries_model.select_target(target=[\"majority_pct\"])\n",
    "juries_model.define_model(model_type = 'linear')\n",
    "juries_model.get_split_datasets(juries_model.baseline_model, val_size = 0.2, test_size = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n",
      "Done\n",
      "Checking Holdout Sets...Creating Holdout Sets...\n",
      "Cleaning Up Columns...\n"
     ]
    }
   ],
   "source": [
    "final_feature_metrics_train,final_feature_metrics_test=repeated_kfold_cv_simplelinear(juries_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jury_train_metrics=convert_metrics_dict_to_sorted_df(final_feature_metrics_train)\n",
    "jury_test_metrics=convert_metrics_dict_to_sorted_df(final_feature_metrics_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"paper\", rc={\"axes.labelsize\":20})\n",
    "sns.set_context(\"talk\", font_scale=1.4)\n",
    "\n",
    "def plot_single_linear_model(conversation_data, x_vars, y_vars, num_top_plots=None):\n",
    "    num_plots = len(x_vars) * len(y_vars)\n",
    "    num_rows = len(y_vars)\n",
    "    num_cols = len(x_vars)\n",
    "    num_plots_per_row = min(5, num_cols)\n",
    "\n",
    "    num_rows_needed = math.ceil(num_plots / num_plots_per_row)\n",
    "    fig_height = num_rows_needed * 5\n",
    "    fig_width = num_plots_per_row * 5\n",
    "\n",
    "    plt.figure(figsize=(fig_width, fig_height))\n",
    "    \n",
    "    plot_num = 1\n",
    "    metrics_values = []\n",
    "    \n",
    "    if num_top_plots is not None:\n",
    "        all_metrics = []\n",
    "\n",
    "    for y_var in y_vars:\n",
    "        for x_var in x_vars:\n",
    "            if num_top_plots is not None:\n",
    "                x_data = conversation_data[x_var].values.reshape(-1, 1)\n",
    "                y_data = conversation_data[y_var].values\n",
    "\n",
    "                # Fit linear regression model\n",
    "                model = LinearRegression()\n",
    "                model.fit(x_data, y_data)\n",
    "\n",
    "                # Predict using the model\n",
    "                y_pred = model.predict(x_data)\n",
    "\n",
    "                # Calculate metrics\n",
    "                r_squared = r2_score(y_data, y_pred)\n",
    "                mse = mean_squared_error(y_data, y_pred)\n",
    "                mae = mean_absolute_error(y_data, y_pred)\n",
    "                all_metrics.append((x_var, y_var, r_squared, mse, mae))\n",
    "            \n",
    "            if num_top_plots is None or plot_num <= num_top_plots:\n",
    "                plt.subplot(num_rows_needed, num_plots_per_row, plot_num)\n",
    "                sns.scatterplot(x=x_var, y=y_var, data=conversation_data)\n",
    "                \n",
    "                if num_top_plots is not None:\n",
    "                    plt.plot(x_data, y_pred, color='red')\n",
    "                    \n",
    "                plot_num += 1\n",
    "                \n",
    "                if plot_num > num_plots:\n",
    "                    break\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    if num_top_plots is not None:\n",
    "        metrics_df = pd.DataFrame(all_metrics, columns=['x_var', 'y_var', 'r_squared', 'mse', 'mae'])\n",
    "        metrics_df = metrics_df.sort_values(by='r_squared', ascending=False).head(num_top_plots)\n",
    "\n",
    "    return(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_jury_simple_models = plot_single_linear_model(juries_model.conv, juries_model.conv.drop([\"target_raw\", \"target_std\"], axis = 1), [\"target_std\"], num_top_plots=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_jury_simple_models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 75% of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "juries_model75 = ModelBuilder(dataset_names = [\"juries\"], output_dir = '../output/first_75/')\n",
    "juries_model75.select_target(target=[\"majority_pct\"])\n",
    "juries_model75.define_model(model_type = 'rf')\n",
    "\n",
    "r2_jury_simple_models75 = plot_single_linear_model(juries_model75.conv, juries_model75.conv.drop([\"target_raw\", \"target_std\"], axis=1), [\"target_std\"], num_top_plots=10)\n",
    "r2_jury_simple_models75"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50% Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "juries_model50 = ModelBuilder(dataset_names = [\"juries\"], output_dir = '../output/first_50/')\n",
    "juries_model50.select_target(target=[\"majority_pct\"])\n",
    "juries_model50.define_model(model_type = 'rf')\n",
    "\n",
    "r2_jury_simple_models50 = plot_single_linear_model(juries_model50.conv, juries_model50.conv.drop([\"target_raw\", \"target_std\"], axis=1), [\"target_std\"], num_top_plots=10)\n",
    "r2_jury_simple_models50"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25% of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "juries_model25 = ModelBuilder(dataset_names = [\"juries\"], output_dir = '../output/first_25/')\n",
    "juries_model25.select_target(target=[\"majority_pct\"])\n",
    "juries_model25.define_model(model_type = 'rf')\n",
    "\n",
    "r2_jury_simple_models25 = plot_single_linear_model(juries_model25.conv, juries_model25.conv.drop([\"target_raw\", \"target_std\"], axis=1), [\"target_std\"], num_top_plots=10)\n",
    "r2_jury_simple_models25"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSOP (blended)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Data (100%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csop_blended_model = ModelBuilder(dataset_names = [\"csop\", \"csopII\"])\n",
    "csop_blended_model.select_target(target=[\"zscore_efficiency\", \"efficiency\"])\n",
    "csop_blended_model.define_model(model_type = 'rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_csop_simple_models = plot_single_linear_model(csop_blended_model.conv, csop_blended_model.conv.drop([\"target_raw\", \"target_std\"], axis=1), [\"target_std\"], num_top_plots=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_csop_simple_models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 75% Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csop_blended_model75 = ModelBuilder(dataset_names = [\"csop\", \"csopII\"], output_dir = '../output/first_75/')\n",
    "csop_blended_model75.select_target(target=[\"zscore_efficiency\", \"efficiency\"])\n",
    "csop_blended_model75.define_model(model_type = 'rf')\n",
    "\n",
    "r2_csop_simple_models75 = plot_single_linear_model(csop_blended_model75.conv, csop_blended_model75.conv.drop([\"target_raw\", \"target_std\"], axis=1), [\"target_std\"], num_top_plots=10)\n",
    "r2_csop_simple_models75"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50% Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csop_blended_model50 = ModelBuilder(dataset_names = [\"csop\", \"csopII\"], output_dir = '../output/first_50/')\n",
    "csop_blended_model50.select_target(target=[\"zscore_efficiency\", \"efficiency\"])\n",
    "csop_blended_model50.define_model(model_type = 'rf')\n",
    "\n",
    "r2_csop_simple_models50 = plot_single_linear_model(csop_blended_model50.conv, csop_blended_model50.conv.drop([\"target_raw\", \"target_std\"], axis=1), [\"target_std\"], num_top_plots=10)\n",
    "r2_csop_simple_models50"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25% Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csop_blended_model25 = ModelBuilder(dataset_names = [\"csop\", \"csopII\"], output_dir = '../output/first_25/')\n",
    "csop_blended_model25.select_target(target=[\"zscore_efficiency\", \"efficiency\"])\n",
    "csop_blended_model25.define_model(model_type = 'rf')\n",
    "\n",
    "r2_csop_simple_models25 = plot_single_linear_model(csop_blended_model25.conv, csop_blended_model25.conv.drop([\"target_raw\", \"target_std\"], axis=1), [\"target_std\"], num_top_plots=10)\n",
    "r2_csop_simple_models25"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full data (100%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_model = ModelBuilder(dataset_names = [\"dat\"])\n",
    "dat_model.select_target(target=[\"efficiency\"])\n",
    "dat_model.define_model(model_type = 'rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_dat_simple_models = plot_single_linear_model(dat_model.conv, dat_model.conv.drop([\"target_raw\", \"target_std\"], axis=1), [\"target_std\"], num_top_plots = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_dat_simple_models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 75% Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_model75 = ModelBuilder(dataset_names = [\"dat\"], output_dir = '../output/first_75/')\n",
    "dat_model75.select_target(target=[\"efficiency\"])\n",
    "dat_model75.define_model(model_type = 'rf')\n",
    "\n",
    "r2_dat_simple_models75 = plot_single_linear_model(dat_model75.conv, dat_model75.conv.drop([\"target_raw\", \"target_std\"], axis=1), [\"target_std\"], num_top_plots=10)\n",
    "r2_dat_simple_models75"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50% Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_model50 = ModelBuilder(dataset_names = [\"dat\"], output_dir = '../output/first_50/')\n",
    "dat_model50.select_target(target=[\"efficiency\"])\n",
    "dat_model50.define_model(model_type = 'rf')\n",
    "\n",
    "r2_dat_simple_models50 = plot_single_linear_model(dat_model50.conv, dat_model50.conv.drop([\"target_raw\", \"target_std\"], axis=1), [\"target_std\"], num_top_plots=10)\n",
    "r2_dat_simple_models50"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25% Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_model25 = ModelBuilder(dataset_names = [\"dat\"], output_dir = '../output/first_25/')\n",
    "dat_model25.select_target(target=[\"efficiency\"])\n",
    "dat_model25.define_model(model_type = 'rf')\n",
    "\n",
    "r2_dat_simple_models25 = plot_single_linear_model(dat_model25.conv, dat_model25.conv.drop([\"target_raw\", \"target_std\"], axis=1), [\"target_std\"], num_top_plots=10)\n",
    "r2_dat_simple_models25"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Data (100%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimation_blended_model = ModelBuilder(dataset_names = [\"gurcay\", \"becker\"])\n",
    "estimation_blended_model.select_target(target=[\"mean_post_discussion_error_pct\", \"mean_post_discussion_error_pct\"])\n",
    "estimation_blended_model.define_model(model_type = 'rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_estimation_simple_models = plot_single_linear_model(estimation_blended_model.conv, estimation_blended_model.conv.drop([\"target_raw\", \"target_std\"], axis=1), [\"target_std\"], num_top_plots = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_estimation_simple_models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 75% Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimation_blended_model75 = ModelBuilder(dataset_names = [\"gurcay\", \"becker\"],  output_dir = '../output/first_75/')\n",
    "estimation_blended_model75.select_target(target=[\"mean_post_discussion_error_pct\", \"mean_post_discussion_error_pct\"])\n",
    "estimation_blended_model75.define_model(model_type = 'rf')\n",
    "\n",
    "r2_estimation_simple_models75 = plot_single_linear_model(estimation_blended_model75.conv, estimation_blended_model75.conv.drop([\"target_raw\", \"target_std\"], axis=1), [\"target_std\"], num_top_plots=10)\n",
    "r2_estimation_simple_models75"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50% Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimation_blended_model50 = ModelBuilder(dataset_names = [\"gurcay\", \"becker\"],  output_dir = '../output/first_50/')\n",
    "estimation_blended_model50.select_target(target=[\"mean_post_discussion_error_pct\", \"mean_post_discussion_error_pct\"])\n",
    "estimation_blended_model50.define_model(model_type = 'rf')\n",
    "\n",
    "r2_estimation_simple_models50 = plot_single_linear_model(estimation_blended_model50.conv, estimation_blended_model50.conv.drop([\"target_raw\", \"target_std\"], axis=1), [\"target_std\"], num_top_plots=10)\n",
    "r2_estimation_simple_models50"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25% Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimation_blended_model25 = ModelBuilder(dataset_names = [\"gurcay\", \"becker\"],  output_dir = '../output/first_25/')\n",
    "estimation_blended_model25.select_target(target=[\"mean_post_discussion_error_pct\", \"mean_post_discussion_error_pct\"])\n",
    "estimation_blended_model25.define_model(model_type = 'rf')\n",
    "\n",
    "r2_estimation_simple_models25 = plot_single_linear_model(estimation_blended_model25.conv, estimation_blended_model25.conv.drop([\"target_raw\", \"target_std\"], axis=1), [\"target_std\"], num_top_plots=10)\n",
    "r2_estimation_simple_models25"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "team_process_map",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4308115ec36d55d4bd05e5164490d17bc30a5f7275b0a0d4f3922ff237a9eaea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
